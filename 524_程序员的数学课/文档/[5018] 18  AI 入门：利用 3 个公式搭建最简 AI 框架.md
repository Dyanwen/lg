<p data-nodeid="43379" class="">你知道，你的网购 app 是如何成为你肚中蛔虫，向你“智能推荐”你的心仪之物的吗？地图 app 又是如何“智能预测”，你家门口的每日交通状况的吗？</p>
<p data-nodeid="43380">如今 AI 变得无所不知，但原因并不是它真的能“窥探”万物，仅仅是因为它学会了从“数据”中学习，寻得了万物的规律。你与“淘友们”的浏览、购买数据，让它了解了你这个类群消费者的偏好；你与“出行者们”的日复一日的交通记录，让它轻松掌握所有人的出行规律。</p>
<p data-nodeid="43381">所以 AI 的本质就是“从大数据中学习”，那么想要了解 AI，是不是真的需要先用千万级的数据练手呢？不是的。接下来我仅用四对数据，便能从中带你找出“人工智能建模框架”的关键公式。</p>
<p data-nodeid="43382">这一模块，我们就开始从数学的视角来学习一下人工智能。</p>
<h3 data-nodeid="43383">从“身高预测”认识 AI 本质</h3>
<p data-nodeid="43384">我们先来看一个最简单的人工智能的例子。有四对父子，他们的身高分别如下表所示，假设孩子的身高与父亲的身高之间是线性关系，试着用前三对父子身高的关系推算出第四对父子中儿子的身高。</p>
<p data-nodeid="43385"><img src="https://s0.lgstatic.com/i/image/M00/8B/D4/Ciqc1F_hidSAYEpWAACoFTaX5sI824.png" alt="Lark20201222-135252.png" data-nodeid="43471"></p>
<p data-nodeid="43386">我们可以利用 Excel 绘制散点图的方法拟合，也可以用先前所学的线性回归进行拟合。不管哪种方法，拟合的结果都是<strong data-nodeid="43477">儿子的身高 = 父亲的身高+3</strong>。我们根据这个关系可以推算出，对于身高 182 的父亲，他的孩子更有可能的身高是 185。</p>
<p data-nodeid="43387"><img src="https://s0.lgstatic.com/i/image/M00/8B/E0/CgqCHl_hid2AJERYAAFTWA63MyU875.png" alt="Lark20201222-135246.png" data-nodeid="43480"></p>
<p data-nodeid="43388">其实，这就是一个用人工智能解决问题的案例。人工智能，是让机器对数据进行计算，从而得到经验（这很像人类对书本知识的学习），并利用经验对未知事务做出更智能的决策。</p>
<p data-nodeid="43389">在这个例子中，我们对前三对父子身高关系进行计算，得到了“儿子的身高 = 父亲的身高 + 3”的经验；再用这个经验，对身高为 182 的父亲的孩子身高做出更合理、智能的决策结果。</p>
<p data-nodeid="43390">可见，人工智能的目标就是要做出更合理、智能的决策。它的途径是对数据的计算，当然数据量越多越好，这也是“大数据”的核心优势。它的产出结果就是经验，有时候也叫作模型。换句话说，<strong data-nodeid="43488">人工智能就是要根据输入的数据，来建立出效果最好的模型</strong>。</p>
<h3 data-nodeid="43391">人工智能建模框架的基本步骤</h3>
<p data-nodeid="43392">既然我们说，人工智能就是要建立模型，那究竟该怎么建立呢？有没有一些通用的方法或者步骤呢？</p>
<p data-nodeid="43393">答案是，有的。我们接下来，以前面预测孩子身高为例，再结合人工智能的定义，来试着总结出人工智能建立模型的步骤。</p>
<p data-nodeid="43394">人工智能要通过数据来建立模型，那么<strong data-nodeid="43501">数据</strong>是什么呢？其实，就是这三对父子的身高，这也是我们建模的输入。那么<strong data-nodeid="43502">模型</strong>又是什么呢？模型是用来做预测的经验，其实这就是基于某个输入的自变量，来预测与之对应的因变量的函数，即 y=f(x)。</p>
<p data-nodeid="43395">在这个例子中加了一个假设，那就是父子之间的身高关系是线性的，这就意味着 f(x) 有线性函数的表现形式，其通式是 kx+b，也就是说 y=f(x)=kx+b。</p>
<blockquote data-nodeid="43396">
<p data-nodeid="43397">当然，这个假设也可以是二次多项式的、指数型的。</p>
</blockquote>
<p data-nodeid="43398">此时可以发现，给定某个自变量 x 时，对因变量 y 的结果起到决定性作用的是参数 k 和 b。也就是说，模型的参数（k 和 b）与自变量 x，共同决定了因变量 y 的值。</p>
<p data-nodeid="43399">因此，有时候人们也喜欢把上面的模型写作 y=f(<i><strong data-nodeid="43529">w</strong></i>;x)。在这里<i><strong data-nodeid="43530">w</strong></i>就代表了模型的参数，它可以是个标量，也可能是个向量，取决于模型的参数有多少个。像此时有 k 和 b 两个参数，那么<i><strong data-nodeid="43531">w</strong></i>就是个向量，定义为 [k,b]。</p>
<p data-nodeid="43400"><strong data-nodeid="43535">人工智能的目标是要让模型预测的结果尽可能正确，而决定模型预测结果的就是模型的参数。因此，建模的过程更像是找到最合适的参数值，让模型的预测结果尽可能正确。</strong></p>
<p data-nodeid="43401">这句话有些隐讳，我们尝试用数学语言来描述它。</p>
<p data-nodeid="43402">围绕“模型预测结果尽可能正确”，就是说预测的结果和真实的结果之间的偏差尽可能小，我们就需要用一个数学式子来表达。在先前的课时中，我们提到过利用平方误差来描述两个值的偏差程度，即 (y<sub>1</sub>-y<sub>2</sub>)<sup>2</sup>，代入到这里就是 (y-ŷ)<sup>2</sup>。</p>
<p data-nodeid="43403">在例子中，我们有三对父子的数据，这样就有了 3 个预测结果和 3 个真实结果。我们用 L(w) 来表示这 3 条数据的平方误差之和，就有了 L(<i><strong data-nodeid="43597">w</strong></i>) = (y<sub>1</sub>-ŷ<sub>1</sub>)<sup>2</sup>+(y<sub>2</sub>-ŷ<sub>2</sub>)<sup>2</sup>+(y<sub>3</sub>-ŷ<sub>3</sub>)<sup>2</sup>。</p>
<p data-nodeid="43404">之所以用 L(<i><strong data-nodeid="43633">w</strong></i>) 来表示，是因为真实值 ŷ<sub>i</sub> 在数据集中是已知的；而预测值 y<sub>i</sub> = f(<i><strong data-nodeid="43634">w</strong></i>; x<sub>i</sub>) 中，x<sub>i</sub> 在数据集中也是已知的，目前只有<i><strong data-nodeid="43635">w</strong></i>这个模型参数是未知的。这样，我们就写出了“偏差”的函数。</p>
<p data-nodeid="43405">最后，人工智能的目标是模型尽可能准确，也就是要让“偏差尽可能小”，这就是求极值的问题，即计算 minL(<i><strong data-nodeid="43643">w</strong></i>)。</p>
<p data-nodeid="43406">我们建模的目标就是，建立出效果最好的模型。由于参数决定了模型的预测结果，效果最好就是偏差最小，也就是说建模的目标就是，要找到让偏差最小的参数值。用数学符号来表达就是<i><strong data-nodeid="43665">w</strong></i>*= argmin L(<i><strong data-nodeid="43666">w</strong></i>)，而<i><strong data-nodeid="43667">w</strong></i>*就是我们要建立的最佳模型。</p>
<h3 data-nodeid="43407"><strong data-nodeid="43671">人工智能建模框架的三个公式</strong></h3>
<p data-nodeid="43408">其实，不论是多么复杂的人工智能模型，其建模过程都是上面的过程，而上面的过程又可以凝练出三个标准路径，分别对应三个数学公式，它们分别如下。</p>
<ul data-nodeid="43409">
<li data-nodeid="43410">
<p data-nodeid="43411">第一步，根据假设，写出模型的输入、输出关系 y = f(<i><strong data-nodeid="43680">w</strong></i>; x)；</p>
</li>
<li data-nodeid="43412">
<p data-nodeid="43413">第二步，根据偏差的计算方法，写出描述偏差的损失函数 L(<i><strong data-nodeid="43688">w</strong></i>)；</p>
</li>
<li data-nodeid="43414">
<p data-nodeid="43415">第三步，对于损失函数，求解最优的参数值，即<i><strong data-nodeid="43703">w</strong></i>*= argmin L(<i><strong data-nodeid="43704">w</strong></i>)。</p>
</li>
</ul>
<blockquote data-nodeid="43416">
<p data-nodeid="43417">值得一提的是，前面所说的“偏差”，通常用损失函数这个专业名词来表达。</p>
</blockquote>
<p data-nodeid="43418">人工智能技术不断更新换代，但所有技术分支都在这三个步骤当中。不同种类的模型，其区别不外乎是这三个步骤实现方法的不同，下面我简单举例以下这种实现方式：</p>
<ul data-nodeid="43419">
<li data-nodeid="43420">
<p data-nodeid="43421">第一步的假设，可以由线性模型调整为高阶多项式的假设 y=ax<sup>2</sup>+bx+c；</p>
</li>
<li data-nodeid="43422">
<p data-nodeid="43423">第二步的损失函数，可以由平方误差调整为绝对值求和的误差，即 L(<i><strong data-nodeid="43763">w</strong></i>) = |y<sub>1</sub> - ŷ<sub>1</sub>| + |y<sub>2</sub> - ŷ<sub>2</sub>| + |y<sub>3</sub> - ŷ<sub>3</sub>|；</p>
</li>
<li data-nodeid="43424">
<p data-nodeid="43425">第三步的求解最优，可以采用求导法，也可以调整为梯度下降法，甚至可以用一些启发式方法求解。</p>
</li>
</ul>
<p data-nodeid="43426">不管这些实现细节如何调整，永远不变的就是这三个标准路径，这也是搭建最简 AI 模型的基本框架。</p>
<h3 data-nodeid="43427">用 AI 基本框架重新看“线性回归”</h3>
<p data-nodeid="43428">经过多年的发展，人工智能领域有很多被验证成熟可用的模型。在模块四后续的每一讲，我们会分别讲述当前技术发展阶段中，被人们公认效果最稳定普适的几个模型。</p>
<p data-nodeid="43429">在这一讲，先以我们都很熟悉的“<strong data-nodeid="43773">线性回归</strong>”为例，来验证一下基本框架。</p>
<ul data-nodeid="43430">
<li data-nodeid="43431">
<p data-nodeid="43432">第一步，根据假设，写出模型的输入、输出关系 y = f(<i><strong data-nodeid="43781">w</strong></i>; x)。我们假设是线性模型，则有</p>
</li>
</ul>
<p data-nodeid="43433">y = kx + b。</p>
<ul data-nodeid="43434">
<li data-nodeid="43435">
<p data-nodeid="43436">第二步，根据偏差的计算方法，写出描述偏差的损失函数 L(<i><strong data-nodeid="43790">w</strong></i>)。我们选择平方误差，则有</p>
</li>
</ul>
<p data-nodeid="43437">L(<i><strong data-nodeid="43870">w</strong></i>) = (y<sub>1</sub> - ŷ<sub>1</sub>)<sup>2</sup> + (y<sub>2</sub> - ŷ<sub>2</sub>)<sup>2</sup> + (y<sub>3</sub> - ŷ<sub>3</sub>)<sup>2</sup>。其中<i><strong data-nodeid="43871">w</strong></i>= [k,b]，我们再把 y=kx+b 和三对父子的实际身高 x<sub>i</sub>、ŷ<sub>i</sub> 代入上式，则有 L(k,b) = (173k+b-170)<sup>2</sup> + (170k+b-176)<sup>2</sup> + (176k+b-182)<sup>2</sup>。</p>
<ul data-nodeid="43438">
<li data-nodeid="43439">
<p data-nodeid="43440">第三步，对于损失函数，求解最优的参数值，即<i><strong data-nodeid="43886">w</strong></i>*= argmin L(<i><strong data-nodeid="43887">w</strong></i>)。为了求解函数的极小值，我们考虑计算损失函数关于 k 和 b 的导数，则有</p>
</li>
</ul>
<p data-nodeid="43441"><img src="https://s0.lgstatic.com/i/image/M00/8B/D4/Ciqc1F_higiAQVKuAACjOhtEoaQ832.png" alt="Lark20201222-135249.png" data-nodeid="43890"></p>
<p data-nodeid="43442">我们用求导法来计算函数最小值，则令这两个偏导数为零并解方程，则有 179610k+1038b-182724=0 和 1038k+6b-1056=0，求得 k=1，b=3，这个结果与刚刚用 Excel 的计算结果完全一致。</p>
<p data-nodeid="43443"><strong data-nodeid="43895">这个例子就是对“线性回归”另一个视角的解读。你也可以理解为，线性回归就是一种最基础的人工智能模型。</strong></p>
<blockquote data-nodeid="43444">
<p data-nodeid="43445">线性回归具体的代码实现，你可以参考《07 | 线性回归：如何在离散点中寻找数据规律？》写出公式后，直接打印就能得到结果，这几乎没有什么开发成本。在此，我就不再重复赘述了。</p>
</blockquote>
<h3 data-nodeid="43446">小结</h3>
<p data-nodeid="43447">最后，我们对这一讲进行总结。这一讲是模块四的开胃菜，我们通过一个预测身高这样一个最简单的例子，以小见大，认识了人工智能模型的建模过程和基本本质。</p>
<p data-nodeid="43448">人工智能的目标是做出更合理、更智能的决策，它的途径是对数据进行计算，从而输出结果，并将这一结果叫作模型。<strong data-nodeid="43905">用一句话来概括，人工智能就是要根据输入的数据，来建立出效果最好的模型。</strong></p>
<p data-nodeid="43449">人工智能的建模过程通常包括下面三个步骤：</p>
<ul data-nodeid="43450">
<li data-nodeid="43451">
<p data-nodeid="43452">第一步，根据假设，写出模型的输入输出关系 y = f(<i><strong data-nodeid="43914">w</strong></i>; x)；</p>
</li>
<li data-nodeid="43453">
<p data-nodeid="43454">第二步，根据偏差的计算方法，写出描述偏差的损失函数 L(<i><strong data-nodeid="43922">w</strong></i>)；</p>
</li>
<li data-nodeid="43455">
<p data-nodeid="43456">第三步，对于损失函数，求解最优的参数值，即<i><strong data-nodeid="43937">w</strong></i>*= argmin L(<i><strong data-nodeid="43938">w</strong></i>)。</p>
</li>
</ul>
<p data-nodeid="43457">人工智能发展到今天，很多成型的复杂的模型，都是对这三个步骤实现细节的优化。</p>
<p data-nodeid="43458">最后，我们留一个练习。在上面求解 k 和 b 的线性回归问题中，我们采用了求导法来计算。现在试着再用一下梯度下降法来求解，并写出代码吧。</p>
<p data-nodeid="43459">我们给出几个提示，梯度下降法需要计算梯度，也就是偏导数；接着随机初始个 k<sub>0</sub> 和 b<sub>0</sub>，每一轮用梯度的值乘以学习率来更新 k 和 b。我们在这一模块的后续章节中，会高频使用到梯度下降法。</p>
<blockquote data-nodeid="43460">
<p data-nodeid="43461">建议你回顾一下《05 | 求极值：如何找到复杂业务的最优解？》中对“梯度下降发”的详细讲解。</p>
</blockquote>
<p data-nodeid="44537">下一讲，我将向你讲解《19 | 逻辑回归：如何让计算机做出二值化决策？》，别忘来听课～</p>
<hr data-nodeid="44538">
<p data-nodeid="44539" class="te-preview-highlight"><a href="https://wj.qq.com/s2/7812549/4cd8/" data-nodeid="44545">课程评价入口，挑选 5 名小伙伴赠送小礼品～</a></p>

---

### 精选评论


