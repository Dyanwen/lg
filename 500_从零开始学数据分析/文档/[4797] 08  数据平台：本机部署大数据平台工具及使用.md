<p data-nodeid="4455">你好，我是取经儿。上一课时我带你学习了快速搭建 BI 平台来构建报表。本课时我将手把手教你在本地电脑安装离线大数据处理工具 Hive。Hive 也是数据分析师最常使用的工具。在本机部署Hive ，可以帮助没有数据工作经验的同学快速上手。而对于已经参加工作的数据分析师来讲，本地 Hive 在语法的测试验证方面也会更方便快速。</p>


<p data-nodeid="3800">下面我们讲下如何在本地 Linux 或者 MacOS 安装 Hive。</p>
<h3 data-nodeid="3801">Hive 安装流程</h3>
<p data-nodeid="3802">Linux 或 MacOS 安装 Hive主要依赖以下环境：</p>
<ul data-nodeid="3803">
<li data-nodeid="3804">
<p data-nodeid="3805">Java；</p>
</li>
<li data-nodeid="3806">
<p data-nodeid="3807">Hadoop；</p>
</li>
<li data-nodeid="3808">
<p data-nodeid="3809">MySQL；</p>
</li>
<li data-nodeid="3810">
<p data-nodeid="3811">MySQL-Connector。</p>
</li>
</ul>
<p data-nodeid="3812">首先 Hive 是 Hadoop 生态系统数据仓库工具。Hive 运行依赖 Java 环境，属于 Hadoop 重要组件。 同时，Hive 元数据一般使用 MySQL 来存储，所以在安装 Hive 之前需要先安装 Java、Hadoop、MySQL 。</p>
<p data-nodeid="3813">注意：本课时涉及安装下载的软件，为了方便，我会为你提供两种方式下载。第一种是官网下载链接；第二种是我出于速度考虑，特意帮你准备的百度网盘下载链接。</p>
<p data-nodeid="3814">下面我们一步一步部署本机安装 Hive 所需要的环境。</p>
<h4 data-nodeid="3815">第一步：安装 JDK。</h4>
<p data-nodeid="3816">先检查本机是否安装 Java。使用下面命令，如果显示 Java 版本在 1.8 以上，即可继续第二步安装。</p>
<pre class="lang-powershell" data-nodeid="3817"><code data-language="powershell">workindata:local qujinger<span class="hljs-variable">$</span> java <span class="hljs-literal">-version</span>
java version <span class="hljs-string">"1.8.0_261"</span>
Java(TM) SE Runtime Environment (build <span class="hljs-number">1.8</span>.<span class="hljs-number">0</span>_261<span class="hljs-literal">-b12</span>)
Java HotSpot(TM) <span class="hljs-number">64</span><span class="hljs-literal">-Bit</span> Server VM (build <span class="hljs-number">25.261</span><span class="hljs-literal">-b12</span>, mixed mode)
</code></pre>
<p data-nodeid="3818">如果本机未安装 Java，则按下面步骤先安装 Java。</p>
<p data-nodeid="4891" class="">1.下载 JDK。</p>
<ul data-nodeid="7714">
<li data-nodeid="7715">
<p data-nodeid="7716"><a href="https://www.oracle.com/java/technologies/javase/javase-jdk8-downloads.html" data-nodeid="7804">方式一：JDK 官网下载</a>。</p>
</li>
<li data-nodeid="7717">
<p data-nodeid="7718"><a href="https://pan.baidu.com/s/1gIbsNywganTA5q26cpYcEA" data-nodeid="7808">方式二：JDK 百度网盘</a>（密码：okb7）。</p>
</li>
</ul>
<p data-nodeid="7719" class="">2.解压JDK并将解压文件夹移动到 /usr/local。</p>
<pre class="lang-powershell" data-nodeid="7720"><code data-language="powershell">tar <span class="hljs-literal">-xvf</span> jdk<span class="hljs-literal">-8u161</span><span class="hljs-literal">-linux</span><span class="hljs-literal">-x64</span>.tar.gz <span class="hljs-literal">-C</span> /usr/local
</code></pre>
<p data-nodeid="7721">3.配置环境变量。</p>
<pre class="lang-powershell" data-nodeid="7722"><code data-language="powershell"><span class="hljs-comment"># 输入下面命令, 打开.bashrc 文件</span>
vim ~/.bashrc
<span class="hljs-comment"># 在文件.bashrc 中添加下面代码</span>
<span class="hljs-comment"># 配置 JAVA 环境</span>
export JAVA_HOME=/usr/local/Java/jdk1.<span class="hljs-number">8.0</span>_181/
export JRE_HOME=<span class="hljs-variable">$JAVA_HOME</span>/jre
export PATH=<span class="hljs-variable">$JAVA_HOME</span>/bin:<span class="hljs-variable">$JRE_HOME</span>/bin:<span class="hljs-variable">$PATH</span>
export CLASSPATH=<span class="hljs-variable">$JAVA_HOME</span>/lib:<span class="hljs-variable">$JRE_HOME</span>/lib:.
<span class="hljs-comment"># 保存.bashrc 后退出, 然后用下面命令生效配置</span>
source ~/.bashrc
</code></pre>
<p data-nodeid="8885" class="">4.测试 Java 环境生效。</p>
<pre class="lang-powershell" data-nodeid="8886"><code data-language="powershell"><span class="hljs-comment"># 测试 Java 安装命令，如下，命令行输入代码: java -version</span>
workindata:local qujinger<span class="hljs-variable">$</span> java <span class="hljs-literal">-version</span>
java version <span class="hljs-string">"1.8.0_261"</span>
Java(TM) SE Runtime Environment (build <span class="hljs-number">1.8</span>.<span class="hljs-number">0</span>_261<span class="hljs-literal">-b12</span>)
Java HotSpot(TM) <span class="hljs-number">64</span><span class="hljs-literal">-Bit</span> Server VM (build <span class="hljs-number">25.261</span><span class="hljs-literal">-b12</span>, mixed mode)
</code></pre>
<p data-nodeid="8887">以上过程后，本机便顺利安装上了 Java 环境，下面我们来安装 Hadoop。</p>
<h4 data-nodeid="8888">第二步：安装 Hadoop。</h4>
<p data-nodeid="8889">Hive 运行依赖于 Hadoop 工作环境，所以需要先在本机搭建 Hadoop 环境，以下是介绍如何在本机上搭建 Hadoop 环境。</p>
<p data-nodeid="8890">首先，下载 Hadoop，并解压到/usr/local路径里。</p>
<ul data-nodeid="8891">
<li data-nodeid="8892">
<p data-nodeid="8893"><a href="https://hadoop.apache.org/releases.html" data-nodeid="8969">方式一：Hadoop官网下载</a>（选择 Binary 文件进行下载）。</p>
</li>
<li data-nodeid="8894">
<p data-nodeid="8895"><a href="https://pan.baidu.com/s/1gIbsNywganTA5q26cpYcEA" data-nodeid="8973">方式二：百度网盘</a>（密码：okb7）。</p>
</li>
</ul>
<pre class="lang-powershell" data-nodeid="8896"><code data-language="powershell">sudo tar <span class="hljs-literal">-zxf</span> ./hadoop<span class="hljs-literal">-3</span>.<span class="hljs-number">2.1</span>.tar.gz <span class="hljs-literal">-C</span> /usr/local
</code></pre>
<p data-nodeid="9455" class="">1.设置环境变量。</p>
<pre class="lang-powershell" data-nodeid="9456"><code data-language="powershell"><span class="hljs-comment"># 输入下面命令, 打开.bashrc文件</span>
vim ~/.bashrc
<span class="hljs-comment"># 添加如下代码</span>
export HADOOP_HOME=/usr/local/hadoop
export PATH=<span class="hljs-variable">$PATH:</span>/usr/local/hadoop/bin
export PATH=<span class="hljs-variable">$PATH:</span>/usr/local/hadoop/sbin
<span class="hljs-comment"># 保存.bashrc后退出, 然后用下面命令生效配置</span>
source ~/.bashrc
</code></pre>
<p data-nodeid="9994" class="">2.检测 Hadoop 安装状态。</p>
<pre class="lang-powershell" data-nodeid="9995"><code data-language="powershell">workindata:local qujinger<span class="hljs-variable">$</span> hadoop version
Hadoop <span class="hljs-number">3.2</span>.<span class="hljs-number">1</span>
Source code repository https://gitbox.apache.org/repos/asf/hadoop.git <span class="hljs-literal">-r</span> b3cbbb467e22ea829b3808f4b7b01d07e0bf3842
Compiled by rohithsharmaks on <span class="hljs-number">2019</span><span class="hljs-literal">-09</span><span class="hljs-literal">-10T15</span>:<span class="hljs-number">56</span>Z
Compiled with protoc <span class="hljs-number">2.5</span>.<span class="hljs-number">0</span>
From source with checksum <span class="hljs-number">776</span>eaf9eee9c0ffc370bcbc1888737
This command was run <span class="hljs-keyword">using</span> /usr/local/hadoop/share/hadoop/common/hadoop-common-3.2.1.jar
</code></pre>
<p data-nodeid="9996">以上为安装 Hadoop 步骤。在 Hadoop 配置完成后，下一步安装 MySQL，用于 Hive 元数据管理。</p>
<h4 data-nodeid="9997">第三步：安装 MySQL。</h4>
<p data-nodeid="9998">在 CentOS 系统中安装 MySQL，安装步骤可以参考 07 课时《07 一小时搭建可视化 BI 数据平台》，我在那一课时中介绍了为 CentOS 系统安装 MySQL 的步骤。</p>
<p data-nodeid="9999">在 MacOS 系统中安装 MySQL，则要先下载安装包。</p>
<ul data-nodeid="10000">
<li data-nodeid="10001">
<p data-nodeid="10002"><a href="https://dev.mysql.com/downloads/mysql/" data-nodeid="10060">方式一：官网下载</a>（选择 DMG 格式下载）。</p>
</li>
<li data-nodeid="10003">
<p data-nodeid="10004"><a href="https://pan.baidu.com/s/1gIbsNywganTA5q26cpYcEA" data-nodeid="10064">方式二：百度网盘</a>（密码：okb7）。</p>
</li>
</ul>
<p data-nodeid="10926">下载完后需要进行安装。这时候，按照提示一步步安装即可：</p>
<p data-nodeid="10927" class=""><img src="https://s0.lgstatic.com/i/image/M00/62/1E/Ciqc1F-RVPSATinnAAKgksQ7PBY808.png" alt="image (1).png" data-nodeid="10935"></p>


<p data-nodeid="10007">注意：MacOS 安装 MySQL 完成后要启动 MySQL。以下是 MacOS 系统启动、停止、重启 MySQL 服务的命令。</p>
<pre class="lang-powershell" data-nodeid="10008"><code data-language="powershell"><span class="hljs-comment"># 启动 MySQL 服务</span>
sudo /usr/local/MySQL/support<span class="hljs-literal">-files</span>/mysql.server <span class="hljs-built_in">start</span>
<span class="hljs-comment">#&nbsp;停止 MySQL 服务</span>
sudo /usr/local/mysql/support<span class="hljs-literal">-files</span>/mysql.server stop
<span class="hljs-comment">#&nbsp;重启 MySQL 服务</span>
sudo /usr/local/mysql/support<span class="hljs-literal">-files</span>/mysql.server restart
</code></pre>
<p data-nodeid="10009">安装完成后，我们需要在 MySQL 创建新用户。新用户的用户名和密码都设置为 Hive。操作命令如下：</p>
<pre class="lang-powershell" data-nodeid="10010"><code data-language="powershell"><span class="hljs-comment"># Root 账户登录 MySQL</span>
mysql <span class="hljs-literal">-uroot</span> <span class="hljs-literal">-p</span> 
<span class="hljs-comment"># 新增用户</span>
mysql&gt; create user <span class="hljs-string">'hive'</span><span class="hljs-string">@'%' identified by 'hive';
mysql&gt; grant all on *.* to hive@localhost identified by 'hive';   
# 后面的 hive 是配置 hive-site.xml 中配置的连接密码
mysql&gt; flush privileges;  
# 刷新权限
</span></code></pre>
<h4 data-nodeid="10011">第四步：下载 Hive 安装软件。</h4>
<ul data-nodeid="10012">
<li data-nodeid="10013">
<p data-nodeid="10014"><a href="http://www.apache.org/dyn/closer.cgi/hive/" data-nodeid="10075">方式一：官网下载</a>。</p>
</li>
<li data-nodeid="10015">
<p data-nodeid="10016"><a href="https://pan.baidu.com/s/1bTNYlPJqSmTlnsx3fKP09w" data-nodeid="10079">方式二：百度网盘</a>（密码：fvfk）。</p>
</li>
</ul>
<p data-nodeid="10017">解压 Hive 安装包并移动到 /usr/local 中即可。</p>
<pre class="lang-powershell" data-nodeid="10018"><code data-language="powershell">sudo tar <span class="hljs-literal">-zxvf</span> ./apache<span class="hljs-literal">-hive</span><span class="hljs-literal">-3</span>.<span class="hljs-number">1.2</span><span class="hljs-literal">-bin</span>.tar.gz 
sudo <span class="hljs-built_in">mv</span> apache<span class="hljs-literal">-hive</span><span class="hljs-literal">-3</span>.<span class="hljs-number">1.2</span><span class="hljs-literal">-bin</span> /usr/local/  -- <span class="hljs-built_in">copy</span>到/usr/local目录
sudo <span class="hljs-built_in">mv</span> apache<span class="hljs-literal">-hive</span><span class="hljs-literal">-3</span>.<span class="hljs-number">1.2</span><span class="hljs-literal">-bin</span> hive       <span class="hljs-comment"># 将文件夹名改为 hive</span>
</code></pre>
<h4 data-nodeid="10019">第五步：配置环境变量。</h4>
<pre class="lang-powershell" data-nodeid="10020"><code data-language="powershell"><span class="hljs-comment"># 输入下面命令，打开.bashrc 文件</span>
vim ~/.bashrc
<span class="hljs-comment"># 添加如下代码</span>
<span class="hljs-comment"># Hive 环境变量</span>
export HIVE_HOME=/usr/local/hive
export PATH=<span class="hljs-variable">$PATH:</span><span class="hljs-variable">$HIVE_HOME</span>/bin
export HADOOP_HOME=/usr/local/hadoop
<span class="hljs-comment"># 保存.bashrc 后退出，然后用下面命令生效配置</span>
source ~/.bashrc
</code></pre>
<h4 data-nodeid="10021">第六步：下载 mysql-connector-java.jar。</h4>
<ul data-nodeid="10022">
<li data-nodeid="10023">
<p data-nodeid="10024"><a href="https://dev.mysql.com/downloads/connector/j/" data-nodeid="10086">方式一：官网下载</a>。</p>
</li>
<li data-nodeid="10025">
<p data-nodeid="10026"><a href="https://pan.baidu.com/s/1hkAENQCqliGvKa1zckFvbg" data-nodeid="10090">方式二：百度网盘</a>（密码：8s0s）。</p>
</li>
</ul>
<p data-nodeid="10027">下面将下载的jar文件Copy到路径/usr/local/hive/lib 中。</p>
<pre class="lang-powershell" data-nodeid="10028"><code data-language="powershell"><span class="hljs-built_in">cp</span> mysql<span class="hljs-literal">-connector</span><span class="hljs-literal">-java</span><span class="hljs-literal">-8</span>.<span class="hljs-number">0.21</span>.jar /usr/local/hive/lib
</code></pre>
<h4 data-nodeid="10029">第七步：启动 Hive。</h4>
<pre class="lang-powershell" data-nodeid="10030"><code data-language="powershell"><span class="hljs-comment"># 启动 Hive 前，先启动 Hadoop</span>
<span class="hljs-variable">$</span> <span class="hljs-built_in">start-dfs</span>.sh
<span class="hljs-variable">$</span> <span class="hljs-variable">$</span> hive
SLF4J: <span class="hljs-class"><span class="hljs-keyword">Class</span> <span class="hljs-title">path</span> <span class="hljs-title">contains</span> <span class="hljs-title">multiple</span> <span class="hljs-title">SLF4J</span> <span class="hljs-title">bindings</span>.
...
...
<span class="hljs-title">Logging</span> <span class="hljs-title">initialized</span> <span class="hljs-title">using</span> <span class="hljs-title">configuration</span> ...
<span class="hljs-title">Loading</span> <span class="hljs-title">class</span> `<span class="hljs-title">com</span>.<span class="hljs-title">mysql</span>.<span class="hljs-title">jdbc</span>.<span class="hljs-title">Driver</span>'. ...
<span class="hljs-title">Hive</span> <span class="hljs-title">Session</span> <span class="hljs-title">ID</span> = <span class="hljs-title">fbeb3b3b</span>-23<span class="hljs-title">d6</span>-41<span class="hljs-title">e0</span>-<span class="hljs-title">bbd2</span>-8563<span class="hljs-title">f623ed29</span>
<span class="hljs-title">Hive</span>-<span class="hljs-title">on</span>-<span class="hljs-title">MR</span> <span class="hljs-title">is</span> <span class="hljs-title">deprecated</span> <span class="hljs-title">in</span> <span class="hljs-title">Hive</span> 2 <span class="hljs-title">and</span> ...
<span class="hljs-title">hive</span>&gt;
</span></code></pre>
<p data-nodeid="10031">启动 Hive 的过程中，可能遇到一些问题。经哥将这些问题和解决方法进行了汇总。感兴趣的同学可以去下面的链接看一看：<br>
<a href="http://www.shangdixinxi.com/detail-1151470.html" data-nodeid="10098">解决 Hive 启动报错：java.lang.NoSuchMethodError: com.google.common.base.Preconditions.checkArgument</a>。</p>
<p data-nodeid="10032">这通常是因为 Hive 内依赖的 guava.jar 和 Hadoop 内依赖的 guava.jar 版本不一致造成的。</p>
<pre class="lang-powershell" data-nodeid="10033"><code data-language="powershell"> <span class="hljs-comment"># 查看 Hadoop guava.jar 版本命令，发现版本：guava-27.0-jre.jar</span>
ll /usr/local/hadoop/share/hadoop/common/lib | grep guava
<span class="hljs-literal">-rw</span><span class="hljs-literal">-r</span>-<span class="hljs-literal">-r</span>--<span class="hljs-selector-tag">@</span> <span class="hljs-number">1</span> <span class="hljs-number">1001</span>  <span class="hljs-number">1001</span>  <span class="hljs-number">2747878</span>  <span class="hljs-number">9</span> <span class="hljs-number">10</span>  <span class="hljs-number">2019</span> guava<span class="hljs-literal">-27</span>.<span class="hljs-number">0</span><span class="hljs-literal">-jre</span>.jar
<span class="hljs-comment"># Hive 中 guava 版本低</span>
ll /usr/local/hive/lib | grep guava
<span class="hljs-literal">-rw</span><span class="hljs-literal">-r</span>-<span class="hljs-literal">-r</span>--<span class="hljs-selector-tag">@</span> <span class="hljs-number">1</span> qujinger  staff   <span class="hljs-number">2308517</span>  <span class="hljs-number">9</span> <span class="hljs-number">27</span>  <span class="hljs-number">2018</span> guava<span class="hljs-literal">-19</span>.<span class="hljs-number">0</span>.jar
<span class="hljs-comment"># 解决方法：</span>
<span class="hljs-comment"># 将 Hadoop 中高版本 guava 包，cp 到 Hive 路径下, 并删除 Hive 路径下低版本包: </span>
<span class="hljs-built_in">cp</span> /usr/local/hadoop/share/hadoop/common/lib/guava<span class="hljs-literal">-27</span>.<span class="hljs-number">0</span><span class="hljs-literal">-jre</span>.jar /usr/local/hive/lib/
<span class="hljs-built_in">rm</span> /usr/local/hive/lib/guava<span class="hljs-literal">-19</span>.<span class="hljs-number">0</span>.jar
</code></pre>
<ul data-nodeid="10034">
<li data-nodeid="10035">
<p data-nodeid="10036">解决 Hive 启动报错：metadata.SessionHiveMetaStoreClient，参考 stackoverflow 网站一个<a href="https://stackoverflow.com/questions/35449274/java-lang-runtimeexception-unable-to-instantiate-org-apache-hadoop-hive-ql-meta" data-nodeid="10104">解决方法</a>。</p>
</li>
</ul>
<pre class="lang-powershell" data-nodeid="10037"><code data-language="powershell"> <span class="hljs-comment"># 由于我们使用 MySQL 管理 Hive 元数据库, 我们需要初始化下:</span>
 <span class="hljs-variable">$</span> <span class="hljs-built_in">cd</span> /usr/local/hive/bin
 <span class="hljs-variable">$</span> ./schematool <span class="hljs-literal">-dbType</span> mysql <span class="hljs-literal">-initSchema</span>  
 <span class="hljs-variable">$</span> ./schematool <span class="hljs-literal">-dbType</span> mysql <span class="hljs-literal">-info</span>
 <span class="hljs-comment"># 再运行 Hive, 并执行 show databases 命令就没有问题了</span>
</code></pre>
<ul data-nodeid="10038">
<li data-nodeid="10039">
<p data-nodeid="10040">Hive 创建数据库报错：Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask。</p>
</li>
</ul>
<pre class="lang-powershell" data-nodeid="10041"><code data-language="powershell"><span class="hljs-comment"># Hive 运行：create database tmp_db2; 报错如下：</span>
hive&gt; create database tmp_db2;
FAILED: Execution Error, <span class="hljs-keyword">return</span> code <span class="hljs-number">1</span> from org.apache.hadoop.hive.ql.exec.DDLTask. MetaException(message:Unable to create database path file:/user/hive/warehouse/tmp_db2.db, failed to create database tmp_db2)

<span class="hljs-comment"># 在 Hadoop 中创建 Hive 所需的仓库：</span>
hadoop fs <span class="hljs-literal">-mkdir</span>   <span class="hljs-literal">-p</span>  /user/hive/warehouse
<span class="hljs-comment"># 将/user 路径及其子路径授权给当前登录用户。比如我当前登录用户名为：qujinger, 则运行下面命令：</span>
sudo chown <span class="hljs-literal">-R</span> qujinger:wheel /user
<span class="hljs-comment"># 设置完 Hive 本地仓库以及授权后, 再运行 Hive 创建数据库命令, 执行正常</span>
hive&gt; create database tmp_db2;
OK
Time taken: <span class="hljs-number">0.333</span> seconds
hive&gt; show databases;
OK
default
tmp_db2
Time taken: <span class="hljs-number">0.513</span> seconds, Fetched: <span class="hljs-number">2</span> row(s)
</code></pre>
<h4 data-nodeid="10042">第八步：创建本地 Hive 外表。</h4>
<p data-nodeid="10043">由于是本机安装，因此我们没有真正分布式的 HDFS 文件，这时候需要根据本地文件来制定Hive 外表。</p>
<pre class="lang-powershell" data-nodeid="10044"><code data-language="powershell"><span class="hljs-comment"># 测试数据在本地/tmp/test_data.txt, 我们查看前 3 行：</span>
<span class="hljs-built_in">cat</span> /tmp/test_data.txt |head <span class="hljs-literal">-3</span>
<span class="hljs-number">2019</span>/<span class="hljs-number">10</span>/<span class="hljs-number">1</span>	<span class="hljs-number">1</span>	<span class="hljs-number">51</span>
<span class="hljs-number">2019</span>/<span class="hljs-number">10</span>/<span class="hljs-number">2</span>	<span class="hljs-number">2</span>	<span class="hljs-number">49</span>
<span class="hljs-number">2019</span>/<span class="hljs-number">10</span>/<span class="hljs-number">3</span>	<span class="hljs-number">3</span>	<span class="hljs-number">50</span>
</code></pre>
<p data-nodeid="10045">这里需要使用 Hadoop 命令 HDFS 来创建目录以及将测试数据 Copy 到指定路径，用于生成 Hive 外表。注意：必须使用 Hadoop 命令进行，如果使用本地 Shell 命令 Copy 数据，无法完成表创建和使用。</p>
<pre class="lang-powershell" data-nodeid="10046"><code data-language="powershell"><span class="hljs-variable">$</span> hdfs dfs <span class="hljs-literal">-mkdir</span> <span class="hljs-literal">-p</span> /usr/local/hive/tmp_db/order_info   <span class="hljs-comment"># 创建临时数据库</span>
<span class="hljs-variable">$</span> hdfs dfs <span class="hljs-literal">-cp</span> /tmp/test_data2 /usr/local/hive/tmp_db/order_info
<span class="hljs-comment"># 根据本地文件创建外表使用：</span>
hive&gt; CREATE EXTERNAL TABLE order_info (dt string, id int, order_num int)
    &gt; COMMENT <span class="hljs-string">'user orders'</span>
    &gt; ROW FORMAT DELIMITED FIELDS TERMINATED BY <span class="hljs-string">'\t'</span>
    &gt; STORED AS TEXTFILE
    &gt; LOCATION <span class="hljs-string">'/usr/local/hive/tmp_db/order_info'</span>;
OK
Time taken: <span class="hljs-number">0.086</span> seconds
</code></pre>
<h4 data-nodeid="11354">第九步：本地 Hive 进行基础统计。</h4>


<p data-nodeid="10049">下面我们就可以利用本机安装的 Hive 进行数据统计了。你可以尝试统计上面新建表的数据，比如：统计表格中的每月订单量。</p>
<pre class="lang-powershell" data-nodeid="10050"><code data-language="powershell"><span class="hljs-comment"># 设置运行结果, 同时输出字段名称</span>
hive&gt; <span class="hljs-built_in">set</span> hive.cli.print.header=true;
<span class="hljs-comment"># 运行 SQL, 统计每月订单总和, 单天最小订单量和最大订单量</span>
hive&gt; <span class="hljs-built_in">select</span> split(dt, <span class="hljs-string">'/'</span>)[<span class="hljs-number">1</span>] as dt, sum(order_num) order_num, min(order_num) as min_order_num, max(order_num) as max_order_num from order_info <span class="hljs-built_in">group</span> by split(dt, <span class="hljs-string">'/'</span>)[<span class="hljs-number">1</span>] order by dt;
Query ID = qujinger_20201018120317_c81beb8f<span class="hljs-literal">-8c55</span><span class="hljs-literal">-4869</span><span class="hljs-literal">-aa75</span><span class="hljs-literal">-9d510026a1b3</span>
Total jobs = <span class="hljs-number">2</span>
Launching Job <span class="hljs-number">1</span> out of <span class="hljs-number">2</span>
Number of reduce tasks not specified. Estimated from input <span class="hljs-keyword">data</span> size: <span class="hljs-number">1</span>
...
...
<span class="hljs-number">2020</span><span class="hljs-literal">-10</span><span class="hljs-literal">-18</span> <span class="hljs-number">12</span>:<span class="hljs-number">03</span>:<span class="hljs-number">20</span>,<span class="hljs-number">995</span> Stage<span class="hljs-literal">-2</span> map = <span class="hljs-number">100</span>%,  reduce = <span class="hljs-number">100</span>%
Ended Job = job_local183869176_0006
...
Total MapReduce CPU Time Spent: <span class="hljs-number">0</span> msec
OK
dt	order_num	min_order_num	max_order_num
<span class="hljs-number">10</span>	<span class="hljs-number">2091</span>	<span class="hljs-number">45</span>	<span class="hljs-number">90</span>
<span class="hljs-number">11</span>	<span class="hljs-number">2189</span>	<span class="hljs-number">57</span>	<span class="hljs-number">98</span>
Time taken: <span class="hljs-number">3.226</span> seconds, Fetched: <span class="hljs-number">2</span> row(s)
</code></pre>
<p data-nodeid="10051">经过以上步骤，想必你已经在本机成功安装了 Hive。现在，你可以在本地创建数据库和表格，并对其进行基础统计，从而进行练习，加深学习效果。在这个过程中，你也可以及对 Hive 基础语法、函数进行学习和巩固练习了。</p>
<h3 data-nodeid="10052">总结</h3>

---

### 精选评论

##### **琨：
> windows下不能配置么，windows有什么办法进行学习

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 其实也可以，但不建议在Windows系统学习这部分内容。公司生产环境几乎都是Linux为主，可以本机安装Ubuntu系统，来了解和学习下Linux系统。

##### *伦：
> 所以到底是用spark还是用什么BI还是用这个Hive？没有重点的吗

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; Hive和Spark属于数据处理工具，工作中，不同场景使用不同工具，一般来讲Hive目前比较普及，使用更多。BI可以理解为数据报表系统，就是把公司最常用的指标放到一些网页上，可以很直观的看到核心业务的数据指标以及趋势。

##### **昊：
> hive 貌似不支持jdk9 以上，怎么办

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; rm 删除，重新安装jdk8

