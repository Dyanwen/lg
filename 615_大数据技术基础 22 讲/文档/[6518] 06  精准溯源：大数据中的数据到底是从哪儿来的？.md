<p data-nodeid="1189" class="">如果说把我们的大数据看成是石油加工的过程，那么在整个大数据的流程中，我们的数据采集工作就相当于石油的开采。数据就在源源不断地生产着，如果我们不对其进行采集，那么我们后续的环节也不复存在，所以做好<strong data-nodeid="1279">数据采集</strong>是一个非常良好的开端。</p>
<p data-nodeid="1190">在数据采集阶段，我们的任务就是要从业务场景中获取原始数据，并把这些数据收集聚合起来，传输到我们的服务器上进行存储。常见的数据采集方式有三种。</p>
<h3 data-nodeid="1191">传感器</h3>
<p data-nodeid="1192">比如我们前面介绍的天气数据就需要放置很多传感器，用气压、温度、风力等传感器，不停地收集数据。在互联网公司的产品中也不乏基于传感器的数据采集：</p>
<ul data-nodeid="1193">
<li data-nodeid="1194">
<p data-nodeid="1195">手机上的指纹开屏；</p>
</li>
<li data-nodeid="1196">
<p data-nodeid="1197">使用指纹进行支付；</p>
</li>
<li data-nodeid="1198">
<p data-nodeid="1199">微信步数的采集；</p>
</li>
<li data-nodeid="1200">
<p data-nodeid="1201">各种手环和运动手表等还可以监测心率；</p>
</li>
<li data-nodeid="1202">
<p data-nodeid="1203">……</p>
</li>
</ul>
<p data-nodeid="1204">传感器采集主要依赖于各种各样的<strong data-nodeid="1293">硬件设施</strong>，而在当前互联网中主要依赖硬件采集信息的还是比较少的。</p>
<h3 data-nodeid="1205">爬虫采集</h3>
<p data-nodeid="1206">顾名思义，爬虫采集是通过一套程序去互联网上获取数据的方法。如果把一个互联网公司的数据划分成<strong data-nodeid="1308">站内数据</strong>和<strong data-nodeid="1309">站外数据</strong>，那么爬虫所获取的都属于站外数据。很多时候我们要做一些任务，只依赖自己的数据是不够的，而互联网上存在着大量开放的数据，通过爬虫系统可以获取很多有益于我们工作的数据。当然，使用爬虫来爬取数据一定要<strong data-nodeid="1310">注意法律风险</strong>，很多公司的数据是禁止爬取的，在具体操作的时候一定不要触碰法律的红线。</p>
<h3 data-nodeid="1207">日志采集</h3>
<p data-nodeid="1208">最重要的一种数据采集的方式就是日志采集。在这个移动互联网的时代，基本上每个互联网公司的输出都以手机 App 为主要的承载形式。阿里巴巴有淘宝、1688、饿了么等多个 App；字节跳动有抖音、今日头条、懂车帝等多个 App。用户在这些 App 上产生各种行为和活动，我们需要在代码中重点标记所需的行为记录，并把它们作为“日志”传输到服务器上。</p>
<p data-nodeid="1209">跟硬件传感器相比，<strong data-nodeid="1318">日志记录可以看作是一种软件传感器</strong>，依托手机 App 就可以实现，这通常是现在的互联网公司获取“站内数据”的主流方式。下图就是一个典型的日志采集场景：</p>
<p data-nodeid="2694" class=""><img src="https://s0.lgstatic.com/i/image6/M00/04/80/CioPOWAsytuAeCwzAASCs7riCJY163.png" alt="图片1.png" data-nodeid="2697"></p>



<p data-nodeid="1211" class="">用户在淘宝上浏览商品，点击下单支付，这些信息都通过日志的形式从前端传递到后端并通过网络输送到公司的服务器上，最终存储在数据库里。有了这些数据，公司又可以对用户进行分析，进一步推荐你可能感兴趣的商品并呈现在 App 的前端界面上。</p>
<p data-nodeid="1212">在日志采集的数据中，通常又可以分成两种类型，一种称为事件，一种称为属性。</p>
<h4 data-nodeid="1213">事件</h4>
<p data-nodeid="1214"><strong data-nodeid="1329">事件是日志采集的重中之重</strong>，这里我们来详细介绍一下。在 App 中，用户的一种行为就被称为一个事件。如果把事件进行归类，我觉得可以分成三种基本事件：曝光事件、点击事件和用户停留事件。</p>
<p data-nodeid="1215">（1）<strong data-nodeid="1334">曝光事件</strong></p>
<p data-nodeid="1216">最简单的，一个 item 或者一个页面被展示出来，就称作曝光。在日志中记录曝光事件，就是记录每一个被展示出来的页面、商品或者内容。</p>
<p data-nodeid="1217">（2）<strong data-nodeid="1340">点击事件</strong></p>
<p data-nodeid="1218">而点击，则是用户在 App 中的点击行为。通常，App 中的各种页面都是通过点击进行跳转的，比如说上面的淘宝页面，你点击一次商品图片可以进入详情页，再点击一次加购可以加入购物车，然后点击支付可以进入到付款页面，依次类推，点击事件是用户行为转变的关键行为。</p>
<p data-nodeid="1219">（3）<strong data-nodeid="1346">用户停留事件</strong></p>
<p data-nodeid="1220">这个事件记录的是<strong data-nodeid="1356">一个用户在某个页面</strong>，<strong data-nodeid="1357">或者某种情况下停留的时间</strong>。比如说在抖音中，你在一个“美女视频”的播放中停留的时间比其他视频的停留时间都要长，我们就可以猜测你对“美女”更感兴趣。</p>
<p data-nodeid="1221">有了上述的三种基本事件，同时综合这三种基本事件发生的不同场景，我们就可以测算各种数据指标。</p>
<ul data-nodeid="1222">
<li data-nodeid="1223">
<p data-nodeid="1224">在<strong data-nodeid="1364">新闻推荐场景</strong>，使用新闻曝光和新闻点击可以计算某条新闻的点击率；</p>
</li>
<li data-nodeid="1225">
<p data-nodeid="1226">在<strong data-nodeid="1370">视频场景</strong>，使用点击和用户停留时间可以计算观看完成比；</p>
</li>
<li data-nodeid="1227">
<p data-nodeid="1228">在<strong data-nodeid="1376">交易场景</strong>，使用浏览点击和下单点击可以计算访购率。</p>
</li>
</ul>
<h4 data-nodeid="1229">属性</h4>
<p data-nodeid="1230">与事件的连贯性不同，<strong data-nodeid="1383">属性的收集往往是一次性的</strong>。当我们打开 App 时，我们使用的手机型号、网络制式、App 版本等信息都作为属性一次性地收集起来。虽然说属性的收集过程比事件要简单，但是属性数据本身的价值并不比大量的事件低，所以，对于属性的日志收集也需要同等的对待。</p>
<h4 data-nodeid="1231">数据埋点</h4>
<p data-nodeid="1232">在我们的公司中，实现日志采集所使用的手段被称为数据埋点。</p>
<p data-nodeid="1233">通俗来说，数据埋点就是在我们 App 的前端，也就是 UI 层的代码中插入一段用于监视用户行为事件的代码。当用户在 App 上发生对应的行为时，就会触发这段代码，从而上传该埋点中事先已经定义好的事件信息。</p>
<p data-nodeid="1234">当然，除了我们所熟知的手机 App，数据埋点还可以设定在 H5 页面、微信小程序等位置。通过埋点收集到的信息：</p>
<ul data-nodeid="1235">
<li data-nodeid="1236">
<p data-nodeid="1237">可以作为监控，看到 App 的长期表现；</p>
</li>
<li data-nodeid="1238">
<p data-nodeid="1239">也可以作为基础原料，进行复杂的运算，用于用户标签、渠道转化分析、个性推荐等。</p>
</li>
</ul>
<h4 data-nodeid="1240">数据埋点的困难</h4>
<p data-nodeid="1241">为了获取更多的流量，满足更多用户的需求，一个成熟的互联网公司往往有各种各样的用户渠道，因此，要想把数据埋点做好也有很多的困难。</p>
<ul data-nodeid="1242">
<li data-nodeid="1243">
<p data-nodeid="1244"><strong data-nodeid="1400">来源众多</strong>。对于一款产品，可能有网页端、App 端，App 还分成安卓、iOS 甚至微软客户端，还有各种各样的小程序。这么多的来源，要把不同来源的同一处行为数据进行<strong data-nodeid="1401">合并统计</strong>，而不同的来源开发语言不同，实现原理不同，埋点的难度可想而知。</p>
</li>
<li data-nodeid="1245">
<p data-nodeid="1246"><strong data-nodeid="1406">页面众多</strong>。看似不起眼的一个 App，从你打开到浏览、下单、支付，这中间不知道要经过多少个页面，有多少种不同的形式，每个页面、每个形式又有若干种事件的组合，要想做好每一处埋点也不是一件容易的事情。</p>
</li>
<li data-nodeid="1247">
<p data-nodeid="1248"><strong data-nodeid="1411">数据格式各不相同</strong>。不同的业务可能对于同一个页面的埋点存在不同的需求，数据埋点需要做到兼容并包、不重不漏，其实也是非常困难的。</p>
</li>
</ul>
<p data-nodeid="1249">说了这么多埋点的困难，那么埋点的方式有哪些呢？对于不同的方式，它们对于困难有什么解决方法，下面我们来看一下。</p>
<h4 data-nodeid="1250">埋点方式</h4>
<p data-nodeid="1251">（1）<strong data-nodeid="1418">手动埋点</strong></p>
<p data-nodeid="1252">说到埋点方式，最容易想到的当然就是手动埋点。前面也说过了，所谓的埋点就是程序员去增加一些代码，那么手动埋点自然是说程序员手动地去增加代码。这就意味着当有产品需求的时候，产品经理提出我们需要在某某页面、某某位置增加一个针对某某行为的埋点，然后程序员领取了这个需求，一顿操作上线这段代码。</p>
<p data-nodeid="1253">这种埋点方式最大的好处就是没有其他的开发量，属于<strong data-nodeid="1425">懒惰开发</strong>的一种情况，只有当需求提出的时候才去增加一个埋点。对于单个需求，开发比较迅速，但是它的缺点也显而易见，随着业务的增长，埋点的需求必然是一个接一个，永无止境，程序员做了大量相似的开发。而且每增加一个埋点，都需要从产品提出到需求沟通到程序员开发到上线走一遍，长期来说消耗是巨大的。</p>
<p data-nodeid="1254">（2）<strong data-nodeid="1430">半自动埋点</strong></p>
<p data-nodeid="1255">手动埋点耗时耗力，所以就要想着把流程改进一下。半自动的埋点通常出现在产品已经基本成熟的时期。程序员加班加点对于目前以及预期未来的业务流程进行了梳理，整理出一套常用的埋点方案，并把这套方案嵌入到业务代码中。当产品经理上线了一个与原有页面类似的新页面，不再需要程序员进行多余的开发，只需要调用之前的方案即可完成埋点。</p>
<p data-nodeid="1256">不过，在半自动埋点的情况下，如果有一些全新的功能或者页面上线，还是需要进行开发的。</p>
<p data-nodeid="1257">（3）<strong data-nodeid="1437">全自动埋点</strong></p>
<p data-nodeid="1258">懒惰是进步的动力。全自动埋点与前面的两个理念完全不同，前面两种不管是手动还是半自动都是在有需求的时候才去埋点，而全自动埋点完全忽略了需求的存在，直接从最基本的事件和属性出发，把所有的东西都纳入埋点的范畴，事无巨细地记录下来，以后产品想要什么东西就自己去日志里统计就好了。</p>
<p data-nodeid="1259">全自动埋点的优势显而易见，<strong data-nodeid="1448">从根本上解决了埋点的需求</strong>，<strong data-nodeid="1449">从此解放了双手</strong>，不再需要听什么埋点需求。但是缺点同样明显，开发一套如此完整的全自动埋点系统通常也极为困难，同时，收集全量信息，网络开销大、存储成本高，大部分没用的信息则会导致后续数据处理的速度缓慢。</p>
<p data-nodeid="1260">不管采取何种埋点方案，有一点我希望提醒你。在处理埋点信息的时候一定要有一套统一的标准：<strong data-nodeid="1459">同一个事件</strong>、<strong data-nodeid="1460">同一个属性坚持只有一个埋点的原则</strong>，收集上来的日志由统一的部门进行汇总管理，进而统一数据口径。试想，如果对于同一个事件，不同的业务部门使用不同的埋点代码，由不同的部门进行计算，随着人员的变动和业务的更迭，最终将导致数据陷入永远无法核对清楚的困境，想想就是一种灾难。</p>
<h3 data-nodeid="1261">进阶</h3>
<p data-nodeid="1262">为了更好地理解数据埋点采集日志与后续环节的关系，我在这里画了一张数据埋点的框架形式，当然，数据埋点的框架可以有很多种，这里只是作为一种说明。</p>
<p data-nodeid="3899" class=""><img src="https://s0.lgstatic.com/i/image6/M00/04/83/Cgp9HWAsyvKAM82sAAFk4RH0U-A120.png" alt="图片2.png" data-nodeid="3902"></p>


<p data-nodeid="1264" class="te-preview-highlight">从上图，我们可以看到，在开发了埋点代码的前端环境中监控用户的行为，当用户产生行为的时候会通过 HTTP 请求把这些事件进行上报，进入到日志收集服务中。日志收集服务会把这些日志转发到日志记录服务中，日志记录服务通过简单的日志加工汇总成为原始日志。在这个位置，通过实时的 ETL 把原始日志处理成标准的格式，比如说汇总成我们所需要的用户 ID 与商品 ID的关联，以及是否有曝光、点击、下单、购买行为，并形成中间层日志，用于各种实时任务。</p>
<p data-nodeid="1265">同时，原始日志和中间层日志通过 Kafka 消息队列同步到 HDFS 中以备后面的离线分析。在上面的一个分支则是后端服务的日志采集，直接通过 Kafka 队列收集信息。实际上，除了前端产生的日志，后端服务同样也会产生各种日志信息，不过这里多用于服务运行状态的检测。</p>
<h3 data-nodeid="1266">总结</h3>
<p data-nodeid="1267">凡是要进行数据的处理，就不得不涉及数据的获取。在当下的互联网公司中，大部分都是以网页、App、小程序为数据源，通过用户的访问日志进行数据的收集。在收集数据的时候，有很多方法，也有很多困难，但是我的建议是尽量选择那些能够保障数据一致性的方法，这样在后续的数据处理、数据应用环节才能够更加快速有效。如果你的日志收集工作没有做好，后面的数据就会一团乱麻，那么大数据体系将无从提起。</p>
<p data-nodeid="1268">在这一讲中，希望你已经了解了数据获取的基本方式以及与埋点有关的信息。当然，在实际的工作中，关于数据获取还有很多细节的事情需要处理，那还需要你不断地摸索，不断地学习。在此过程中，有任何问题或者心得，欢迎在评论区和我交流。</p>
<p data-nodeid="1269">下一讲，我将与你一起讲解 Hadoop 体系中的文件系统 HDFS，到时见。</p>
<hr data-nodeid="1270">
<p data-nodeid="1271"><a href="https://shenceyun.lagou.com/r/rJs" data-nodeid="1476"><img src="https://s0.lgstatic.com/i/image6/M00/00/6D/Cgp9HWAaHaOAI85HAAUCrlmIuEw966.png" alt="Drawing 2.png" data-nodeid="1475"></a></p>
<p data-nodeid="1272"><strong data-nodeid="1480">《大数据开发高薪训练营》</strong></p>
<p data-nodeid="1273" class="">PB 级企业大数据项目实战 + 拉勾硬核内推，5 个月全面掌握大数据核心技能。<a href="https://shenceyun.lagou.com/r/rJs" data-nodeid="1484">点击链接</a>，全面赋能！</p>

---

### 精选评论

##### **超：
> 您好老师，关于自动埋点，现在有什么成熟的解决方案吗，最近在找相关的东西，但是没找到.......

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 你好，埋点的作用就是记录日志用于后面的数据分析和挖掘，埋点框架一般也是针对特定的需求，或者通用功能进行开发，我了解好像也没有特别常用的，可以看一下heap，mixpanel，growingIO，大公司一般会自己开发公司内的通用埋点框架，但是也只是管理最常用的埋点需求，比如网易Hubble。

##### **前：
> 老师您好：请问，大数据中的数据，一大部分应该是各业务系统产生的数据吧？文章中是不是缺少这一部分数据？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 您好，业务系统的数据其实也是来源于业务的用户。

