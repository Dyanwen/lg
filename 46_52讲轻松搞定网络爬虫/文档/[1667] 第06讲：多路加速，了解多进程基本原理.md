<p>在上一课时我们了解了多线程的基本概念，同时我们也提到，Python 中的多线程是不能很好发挥多核优势的，如果想要发挥多核优势，最好还是使用多进程。</p>
<p>那么本课时我们就来了解下多进程的基本概念和用 Python 实现多进程的方法。</p>
<h3>多进程的含义</h3>
<p>进程（Process）是具有一定独立功能的程序关于某个数据集合上的一次运行活动，是系统进行资源分配和调度的一个独立单位。</p>
<p>顾名思义，多进程就是启用多个进程同时运行。由于进程是线程的集合，而且进程是由一个或多个线程构成的，所以多进程的运行意味着有大于或等于进程数量的线程在运行。</p>
<h3>Python 多进程的优势</h3>
<p>通过上一课时我们知道，由于进程中 GIL 的存在，Python 中的多线程并不能很好地发挥多核优势，一个进程中的多个线程，在同一时刻只能有一个线程运行。</p>
<p>而对于多进程来说，每个进程都有属于自己的 GIL，所以，在多核处理器下，多进程的运行是不会受 GIL 的影响的。因此，多进程能更好地发挥多核的优势。</p>
<p>当然，对于爬虫这种 IO 密集型任务来说，多线程和多进程影响差别并不大。对于计算密集型任务来说，Python 的多进程相比多线程，其多核运行效率会有成倍的提升。</p>
<p>总的来说，Python 的多进程整体来看是比多线程更有优势的。所以，在条件允许的情况下，能用多进程就尽量用多进程。</p>
<p>不过值得注意的是，由于进程是系统进行资源分配和调度的一个独立单位，所以各个进程之间的数据是无法共享的，如多个进程无法共享一个全局变量，进程之间的数据共享需要有单独的机制来实现，这在后面也会讲到。</p>
<h3>多进程的实现</h3>
<p>在 Python 中也有内置的库来实现多进程，它就是 multiprocessing。</p>
<p>multiprocessing 提供了一系列的组件，如 Process（进程）、Queue（队列）、Semaphore（信号量）、Pipe（管道）、Lock（锁）、Pool（进程池）等，接下来让我们来了解下它们的使用方法。</p>
<h4>直接使用 Process 类</h4>
<p>在 multiprocessing 中，每一个进程都用一个 Process 类来表示。它的 API 调用如下：</p>
<pre><code data-language="python" class="lang-python">Process([group [, target [, name [, args [, kwargs]]]]])
</code></pre>
<ul>
<li>target 表示调用对象，你可以传入方法的名字。</li>
<li>args 表示被调用对象的位置参数元组，比如 target 是函数 func，他有两个参数 m，n，那么 args 就传入 [m, n] 即可。</li>
<li>kwargs 表示调用对象的字典。</li>
<li>name 是别名，相当于给这个进程取一个名字。</li>
<li>group 分组。</li>
</ul>
<p>我们先用一个实例来感受一下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">import</span> multiprocessing

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process</span><span class="hljs-params">(index)</span>:</span>
    print(<span class="hljs-string">f'Process: <span class="hljs-subst">{index}</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
        p = multiprocessing.Process(target=process, args=(i,))
        p.start()
</code></pre>
<p>这是一个实现多进程最基础的方式：通过创建 Process 来新建一个子进程，其中 target 参数传入方法名，args 是方法的参数，是以元组的形式传入，其和被调用的方法 process 的参数是一一对应的。</p>
<blockquote>
<p>注意：这里 args 必须要是一个元组，如果只有一个参数，那也要在元组第一个元素后面加一个逗号，如果没有逗号则和单个元素本身没有区别，无法构成元组，导致参数传递出现问题。</p>
</blockquote>
<p>创建完进程之后，我们通过调用 start 方法即可启动进程了。运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Process:&nbsp;<span class="hljs-number">0</span>
Process:&nbsp;<span class="hljs-number">1</span>
Process:&nbsp;<span class="hljs-number">2</span>
Process:&nbsp;<span class="hljs-number">3</span>
Process:&nbsp;<span class="hljs-number">4</span>
</code></pre>
<p>可以看到，我们运行了 5 个子进程，每个进程都调用了 process 方法。process 方法的 index 参数通过 Process 的 args 传入，分别是 0~4 这 5 个序号，最后打印出来，5 个子进程运行结束。</p>
<p>由于进程是 Python 中最小的资源分配单元，因此这些进程和线程不同，各个进程之间的数据是不会共享的，每启动一个进程，都会独立分配资源。</p>
<p>另外，在当前 CPU 核数足够的情况下，这些不同的进程会分配给不同的 CPU 核来运行，实现真正的并行执行。</p>
<p>multiprocessing 还提供了几个比较有用的方法，如我们可以通过 cpu_count 的方法来获取当前机器 CPU 的核心数量，通过 active_children 方法获取当前还在运行的所有进程。</p>
<p>下面通过一个实例来看一下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">import</span> multiprocessing
<span class="hljs-keyword">import</span> time

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process</span><span class="hljs-params">(index)</span>:</span>
    time.sleep(index)
    print(<span class="hljs-string">f'Process: <span class="hljs-subst">{index}</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">5</span>):
        p = multiprocessing.Process(target=process, args=[i])
        p.start()
    print(<span class="hljs-string">f'CPU number: <span class="hljs-subst">{multiprocessing.cpu_count()}</span>'</span>)
    <span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> multiprocessing.active_children():
        print(<span class="hljs-string">f'Child process name: <span class="hljs-subst">{p.name}</span> id: <span class="hljs-subst">{p.pid}</span>'</span>)
    print(<span class="hljs-string">'Process Ended'</span>)
</code></pre>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Process: <span class="hljs-number">0</span>
CPU number: <span class="hljs-number">8</span>
Child process name: Process<span class="hljs-number">-5</span> id: <span class="hljs-number">73595</span>
Child process name: Process<span class="hljs-number">-2</span> id: <span class="hljs-number">73592</span>
Child process name: Process<span class="hljs-number">-3</span> id: <span class="hljs-number">73593</span>
Child process name: Process<span class="hljs-number">-4</span> id: <span class="hljs-number">73594</span>
Process Ended
Process: <span class="hljs-number">1</span>
Process: <span class="hljs-number">2</span>
Process: <span class="hljs-number">3</span>
Process: <span class="hljs-number">4</span>
</code></pre>
<p>在上面的例子中我们通过 cpu_count 成功获取了 CPU 核心的数量：8 个，当然不同的机器结果可能不同。</p>
<p>另外我们还通过 active_children 获取到了当前正在活跃运行的进程列表。然后我们遍历了每个进程，并将它们的名称和进程号打印出来了，这里进程号直接使用 pid 属性即可获取，进程名称直接通过 name 属性即可获取。</p>
<p>以上我们就完成了多进程的创建和一些基本信息的获取。</p>
<h4>继承 Process 类</h4>
<p>在上面的例子中，我们创建进程是直接使用 Process 这个类来创建的，这是一种创建进程的方式。不过，创建进程的方式不止这一种，同样，我们也可以像线程 Thread 一样来通过继承的方式创建一个进程类，进程的基本操作我们在子类的 run 方法中实现即可。</p>
<p>通过一个实例来看一下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process
<span class="hljs-keyword">import</span> time

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyProcess</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, loop)</span>:</span>
        Process.__init__(self)
        self.loop = loop

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> range(self.loop):
            time.sleep(<span class="hljs-number">1</span>)
            print(<span class="hljs-string">f'Pid: <span class="hljs-subst">{self.pid}</span> LoopCount: <span class="hljs-subst">{count}</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>):
        p = MyProcess(i)
        p.start()
</code></pre>
<p>我们首先声明了一个构造方法，这个方法接收一个 loop 参数，代表循环次数，并将其设置为全局变量。在 run 方法中，又使用这个 loop 变量循环了 loop 次并打印了当前的进程号和循环次数。</p>
<p>在调用时，我们用 range 方法得到了 2、3、4 三个数字，并把它们分别初始化了 MyProcess 进程，然后调用 start 方法将进程启动起来。</p>
<blockquote>
<p>注意：这里进程的执行逻辑需要在 run 方法中实现，启动进程需要调用 start 方法，调用之后 run 方法便会执行。</p>
</blockquote>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Pid: <span class="hljs-number">73667</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">73668</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">73669</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">73667</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">73668</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">73669</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">73668</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">73669</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">73669</span> LoopCount: <span class="hljs-number">3</span>
</code></pre>
<p>可以看到，三个进程分别打印出了 2、3、4 条结果，即进程 73667 打印了 2 次 结果，进程 73668 打印了 3 次结果，进程 73669 打印了 4 次结果。</p>
<blockquote>
<p>注意，这里的进程 pid 代表进程号，不同机器、不同时刻运行结果可能不同。</p>
</blockquote>
<p>通过上面的方式，我们也非常方便地实现了一个进程的定义。为了复用方便，我们可以把一些方法写在每个进程类里封装好，在使用时直接初始化一个进程类运行即可。</p>
<h4>守护进程</h4>
<p>在多进程中，同样存在守护进程的概念，如果一个进程被设置为守护进程，当父进程结束后，子进程会自动被终止，我们可以通过设置 daemon 属性来控制是否为守护进程。</p>
<p>还是原来的例子，增加了 deamon 属性的设置：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process
<span class="hljs-keyword">import</span> time

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyProcess</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, loop)</span>:</span>
        Process.__init__(self)
        self.loop = loop

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> range(self.loop):
            time.sleep(<span class="hljs-number">1</span>)
            print(<span class="hljs-string">f'Pid: <span class="hljs-subst">{self.pid}</span> LoopCount: <span class="hljs-subst">{count}</span>'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>):
        p = MyProcess(i)
        p.daemon = <span class="hljs-literal">True</span>
        p.start()

print(<span class="hljs-string">'Main Process ended'</span>)
</code></pre>
<p>运行结果如下：</p>
<pre><code>Main Process ended
</code></pre>
<p>结果很简单，因为主进程没有做任何事情，直接输出一句话结束，所以在这时也直接终止了子进程的运行。</p>
<p>这样可以有效防止无控制地生成子进程。这样的写法可以让我们在主进程运行结束后无需额外担心子进程是否关闭，避免了独立子进程的运行。</p>
<h4>进程等待</h4>
<p>上面的运行效果其实不太符合我们预期：主进程运行结束时，子进程（守护进程）也都退出了，子进程什么都没来得及执行。</p>
<p>能不能让所有子进程都执行完了然后再结束呢？当然是可以的，只需要加入 join 方法即可，我们可以将代码改写如下：</p>
<pre><code data-language="python" class="lang-python">processes = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>):
    p = MyProcess(i)
    processes.append(p)
    p.daemon = <span class="hljs-literal">True</span>
    p.start()
<span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> processes:
    p.join()
</code></pre>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Pid: <span class="hljs-number">40866</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">40867</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">40868</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">40866</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">40867</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">40868</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">40867</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">40868</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">40868</span> LoopCount: <span class="hljs-number">3</span>
Main Process ended
</code></pre>
<p>在调用 start 和 join 方法后，父进程就可以等待所有子进程都执行完毕后，再打印出结束的结果。</p>
<p>默认情况下，join 是无限期的。也就是说，如果有子进程没有运行完毕，主进程会一直等待。这种情况下，如果子进程出现问题陷入了死循环，主进程也会无限等待下去。怎么解决这个问题呢？可以给 join 方法传递一个超时参数，代表最长等待秒数。如果子进程没有在这个指定秒数之内完成，会被强制返回，主进程不再会等待。也就是说这个参数设置了主进程等待该子进程的最长时间。</p>
<p>例如这里我们传入 1，代表最长等待 1 秒，代码改写如下：</p>
<pre><code data-language="python" class="lang-python">processes = []
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">3</span>, <span class="hljs-number">5</span>):
    p = MyProcess(i)
    processes.append(p)
    p.daemon = <span class="hljs-literal">True</span>
    p.start()
<span class="hljs-keyword">for</span> p <span class="hljs-keyword">in</span> processes:
    p.join(<span class="hljs-number">1</span>)
</code></pre>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Pid: <span class="hljs-number">40970</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">40971</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">40970</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">40971</span> LoopCount: <span class="hljs-number">1</span>
Main Process ended
</code></pre>
<p>可以看到，有的子进程本来要运行 3 秒，结果运行 1 秒就被强制返回了，由于是守护进程，该子进程被终止了。</p>
<p>到这里，我们就了解了守护进程、进程等待和超时设置的用法。</p>
<h4>终止进程</h4>
<p>当然，终止进程不止有守护进程这一种做法，我们也可以通过 terminate 方法来终止某个子进程，另外我们还可以通过 is_alive 方法判断进程是否还在运行。</p>
<p>下面我们来看一个实例：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">import</span> multiprocessing
<span class="hljs-keyword">import</span> time

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">process</span><span class="hljs-params">()</span>:</span>
    print(<span class="hljs-string">'Starting'</span>)
    time.sleep(<span class="hljs-number">5</span>)
    print(<span class="hljs-string">'Finished'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    p = multiprocessing.Process(target=process)
    print(<span class="hljs-string">'Before:'</span>, p, p.is_alive())

    p.start()
    print(<span class="hljs-string">'During:'</span>, p, p.is_alive())

    p.terminate()
    print(<span class="hljs-string">'Terminate:'</span>, p, p.is_alive())

    p.join()
    print(<span class="hljs-string">'Joined:'</span>, p, p.is_alive())
</code></pre>
<p>在上面的例子中，我们用 Process 创建了一个进程，接着调用 start 方法启动这个进程，然后调用 terminate 方法将进程终止，最后调用 join 方法。</p>
<p>另外，在进程运行不同的阶段，我们还通过 is_alive 方法判断当前进程是否还在运行。</p>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Before: &lt;Process(Process<span class="hljs-number">-1</span>, initial)&gt; <span class="hljs-literal">False</span>
During: &lt;Process(Process<span class="hljs-number">-1</span>, started)&gt; <span class="hljs-literal">True</span>
Terminate: &lt;Process(Process<span class="hljs-number">-1</span>, started)&gt; <span class="hljs-literal">True</span>
Joined: &lt;Process(Process<span class="hljs-number">-1</span>, stopped[SIGTERM])&gt; <span class="hljs-literal">False</span>
</code></pre>
<p>这里有一个值得注意的地方，在调用 terminate 方法之后，我们用 is_alive 方法获取进程的状态发现依然还是运行状态。在调用 join 方法之后，is_alive 方法获取进程的运行状态才变为终止状态。</p>
<p>所以，在调用 terminate 方法之后，记得要调用一下 join 方法，这里调用 join 方法可以为进程提供时间来更新对象状态，用来反映出最终的进程终止效果。</p>
<h3>进程互斥锁</h3>
<p>在上面的一些实例中，我们可能会遇到如下的运行结果：</p>
<pre><code data-language="python" class="lang-python">Pid: <span class="hljs-number">73993</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">73993</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">73994</span> LoopCount: <span class="hljs-number">0</span>Pid: <span class="hljs-number">73994</span> LoopCount: <span class="hljs-number">1</span>

Pid: <span class="hljs-number">73994</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">73995</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">73995</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">73995</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">73995</span> LoopCount: <span class="hljs-number">3</span>
Main Process ended
</code></pre>
<p>我们发现，有的输出结果没有换行。这是什么原因造成的呢？</p>
<p>这种情况是由多个进程并行执行导致的，两个进程同时进行了输出，结果第一个进程的换行没有来得及输出，第二个进程就输出了结果，导致最终输出没有换行。</p>
<p>那如何来避免这种问题？如果我们能保证，多个进程运行期间的任一时间，只能一个进程输出，其他进程等待，等刚才那个进程输出完毕之后，另一个进程再进行输出，这样就不会出现输出没有换行的现象了。</p>
<p>这种解决方案实际上就是实现了进程互斥，避免了多个进程同时抢占临界区（输出）资源。我们可以通过 multiprocessing 中的 Lock 来实现。Lock，即锁，在一个进程输出时，加锁，其他进程等待。等此进程执行结束后，释放锁，其他进程可以进行输出。</p>
<p>我们首先实现一个不加锁的实例，代码如下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, Lock
<span class="hljs-keyword">import</span> time

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyProcess</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, loop, lock)</span>:</span>
        Process.__init__(self)
        self.loop = loop
        self.lock = lock

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">for</span> count <span class="hljs-keyword">in</span> range(self.loop):
            time.sleep(<span class="hljs-number">0.1</span>)
            <span class="hljs-comment"># self.lock.acquire()</span>
            print(<span class="hljs-string">f'Pid: <span class="hljs-subst">{self.pid}</span> LoopCount: <span class="hljs-subst">{count}</span>'</span>)
            <span class="hljs-comment"># self.lock.release()</span>

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    lock = Lock()
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>, <span class="hljs-number">15</span>):
        p = MyProcess(i, lock)
        p.start()
</code></pre>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Pid: <span class="hljs-number">74030</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74031</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74032</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74033</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74034</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74030</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74031</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74032</span> LoopCount: <span class="hljs-number">1</span>Pid: <span class="hljs-number">74033</span> LoopCount: <span class="hljs-number">1</span>

Pid: <span class="hljs-number">74034</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74030</span> LoopCount: <span class="hljs-number">2</span>
...
</code></pre>
<p>可以看到运行结果中有些输出已经出现了不换行的问题。</p>
<p>我们对其加锁，取消掉刚才代码中的两行注释，重新运行，运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Pid: <span class="hljs-number">74061</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74062</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74063</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74064</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74065</span> LoopCount: <span class="hljs-number">0</span>
Pid: <span class="hljs-number">74061</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74062</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74063</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74064</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74065</span> LoopCount: <span class="hljs-number">1</span>
Pid: <span class="hljs-number">74061</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">74062</span> LoopCount: <span class="hljs-number">2</span>
Pid: <span class="hljs-number">74064</span> LoopCount: <span class="hljs-number">2</span>
...
</code></pre>
<p>这时输出效果就正常了。</p>
<p>所以，在访问一些临界区资源时，使用 Lock 可以有效避免进程同时占用资源而导致的一些问题。</p>
<h3>信号量</h3>
<p>进程互斥锁可以使同一时刻只有一个进程能访问共享资源，如上面的例子所展示的那样，在同一时刻只能有一个进程输出结果。但有时候我们需要允许多个进程来访问共享资源，同时还需要限制能访问共享资源的进程的数量。</p>
<p>这种需求该如何实现呢？可以用信号量，信号量是进程同步过程中一个比较重要的角色。它可以控制临界资源的数量，实现多个进程同时访问共享资源，限制进程的并发量。</p>
<p>如果你学过操作系统，那么一定对这方面非常了解，如果你还不了解信号量是什么，可以先熟悉一下这个概念。</p>
<p>我们可以用 multiprocessing 库中的 Semaphore 来实现信号量。</p>
<p>那么接下来我们就用一个实例来演示一下进程之间利用 Semaphore 做到多个进程共享资源，同时又限制同时可访问的进程数量，代码如下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, Semaphore, Lock, Queue
<span class="hljs-keyword">import</span> time

buffer = Queue(<span class="hljs-number">10</span>)
empty = Semaphore(<span class="hljs-number">2</span>)
full = Semaphore(<span class="hljs-number">0</span>)
lock = Lock()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Consumer</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">global</span> buffer, empty, full, lock
        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
            full.acquire()
            lock.acquire()
            buffer.get()
            print(<span class="hljs-string">'Consumer pop an element'</span>)
            time.sleep(<span class="hljs-number">1</span>)
            lock.release()
            empty.release()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Producer</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">global</span> buffer, empty, full, lock
        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
            empty.acquire()
            lock.acquire()
            buffer.put(<span class="hljs-number">1</span>)
            print(<span class="hljs-string">'Producer append an element'</span>)
            time.sleep(<span class="hljs-number">1</span>)
            lock.release()
            full.release()

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    p = Producer()
    c = Consumer()
    p.daemon = c.daemon = <span class="hljs-literal">True</span>
    p.start()
    c.start()
    p.join()
    c.join()
    print(<span class="hljs-string">'Main Process Ended'</span>)
</code></pre>
<p>如上代码实现了经典的生产者和消费者问题。它定义了两个进程类，一个是消费者，一个是生产者。</p>
<p>另外，这里使用 multiprocessing 中的 Queue 定义了一个共享队列，然后定义了两个信号量 Semaphore，一个代表缓冲区空余数，一个表示缓冲区占用数。</p>
<p>生产者 Producer 使用 acquire 方法来占用一个缓冲区位置，缓冲区空闲区大小减 1，接下来进行加锁，对缓冲区进行操作，然后释放锁，最后让代表占用的缓冲区位置数量加 1，消费者则相反。</p>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Producer append an element
Producer append an element
Consumer pop an element
Consumer pop an element
Producer append an element
Producer append an element
Consumer pop an element
Consumer pop an element
Producer append an element
Producer append an element
Consumer pop an element
Consumer pop an element
Producer append an element
Producer append an element
</code></pre>
<p>我们发现两个进程在交替运行，生产者先放入缓冲区物品，然后消费者取出，不停地进行循环。 你可以通过上面的例子来体会信号量 Semaphore 的用法，通过 Semaphore 我们很好地控制了进程对资源的并发访问数量。</p>
<h3>队列</h3>
<p>在上面的例子中我们使用 Queue 作为进程通信的共享队列使用。</p>
<p>而如果我们把上面程序中的 Queue 换成普通的 list，是完全起不到效果的，因为进程和进程之间的资源是不共享的。即使在一个进程中改变了这个 list，在另一个进程也不能获取到这个 list 的状态，所以声明全局变量对多进程是没有用处的。</p>
<p>那进程如何共享数据呢？可以用 Queue，即队列。当然这里的队列指的是 multiprocessing 里面的 Queue。</p>
<p>依然用上面的例子，我们一个进程向队列中放入随机数据，然后另一个进程取出数据。</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, Semaphore, Lock, Queue
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">from</span> random <span class="hljs-keyword">import</span> random

buffer = Queue(<span class="hljs-number">10</span>)
empty = Semaphore(<span class="hljs-number">2</span>)
full = Semaphore(<span class="hljs-number">0</span>)
lock = Lock()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Consumer</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">global</span> buffer, empty, full, lock
        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
            full.acquire()
            lock.acquire()
            print(<span class="hljs-string">f'Consumer get <span class="hljs-subst">{buffer.get()}</span>'</span>)
            time.sleep(<span class="hljs-number">1</span>)
            lock.release()
            empty.release()

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Producer</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">global</span> buffer, empty, full, lock
        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
            empty.acquire()
            lock.acquire()
            num = random()
            print(<span class="hljs-string">f'Producer put <span class="hljs-subst">{num}</span>'</span>)
            buffer.put(num)
            time.sleep(<span class="hljs-number">1</span>)
            lock.release()
            full.release()

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    p = Producer()
    c = Consumer()
    p.daemon = c.daemon = <span class="hljs-literal">True</span>
    p.start()
    c.start()
    p.join()
    c.join()
    print(<span class="hljs-string">'Main Process Ended'</span>)
</code></pre>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Producer put  <span class="hljs-number">0.719213647437</span>
Producer put  <span class="hljs-number">0.44287326683</span>
Consumer get <span class="hljs-number">0.719213647437</span>
Consumer get <span class="hljs-number">0.44287326683</span>
Producer put  <span class="hljs-number">0.722859424381</span>
Producer put  <span class="hljs-number">0.525321338921</span>
Consumer get <span class="hljs-number">0.722859424381</span>
Consumer get <span class="hljs-number">0.525321338921</span>
</code></pre>
<p>在上面的例子中我们声明了两个进程，一个进程为生产者 Producer，另一个为消费者 Consumer，生产者不断向 Queue 里面添加随机数，消费者不断从队列里面取随机数。</p>
<p>生产者在放数据的时候调用了 Queue 的 put 方法，消费者在取的时候使用了 get 方法，这样我们就通过 Queue 实现两个进程的数据共享了。</p>
<h3>管道</h3>
<p>刚才我们使用 Queue 实现了进程间的数据共享，那么进程之间直接通信，如收发信息，用什么比较好呢？可以用 Pipe，管道。</p>
<p>管道，我们可以把它理解为两个进程之间通信的通道。管道可以是单向的，即 half-duplex：一个进程负责发消息，另一个进程负责收消息；也可以是双向的 duplex，即互相收发消息。</p>
<p>默认声明 Pipe 对象是双向管道，如果要创建单向管道，可以在初始化的时候传入 deplex 参数为 False。</p>
<p>我们用一个实例来感受一下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Process, Pipe

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Consumer</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, pipe)</span>:</span>
        Process.__init__(self)
        self.pipe = pipe

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        self.pipe.send(<span class="hljs-string">'Consumer Words'</span>)
        print(<span class="hljs-string">f'Consumer Received: <span class="hljs-subst">{self.pipe.recv()}</span>'</span>)

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Producer</span><span class="hljs-params">(Process)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, pipe)</span>:</span>
        Process.__init__(self)
        self.pipe = pipe

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">run</span><span class="hljs-params">(self)</span>:</span>
        print(<span class="hljs-string">f'Producer Received: <span class="hljs-subst">{self.pipe.recv()}</span>'</span>)
        self.pipe.send(<span class="hljs-string">'Producer Words'</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    pipe = Pipe()
    p = Producer(pipe[<span class="hljs-number">0</span>])
    c = Consumer(pipe[<span class="hljs-number">1</span>])
    p.daemon = c.daemon = <span class="hljs-literal">True</span>
    p.start()
    c.start()
    p.join()
    c.join()
    print(<span class="hljs-string">'Main Process Ended'</span>)
</code></pre>
<p>在这个例子里我们声明了一个默认为双向的管道，然后将管道的两端分别传给两个进程。两个进程互相收发。观察一下结果：</p>
<pre><code data-language="python" class="lang-python">Producer Received: Consumer Words
Consumer Received: Producer Words
Main Process Ended
</code></pre>
<p>管道 Pipe 就像进程之间搭建的桥梁，利用它我们就可以很方便地实现进程间通信了。</p>
<h3>进程池</h3>
<p>在前面，我们讲了可以使用 Process 来创建进程，同时也讲了如何用 Semaphore 来控制进程的并发执行数量。</p>
<p>假如现在我们遇到这么一个问题，我有 10000 个任务，每个任务需要启动一个进程来执行，并且一个进程运行完毕之后要紧接着启动下一个进程，同时我还需要控制进程的并发数量，不能并发太高，不然 CPU 处理不过来（如果同时运行的进程能维持在一个最高恒定值当然利用率是最高的）。</p>
<p>那么我们该如何来实现这个需求呢？</p>
<p>用 Process 和 Semaphore 可以实现，但是实现起来比较我们可以用 Process 和 Semaphore 解决问题，但是实现起来比较烦琐。而这种需求在平时又是非常常见的。此时，我们就可以派上进程池了，即 multiprocessing 中的 Pool。</p>
<p>Pool 可以提供指定数量的进程，供用户调用，当有新的请求提交到 pool 中时，如果池还没有满，就会创建一个新的进程用来执行该请求；但如果池中的进程数已经达到规定最大值，那么该请求就会等待，直到池中有进程结束，才会创建新的进程来执行它。</p>
<p>我们用一个实例来实现一下，代码如下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Pool
<span class="hljs-keyword">import</span> time


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">function</span><span class="hljs-params">(index)</span>:</span>
    print(<span class="hljs-string">f'Start process: <span class="hljs-subst">{index}</span>'</span>)
    time.sleep(<span class="hljs-number">3</span>)
    print(<span class="hljs-string">f'End process <span class="hljs-subst">{index}</span>'</span>, )


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    pool = Pool(processes=<span class="hljs-number">3</span>)
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">4</span>):
        pool.apply_async(function, args=(i,))

    print(<span class="hljs-string">'Main Process started'</span>)
    pool.close()
    pool.join()
    print(<span class="hljs-string">'Main Process ended'</span>)
</code></pre>
<p>在这个例子中我们声明了一个大小为 3 的进程池，通过 processes 参数来指定，如果不指定，那么会自动根据处理器内核来分配进程数。接着我们使用 apply_async 方法将进程添加进去，args 可以用来传递参数。</p>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">Main Process started
Start process: <span class="hljs-number">0</span>
Start process: <span class="hljs-number">1</span>
Start process: <span class="hljs-number">2</span>
End process <span class="hljs-number">0</span>
End process <span class="hljs-number">1</span>
End process <span class="hljs-number">2</span>
Start process: <span class="hljs-number">3</span>
End process <span class="hljs-number">3</span>
Main Process ended
</code></pre>
<p>进程池大小为 3，所以最初可以看到有 3 个进程同时执行，第4个进程在等待，在有进程运行完毕之后，第4个进程马上跟着运行，出现了如上的运行效果。</p>
<p>最后，我们要记得调用 close 方法来关闭进程池，使其不再接受新的任务，然后调用 join 方法让主进程等待子进程的退出，等子进程运行完毕之后，主进程接着运行并结束。</p>
<p>不过上面的写法多少有些烦琐，这里再介绍进程池一个更好用的 map 方法，可以将上述写法简化很多。</p>
<p>map 方法是怎么用的呢？第一个参数就是要启动的进程对应的执行方法，第 2 个参数是一个可迭代对象，其中的每个元素会被传递给这个执行方法。</p>
<p>举个例子：现在我们有一个 list，里面包含了很多 URL，另外我们也定义了一个方法用来抓取每个 URL 内容并解析，那么我们可以直接在 map 的第一个参数传入方法名，第 2 个参数传入 URL 数组。</p>
<p>我们用一个实例来感受一下：</p>
<pre><code data-language="python" class="lang-python"><span class="hljs-keyword">from</span> multiprocessing <span class="hljs-keyword">import</span> Pool
<span class="hljs-keyword">import</span> urllib.request
<span class="hljs-keyword">import</span> urllib.error


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">scrape</span><span class="hljs-params">(url)</span>:</span>
    <span class="hljs-keyword">try</span>:
        urllib.request.urlopen(url)
        print(<span class="hljs-string">f'URL <span class="hljs-subst">{url}</span> Scraped'</span>)
    <span class="hljs-keyword">except</span> (urllib.error.HTTPError, urllib.error.URLError):
        print(<span class="hljs-string">f'URL <span class="hljs-subst">{url}</span> not Scraped'</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    pool = Pool(processes=<span class="hljs-number">3</span>)
    urls = [
        <span class="hljs-string">'https://www.baidu.com'</span>,
        <span class="hljs-string">'http://www.meituan.com/'</span>,
        <span class="hljs-string">'http://blog.csdn.net/'</span>,
        <span class="hljs-string">'http://xxxyxxx.net'</span>
    ]
    pool.map(scrape, urls)
    pool.close()
</code></pre>
<p>这个例子中我们先定义了一个 scrape 方法，它接收一个参数 url，这里就是请求了一下这个链接，然后输出爬取成功的信息，如果发生错误，则会输出爬取失败的信息。</p>
<p>首先我们要初始化一个 Pool，指定进程数为 3。然后我们声明一个 urls 列表，接着我们调用了 map 方法，第 1 个参数就是进程对应的执行方法，第 2 个参数就是 urls 列表，map 方法会依次将 urls 的每个元素作为 scrape 的参数传递并启动一个新的进程，加到进程池中执行。</p>
<p>运行结果如下：</p>
<pre><code data-language="python" class="lang-python">URL https://www.baidu.com Scraped
URL http://xxxyxxx.net <span class="hljs-keyword">not</span> Scraped
URL http://blog.csdn.net/ Scraped
URL http://www.meituan.com/ Scraped
</code></pre>
<p>这样，我们就可以实现 3 个进程并行运行。不同的进程相互独立地输出了对应的爬取结果。</p>
<p>可以看到，我们利用 Pool 的 map 方法非常方便地实现了多进程的执行。后面我们也会在实战案例中结合进程池来实现数据的爬取。</p>
<p>以上便是 Python 中多进程的基本用法，本节内容比较多，后面的实战案例也会用到这些内容，需要好好掌握。</p>

---

### 精选评论

##### **7909：
> 关于信号量那部分生产者和消费者的代码，我的运行结果一直是：<div>Producer append an element<br>Producer append an element</div><div>请问这是什么原因呢？</div>

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 由于是两个进程对信号量进行读写，empty 信号量为 2，full 为 0，消费者每次都要获取 full 的信号量使其减一，生产者要获取 empty 的信号量使其加一，所以。运行结果只要执行顺序能满足当前缓冲区大小为 2 即可，消费者和生产者的执行顺序可能不定。不过最主要的还是理解信号量的作用和意义。

你的是 windows 吗？如果换到 Linux 或 Mac 应该是好的，具体的解决方案可以见：https://stackoverflow.com/questions/50379009/python-multiprocessing-semaphore-not-working，抱歉的确是我当时没有在 WIndows 下单独测试

##### Quosimodo：
> 那个消费者信号量问题貌似是因为global在不同的进程中只能读，不能写，子进程获得的是一个新的拷贝。把buffer等改成参数传进去就可以解决了，我改了运行是可以的。作者这个讲的还是很详细了，感谢！

##### **9049：
> <p class="MsoNormal"><b><span style="font-family: 微软雅黑; font-size: 11pt;"><font face="微软雅黑">信号量的例子生产者与消费者代码运行死机，在哪里可以和老师互动？看看什么地方出问题了？</font></span></b></p>

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 可以在这里留言，老师看到后会及时回复的

##### **宝：
> 代码希望像极客时间那种可以直接复制的，照片不方便。

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 可以关注 拉勾教育 公众号 咨询小助手获取代码

##### cxc：
> 老师讲的很好，就是代码看起来太不方便了，有的大有的小，可以优化一下吗？

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 已反馈给讲师，后续会调整哈

##### **7172：
> 打卡。哪里下载课件和代码？

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 关注 拉勾教育 公众号 咨询小助手获取课件

##### **鹏：
> 本章由浅入深逐步剖析多进程，个人总结为进程基本实现、锁、信号量、互斥、队列、阻塞的概念及管道。及复合使用线程池。期待，感谢。

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 继续加油哦～

##### **羊：
> 在win上运行，如果把queue用作全局变量的话，消费者会卡在buffer.get()那里，打印了Producter跟Consumer两个进程的buffer队列id，两个是不同的，应该是进程获取的全局变量只是一个拷贝，不是原来那个，如果把信号量、锁跟队列的变量写成传参进进程函数的话是可以顺利运行的

##### *正：
> 老师的Pycharm配色和字体可以来一份吗，好漂亮😂我有基础，今天看了模块一感觉来了个全面的复习😋老师NB😎

##### *栋：
> 各位学习本身都有代码基础么

##### **利：
> 请问崔大，信号量那部分的代码，我原封不动的按照例子的代码实现，但是没有输出预期的结果，而是输出两个“<span style="font-size: 16.0125px;">Producer append an element</span>”就卡住了，我觉得好像是Consumer进程没有和Producer共享empty和full信号量导致死锁了，请问老师怎么解决呢？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 由于是两个进程对信号量进行读写，empty 信号量为 2，full 为 0，消费者每次都要获取 full 的信号量使其减一，生产者要获取 empty 的信号量使其加一，所以。运行结果只要执行顺序能满足当前缓冲区大小为 2 即可，消费者和生产者的执行顺序可能不定。不过最主要的还是理解信号量的作用和意义。

##### **曦：
> 信号量部分，生产者和消费者代码，生产者每次获取信号量(1)正常，并且也在释放信号量(2)也正常，并且打印确实能看到数值的变化，但是消费者没办法执行到信号量(2)之后的部分，环境python3.7。

##### **平：
> 为什么我执行信号量那个代码时候，生产者生产了2个元素之后就卡着不动了啊？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 你的是 windows 吗？如果换到 Linux 或 Mac 应该是好的，具体的解决方案可以见：https://stackoverflow.com/questions/50379009/python-multiprocessing-semaphore-not-working，抱歉的确是我当时没有在 WIndows 下单独测试

##### **聪：
> 文中的代码能否集中传到Github上，课件也可以传到Github上。

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 可以关注 拉勾教育 公众号 咨询小助手获取课件哦～

##### **3280：
> 讲的确实好

##### Tom：
> 第一模块学完了，收获很大。想问一下小编，这52讲如果能够熟练掌握，可以从事数据爬虫工程师职业吗？

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 我个人觉得只要努力学习肯定是没问题的。

##### **6391：
> 很不错，这学期正在学操作系统，互相帮助理解

##### **昱：
> 听着好像慕承和

##### **耿爱生活：
> 请问有学习群吗，里面的代码在我这有的运行不出来想能有个地方交流

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 关注 拉勾教 公众号，咨询小助手

##### *焦：
> 崔大，讲的很棒，很仔细

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 后面的课程更精彩哦～

##### *尾：
> 催老师，讲的很详细，。有代码。，看他的博客有些没看懂的，，现在懂了，，

##### **利：
> 这节很有进展

##### *刚：
> 讲的真不错😀

