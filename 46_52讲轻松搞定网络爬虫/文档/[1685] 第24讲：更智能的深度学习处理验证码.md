<p>我们在前面讲解了如何使用打码平台来识别验证码，简单高效。但是也有一些缺点，比如效率可能没那么高，准确率也不一定能做到完全可控，并且需要付出一定的费用。</p>
<p>本课时我们就来介绍使用深度学习来识别验证码的方法，训练好对应的模型就能更好地对验证码进行识别，并且准确率可控，节省一定的成本。</p>
<p>本课时我们以深度学习识别滑块验证码为例来讲解深度学习对于此类验证码识别的实现。</p>
<p>滑块验证码是怎样的呢？如图所示，验证码是一张矩形图，图片左侧会出现一个滑块，右侧会出现一个缺口，下侧会出现一个滑轨。左侧的滑块会随着滑轨的拖动而移动，如果能将左侧滑块匹配滑动到右侧缺口处，就算完成了验证。</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/12/3A/Ciqah16dWvaAFI32AAHHgbnOPXI004.png" alt="1.png"></p>
<p>由于这种验证码交互形式比较友好，且安全性、美观度上也会更高，像这种类似的验证码也变得越来越流行。另外不仅仅是“极验”，其他很多验证码服务商也推出了类似的验证码服务，如“网易易盾”等，上图所示的就是“网易易盾”的滑动验证码。</p>
<p>没错，这种滑动验证码的出现确实让很多网站变得更安全。但是做爬虫的可就苦恼了，如果想采用自动化的方法来绕过这种滑动验证码，关键点在于以下两点：</p>
<ul>
<li>找出目标缺口的位置。</li>
<li>模拟人的滑动轨迹将滑块滑动到缺口处。</li>
</ul>
<p>那么问题来了，第一步怎么做呢？</p>
<p>接下来我们就来看看如何利用深度学习来实现吧。</p>
<h4>目标检测</h4>
<p>我们的目标就是输入一张图，输出缺口的的位置，所以只需要将这个问题归结成一个深度学习的“目标检测”问题就好了。</p>
<p>首先在开始之前简单说下目标检测。什么叫目标检测？顾名思义，就是把我们想找的东西找出来。比如给一张“狗”的图片，如图所示：</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/05/0B/CgoCgV6dWxOAPxb8AAehD7cahYQ261.png" alt="2.png"></p>
<p>我们想知道这只狗在哪，它的舌头在哪，找到了就把它们框选出来，这就是目标检测。</p>
<p>经过目标检测算法处理之后，我们期望得到的图片是这样的：</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/12/3A/Ciqah16dWx2AUveZAAfLKj2mbM0144.png" alt="3.png"></p>
<p>可以看到这只狗和它的舌头就被框选出来了，这样就完成了一个不错的目标检测。</p>
<p>当前做目标检测的算法主要有两个方向，有一阶段式和两阶段式，英文分别叫作 One stage 和 Two stage，简述如下。</p>
<ul>
<li>Two Stage：算法首先生成一系列目标所在位置的候选框，然后再对这些框选出来的结果进行样本分类，即先找出来在哪，然后再分出来是什么，俗话说叫“看两眼”，这种算法有 R-CNN、Fast R-CNN、Faster R-CNN 等，这些算法架构相对复杂，但准确率上有优势。</li>
<li>One Stage：不需要产生候选框，直接将目标定位和分类的问题转化为回归问题，俗话说叫“看一眼”，这种算法有 YOLO、SSD，这些算法虽然准确率上不及 Two stage，但架构相对简单，检测速度更快。</li>
</ul>
<p>所以这次我们选用 One Stage 的有代表性的目标检测算法 YOLO 来实现滑动验证码缺口的识别。</p>
<p>YOLO，英文全称叫作 You Only Look Once，取了它们的首字母就构成了算法名，目前 YOLO 算法最新的版本是 V3 版本，这里算法的具体流程我们就不过多介绍了，如果你感兴趣可以搜一下相关资料了解下，另外也可以了解下 YOLO V1～V3 版本的不同和改进之处，这里列几个参考链接。</p>
<ul>
<li>YOLO V3 论文：<a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></li>
<li>YOLO V3 介绍：<a href="https://zhuanlan.zhihu.com/p/34997279">https://zhuanlan.zhihu.com/p/34997279</a></li>
<li>YOLO V1-V3 对比介绍：<a href="https://www.cnblogs.com/makefile/p/yolov3.html">https://www.cnblogs.com/makefile/p/yolov3.html</a></li>
</ul>
<h4>数据准备</h4>
<p>回归我们本课时的主题，我们要做的是缺口的位置识别，那么第一步应该做什么呢？</p>
<p>我们的目标是要训练深度学习模型，那我们总得需要让模型知道要学点什么东西吧，这次我们做缺口识别，那么我们需要让模型学的就是找到这个缺口在哪里。由于一张验证码图片只有一个缺口，要分类就是一类，所以我们只需要找到缺口位置就行了。</p>
<p>好，那模型要学如何找出缺口的位置，就需要我们提供样本数据让模型来学习才行。样本数据怎样的呢？样本数据就得有带缺口的验证码图片以及我们自己标注的缺口位置。只有把这两部分都告诉模型，模型才能去学习。等模型学好了，当我们再给个新的验证码时，就能检测出缺口在哪里了，这就是一个成功的模型。</p>
<p>OK，那我们就开始准备数据和缺口标注结果吧。</p>
<p>数据这里用的是网易盾的验证码，验证码图片可以自行收集，写个脚本批量保存下来就行。标注的工具可以使用 LabelImg，GitHub 链接为：<a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a>，利用它我们可以方便地进行检测目标位置的标注和类别的标注，如这里验证码和标注示例如下：</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/8B/50/Cgq2xl6dW4OAffxPAAmrTFP3fXg210.png" alt="4.png"></p>
<p>标注完了会生成一系列 xml 文件，你需要解析 xml 文件把位置的坐标和类别等处理一下，转成训练模型需要的数据。</p>
<p>在这里我已经整理好了我的数据集，完整 GitHub 链接为：<a href="https://github.com/Python3WebSpider/DeepLearningSlideCaptcha">https://github.com/Python3WebSpider/DeepLearningSlideCaptcha</a>，我标注了 200 多张图片，然后处理了 xml 文件，变成训练 YOLO 模型需要的数据格式，验证码图片和标注结果见 data/captcha 文件夹。</p>
<p>如果要训练自己的数据，数据格式准备见：<a href="https://github.com/eriklindernoren/PyTorch-YOLOv3#train-on-custom-dataset">https://github.com/eriklindernoren/PyTorch-YOLOv3#train-on-custom-dataset</a></p>
<h4>初始化</h4>
<p>上一步我已经把标注好的数据处理好了，可以直接拿来训练了。</p>
<p>由于 YOLO 模型相对比较复杂，所以这个项目我就直接基于开源的 PyTorch-YOLOV3 项目来进行修改了，模型使用的深度学习框架为 PyTorch，具体的 YOLO V3 模型的实现这里不再阐述了。</p>
<p>另外推荐使用 GPU 训练，不然拿 CPU 直接训练速度会很慢。我的 GPU 是 P100，几乎十几秒就训练完一轮。</p>
<p>下面就直接把代码克隆下来吧。</p>
<p>由于本项目我把训练好的模型也放上去了，使用了 Git LFS，所以克隆时间较长，克隆命令如下：</p>
<pre><code data-language="js" class="lang-js">git clone https:<span class="hljs-comment">//github.com/Python3WebSpider/DeepLearningSlideCaptcha.git</span>
</code></pre>
<p>如果想加速克隆，可以暂时先跳过大文件模型下载，可以执行命令：</p>
<pre><code data-language="js" class="lang-js">GIT_LFS_SKIP_SMUDGE=<span class="hljs-number">1</span> git clone https:<span class="hljs-comment">//github.com/Python3WebSpider/DeepLearningSlideCaptcha.git</span>
</code></pre>
<h4>环境安装</h4>
<p>代码克隆下载之后，我们还需要下载一些预训练模型。</p>
<p>YOLOV3 的训练要加载预训练模型才能有不错的训练效果，预训练模型下载命令如下：</p>
<pre><code data-language="js" class="lang-js">bash prepare.sh
</code></pre>
<p>执行这个脚本，就能下载 YOLO V3 模型的一些权重文件，包括 yolov3 和 weights，还有 darknet 的 weights，在训练之前我们需要用这些权重文件初始化 YOLO V3 模型。</p>
<blockquote>
<p>注意：Windows 下建议使用 Git Bash 来运行上述命令。</p>
</blockquote>
<p>另外还需要安装一些必须的库，如 PyTorch、TensorBoard 等，建议使用 Python 虚拟环境，运行命令如下：</p>
<pre><code data-language="js" class="lang-js">pip3 install -r requirements.txt
</code></pre>
<p>这些库都安装好了之后，就可以开始训练了。</p>
<h4>训练</h4>
<p>本项目已经提供了标注好的数据集，在 data/captcha，可以直接使用。</p>
<p>当前数据训练脚本：</p>
<pre><code data-language="js" class="lang-js">bash train.sh
</code></pre>
<p>实测 P100 训练时长约 15 秒一个 epoch，大约几分钟即可训练出较好效果。</p>
<p>训练差不多了，我们便可以使用 TensorBoard 来看看 loss 和 mAP 的变化，运行 TensorBoard：</p>
<pre><code data-language="js" class="lang-js">tensorboard --logdir=<span class="hljs-string">'logs'</span> --port=<span class="hljs-number">6006</span> --host <span class="hljs-number">0.0</span><span class="hljs-number">.0</span><span class="hljs-number">.0</span>
</code></pre>
<p>loss_1 变化如下：</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/05/0D/CgoCgV6dXTKAfgtfAAA6KqSjdxM383.png" alt="5.png"></p>
<p>val_mAP 变化如下：</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/12/3C/Ciqah16dXTqAbsXfAABBNhdjyNM911.png" alt="6.png"></p>
<p>可以看到 loss 从最初的非常高下降到了很低，准确率也逐渐接近 100%。</p>
<p>另外训练过程中还能看到如下的输出结果：</p>
<pre><code data-language="js" class="lang-js">---- [Epoch <span class="hljs-number">99</span>/<span class="hljs-number">100</span>, Batch <span class="hljs-number">27</span>/<span class="hljs-number">29</span>] ----
+------------+--------------+--------------+--------------+
| Metrics    | YOLO Layer <span class="hljs-number">0</span> | YOLO Layer <span class="hljs-number">1</span> | YOLO Layer <span class="hljs-number">2</span> |
+------------+--------------+--------------+--------------+
| grid_size  | <span class="hljs-number">14</span>           | <span class="hljs-number">28</span>           | <span class="hljs-number">56</span>           |
| loss       | <span class="hljs-number">0.028268</span>     | <span class="hljs-number">0.046053</span>     | <span class="hljs-number">0.043745</span>     |
| x          | <span class="hljs-number">0.002108</span>     | <span class="hljs-number">0.005267</span>     | <span class="hljs-number">0.008111</span>     |
| y          | <span class="hljs-number">0.004561</span>     | <span class="hljs-number">0.002016</span>     | <span class="hljs-number">0.009047</span>     |
| w          | <span class="hljs-number">0.001284</span>     | <span class="hljs-number">0.004618</span>     | <span class="hljs-number">0.000207</span>     |
| h          | <span class="hljs-number">0.000594</span>     | <span class="hljs-number">0.000528</span>     | <span class="hljs-number">0.000946</span>     |
| conf       | <span class="hljs-number">0.019700</span>     | <span class="hljs-number">0.033624</span>     | <span class="hljs-number">0.025432</span>     |
| cls        | <span class="hljs-number">0.000022</span>     | <span class="hljs-number">0.000001</span>     | <span class="hljs-number">0.000002</span>     |
| cls_acc    | <span class="hljs-number">100.00</span>%      | <span class="hljs-number">100.00</span>%      | <span class="hljs-number">100.00</span>%      |
| recall50   | <span class="hljs-number">1.000000</span>     | <span class="hljs-number">1.000000</span>     | <span class="hljs-number">1.000000</span>     |
| recall75   | <span class="hljs-number">1.000000</span>     | <span class="hljs-number">1.000000</span>     | <span class="hljs-number">1.000000</span>     |
| precision  | <span class="hljs-number">1.000000</span>     | <span class="hljs-number">0.800000</span>     | <span class="hljs-number">0.666667</span>     |
| conf_obj   | <span class="hljs-number">0.994271</span>     | <span class="hljs-number">0.999249</span>     | <span class="hljs-number">0.997762</span>     |
| conf_noobj | <span class="hljs-number">0.000126</span>     | <span class="hljs-number">0.000158</span>     | <span class="hljs-number">0.000140</span>     |
+------------+--------------+--------------+--------------+
Total loss <span class="hljs-number">0.11806630343198776</span>
</code></pre>
<p>这里显示了训练过程中各个指标的变化情况，如 loss、recall、precision、confidence 等，分别代表训练过程的损失（越小越好）、召回率（能识别出的结果占应该识别出结果的比例，越高越好）、精确率（识别出的结果中正确的比率，越高越好）、置信度（模型有把握识别对的概率，越高越好），可以作为参考。</p>
<h4>测试</h4>
<p>训练完毕之后会在 checkpoints 文件夹生成 pth 文件，可直接使用模型来预测生成标注结果。</p>
<p>如果你没有训练自己的模型的话，这里我已经把训练好的模型放上去了，可以直接使用我训练好的模型来测试。如之前跳过了 Git LFS 文件下载，则可以使用如下命令下载 Git LFS 文件：</p>
<pre><code data-language="js" class="lang-js">git lfs pull
</code></pre>
<p>此时 checkpoints 文件夹会生成训练好的 pth 文件。</p>
<p>测试脚本：</p>
<pre><code data-language="js" class="lang-js">sh detect.sh
</code></pre>
<p>该脚本会读取 captcha 下的 test 文件夹所有图片，并将处理后的结果输出到 result 文件夹。</p>
<p>运行结果样例：</p>
<pre><code data-language="js" class="lang-js">Performing object detection:
        + Batch <span class="hljs-number">0</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.044223</span>
        + Batch <span class="hljs-number">1</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.028566</span>
        + Batch <span class="hljs-number">2</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.029764</span>
        + Batch <span class="hljs-number">3</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.032430</span>
        + Batch <span class="hljs-number">4</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.033373</span>
        + Batch <span class="hljs-number">5</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.027861</span>
        + Batch <span class="hljs-number">6</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.031444</span>
        + Batch <span class="hljs-number">7</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.032110</span>
        + Batch <span class="hljs-number">8</span>, Inference Time: <span class="hljs-number">0</span>:<span class="hljs-number">00</span>:<span class="hljs-number">00.029131</span>

Saving images:
(<span class="hljs-number">0</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4497.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99999</span>
(<span class="hljs-number">1</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4498.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99999</span>
(<span class="hljs-number">2</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4499.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99997</span>
(<span class="hljs-number">3</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4500.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99999</span>
(<span class="hljs-number">4</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4501.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99997</span>
(<span class="hljs-number">5</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4502.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99999</span>
(<span class="hljs-number">6</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4503.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99997</span>
(<span class="hljs-number">7</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4504.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99998</span>
(<span class="hljs-number">8</span>) Image: <span class="hljs-string">'data/captcha/test/captcha_4505.png'</span>
        + Label: target, <span class="hljs-attr">Conf</span>: <span class="hljs-number">0.99998</span>
</code></pre>
<p>拿几个样例结果看下：</p>
<p><img src="https://s0.lgstatic.com/i/image3/M01/05/0E/CgoCgV6dXamAbOLDAALPfVGbpFE467.png" alt="7.png"><br>
<img src="https://s0.lgstatic.com/i/image3/M01/8B/53/Cgq2xl6dXbGAOPAzAAKfofXm6vo290.png" alt="8.png"><br>
<img src="https://s0.lgstatic.com/i/image3/M01/8B/53/Cgq2xl6dXbeAKiqQAALeTg7slfU302.png" alt="9.png"></p>
<p>这里我们可以看到，利用训练好的模型我们就成功识别出缺口的位置了，另外程序还会打印输出这个边框的中心点和宽高信息。</p>
<p>有了这个边界信息，我们再利用某些手段拖动滑块即可通过验证了，比如可以模拟加速减速过程，或者可以录制人的轨迹再执行都是可以的，由于本课时更多是介绍深度学习识别相关内容，所以关于拖动轨迹不再展开讲解。</p>
<h4>总结</h4>
<p>本课时我们介绍了使用深度学习识别滑动验证码缺口的方法，包括标注、训练、测试等环节都进行了阐述。有了它，我们就能轻松方便地对缺口进行识别了。</p>
<p>代码：<a href="https://github.com/Python3WebSpider/DeepLearningSlideCaptcha">https://github.com/Python3WebSpider/DeepLearningSlideCaptcha</a></p>

---

### 精选评论

##### **明：
> 我要加学习群，群号呢

 ###### &nbsp;&nbsp;&nbsp; 官方客服回复：
> &nbsp;&nbsp;&nbsp; 可以添加运营小姐姐微信lagoujuzi，回复 爬虫 ，拉你入群

##### **佳：
> 长知识了

##### bing wu：
> 深度学习这块好难呀

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 有什么具体问题可以加入学习群和崔大一起沟通

