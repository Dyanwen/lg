<p data-nodeid="4871" class="">上一讲我们主要学习了数据分析模型基础中的回归模型与相关性模型，这两个模型都是为了解决原因分析类问题，如资源投放、因素判断等。而今天要介绍的聚类分析模型主要解决的是产品、用户的分类问题，掌握这部分内容能够使你快速应对大多数分类场景，如客户类型管理、用户群分析等。</p>
<p data-nodeid="4872">首先我们要了解的问题就是——何为聚类？</p>
<p data-nodeid="4873"><strong data-nodeid="4984">什么是聚类？</strong></p>
<p data-nodeid="4874">在提起聚类这个概念的时候，很多人都会将其与分类这个概念混淆。我们不妨举一个例子来说明一下二者的区别。</p>
<p data-nodeid="4875">某电商 App 平台的用户分为潜在用户、普通用户、活跃用户、沉睡用户四种，其定义分别如下。</p>
<ul data-nodeid="4876">
<li data-nodeid="4877">
<p data-nodeid="4878">潜在用户是指下载但是未激活注册的用户；</p>
</li>
<li data-nodeid="4879">
<p data-nodeid="4880">沉睡用户是指注册激活，且周活跃率（一周内有多少天登陆）在 20% 以下的用户；</p>
</li>
<li data-nodeid="4881">
<p data-nodeid="4882">普通用户是指注册激活，且周活跃率在 60% 以下的用户；</p>
</li>
<li data-nodeid="4883">
<p data-nodeid="4884">活跃用户是指注册激活，且周活跃率在 60% 以上的用户；</p>
</li>
</ul>
<p data-nodeid="4885">目前运营人员给了你一份用户名单（表 1），其中包含了所有用户的周活跃率以及下载激活情况，想让你对这些客户按照一定的规则进行类别划分，这种方式就叫作分类。</p>
<p data-nodeid="4886"><img src="https://s0.lgstatic.com/i/image/M00/6E/DB/CgqCHl-zm_6ARFb_AABi0prtaVs891.png" alt="Drawing 1.png" data-nodeid="4994"></p>
<p data-nodeid="4887">也就是说，分类是已经知道样本数据特征的前提下，对新数据进行判定的方式，更直观的例子就是让你按照性别对用户进行分类，“性别”就是分类的数据特征。</p>
<p data-nodeid="4888">那么如果运营人员给你的名单是表 2 这样的，里面并没有活跃率的指标，也让你对这些客户按照一定的规则进行分类，而且也必须分为潜在用户、普通用户、活跃用户、沉睡用户四种，你该怎么做？</p>
<p data-nodeid="4889"><img src="https://s0.lgstatic.com/i/image/M00/6E/D0/Ciqc1F-znAaAbozWAABYXqN-SCo715.png" alt="Drawing 3.png" data-nodeid="4999"></p>
<p data-nodeid="4890">这时候你可能就会产生疑问，我不知道分类的标准和规则，怎么去对这些数据分类呢？因此，聚类的方法就自然出现了，简而言之就是在不知道数据特征的前提下，对所有数据的内在特征进行推理，也就是自己去找到分类的“判定标准”。</p>
<p data-nodeid="4891">在聚类的结论出来之前，我完全不知道每一类有什么特点，一定要根据聚类的结果并结合人的经验来分析，看看聚成的这一类数据大概有什么特点。</p>
<p data-nodeid="4892">比如你可以选择下单频率这个指标作为判定标准，将所有的数据按照一定的算法划归成四类或者四组，并且保证每一组内的数据都具有类似的下单频率，也就是保证不同组之间的数据具有不同的属性，这就是聚类算法的本质。</p>
<p data-nodeid="4893">用一句话总结一下聚类的本质就是：<strong data-nodeid="5008">近朱者赤，近墨者黑</strong>。</p>
<p data-nodeid="4894">那么聚类的好处是什么呢？我们不妨还举上面的例子。</p>
<p data-nodeid="4895">运营人员还是让你根据表 2 中的名单将客户分成四类，这个时候你首先要找到分类指标是下单频率；其次你要明确分类量级，怎么划归到对应的组类上，也就是要定义下单频次多少才划分为沉睡用户，下单频次多少才划分为活跃用户？</p>
<p data-nodeid="4896">这时候你可能就会说，既然不知道分类量级，那就随便定一个吧，比如下面这种标准。</p>
<ul data-nodeid="4897">
<li data-nodeid="4898">
<p data-nodeid="4899">下单频次在 25% 以下的为潜在用户；</p>
</li>
<li data-nodeid="4900">
<p data-nodeid="4901">下单频次在 25%-50% 之间的为沉睡用户；</p>
</li>
<li data-nodeid="4902">
<p data-nodeid="4903">下单频次在 50%-75% 之间的为普通用户；</p>
</li>
<li data-nodeid="4904">
<p data-nodeid="4905">下单频次在 75%-100% 之间的为活跃用户。</p>
</li>
</ul>
<p data-nodeid="4906">看上去还不错，但是有可能用户的下单频次普遍都在 50% 以下，那么最终你根据这个分类量级规则划分出的数据情况就会如下图所示：</p>
<p data-nodeid="4907"><img src="https://s0.lgstatic.com/i/image/M00/6E/DB/CgqCHl-znBGAQVhqAAAZn32_1W8108.png" alt="Drawing 4.png" data-nodeid="5019"></p>
<div data-nodeid="4908"><p style="text-align:center">图 1 下单率</p></div>
<p data-nodeid="4909">你会发现所有的数据都在 35% 以下，连普通用户都几乎没有，为什么会出现这个情况？是因为这个划分标准是你“拍脑袋”定的，这就是普通分类方法的弊端，它必须按照已知的规则对数据进行划分，这个规则不一定真的能够代表数据之间的真实联系。</p>
<p data-nodeid="4910">而聚类则不同，它是不断推测数据之间的联系规则，从而将数据进行族类划分，也就是去挖掘数据内部的规律，摸索出一个分类规则。因此，聚类常常被用到数据分析、数据挖掘、大数据计算等领域，因为它是一种科学的分类方法。</p>
<h3 data-nodeid="4911">K-Means 聚类法</h3>
<p data-nodeid="4912">从上面我们知道聚类的关键就是要通过某个算法找到数据分类规则，那么怎么通过聚类方法去找分类标准呢？</p>
<p data-nodeid="4913">其核心就在于推理算法，聚类有非常多的挖掘算法，而最常见、最常用的聚类算法就是 K-Means 聚类法。这种方法很简单，也很有效，在很多分析软件上都能进行算法计算。</p>
<p data-nodeid="4914">首先，我们介绍一下 K-Means 算法的原理，我用一个形象化的例子给你解释。</p>
<p data-nodeid="4915">这里有一群数据，它有两个维度的指标 X 与 Y，我们想要将其分成 2 组，保证每组之间的数据拥有不同的特征。利用的方法简而言之就是“找大哥”，从所有数据当中找到两个大哥，定义为 A 与 B，并且保证 A 周围的数据与 B 周围的数据特征不同。</p>
<p data-nodeid="4916"><img src="https://s0.lgstatic.com/i/image/M00/6E/DB/CgqCHl-znISAa-jMAAAnZwfeMJw284.png" alt="Drawing 6.png" data-nodeid="5029"></p>
<p data-nodeid="4917">那么怎么去找到这两个“大哥”呢？这里就要用到 K-Means 算法，其计算过程如下。</p>
<h4 data-nodeid="4918">算法计算过程</h4>
<p data-nodeid="4919"><strong data-nodeid="5035">1.确定分组数</strong></p>
<p data-nodeid="4920">首先我们要确定将数据分成几组或者几类，在 K-Means 算法中我们将分组数定义为 K，一般来说，K 越多计算过程越复杂。</p>
<p data-nodeid="4921">那么在上面的例子中，K=2。</p>
<p data-nodeid="4922"><strong data-nodeid="5041">2.第一次“找大哥”</strong></p>
<p data-nodeid="4923">第二步我们就要挑选两个数据作为大哥，但是因为是第一次挑选，我们不知道这两个数据究竟能不能作为大哥，为了方便直观理解，我们先将所有数据放到散点坐标中，制作一张横纵坐标图，如下所示：</p>
<p data-nodeid="4924"><img src="https://s0.lgstatic.com/i/image/M00/6E/D1/Ciqc1F-zneeASxiYAAAv6Jh6dMw995.png" alt="Lark20201117-175420.png" data-nodeid="5045"></p>
<p data-nodeid="4925">通过散点图我们还是不知道该怎么挑选大哥，因此我们就随机挑选两个数据，比如这里就以前两个数据作为数据中心，暂时定义为 A、B。</p>
<p data-nodeid="4926"><img src="https://s0.lgstatic.com/i/image/M00/6E/DC/CgqCHl-znfSABTlmAAA2VPaOsSI136.png" alt="Lark20201117-175424.png" data-nodeid="5049"></p>
<p data-nodeid="4927"><strong data-nodeid="5053">3.计算其他数据与“大哥”的距离</strong></p>
<p data-nodeid="4928">第三步我们就要确认一下这两个大哥是不是真的能代表两种数据组类，也就是判断一下数据中心周围的数据是否真的具有相似性。</p>
<p data-nodeid="4929">那么用什么标准去判断呢？方法也有很多，这里我们以欧氏距离为例，所谓的欧氏距离简单说就是空间距离，用空间中两个数据点的空间距离表示二者的远近，最简单的例子就是勾股定理，也就是二维空间下的空间距离计算。其完整公式如下：</p>
<p data-nodeid="4930"><img src="https://s0.lgstatic.com/i/image/M00/6E/D0/Ciqc1F-znPmAYXOeAAAMiq_d4Ww021.png" alt="Drawing 12.png" data-nodeid="5058"></p>
<p data-nodeid="4931">这个时候我们将其他数据的坐标代入到上面的坐标中去，计算出每个数据与每个大哥（数据中心）A、B 的距离，哪个数据离 A 更近谁就是 A 组，哪个数据离 B 更近谁就是 B 组。</p>
<p data-nodeid="4932">最后我们计算出每个数据与 A、B 的距离，如下表所示：</p>
<p data-nodeid="4933"><img src="https://s0.lgstatic.com/i/image/M00/6E/DC/CgqCHl-znQOAdl2UAAAz9hWk7wI002.png" alt="Drawing 14.png" data-nodeid="5063"></p>
<p data-nodeid="4934">从计算结果可以看出，哪几个数据距离 A 更近，哪几个数据距离 B 更近。这时候我们就可以进行第一次分组，如下表所示：</p>
<p data-nodeid="4935"><img src="https://s0.lgstatic.com/i/image/M00/6E/DC/CgqCHl-znQ6AVH_MAAAsGEuxFuA989.png" alt="Drawing 16.png" data-nodeid="5067"></p>
<p data-nodeid="4936"><strong data-nodeid="5071">4.重新选一次大哥</strong></p>
<p data-nodeid="4937">根据上面的步骤我们已经进行了第一次的分组，接下来我们继续重复前面两个步骤，在每一组内再各自挑出一个大哥，计算方法很简单，通过计算组内平均值即可。如 A 组一共有（1，0）（2，2）（4，3）（4，5）这个四个数据，其 X 与 Y 的平均值为（2.75，2.5），这个数据点就是 A 组的“新大哥”。</p>
<p data-nodeid="4938">同理我们再找出 B 组的新大哥是（2，0），我们将这两个新大哥在坐标图中标注出来，如图所示：</p>
<p data-nodeid="4939"><img src="https://s0.lgstatic.com/i/image/M00/73/74/Ciqc1F_GA7aAeX_rAAA7L_k1snA659.png" alt="Lark20201201-164930.png" data-nodeid="5076"></p>
<p data-nodeid="4940">这时候我们就会发现，“新大哥”的位置发生了变化，上面四个数据距离 A 更近，下面两个数据距离 B 更近，他们具有不同的数据特征。</p>
<p data-nodeid="4941"><strong data-nodeid="5081">5.再次计算其他数据与“大哥”的距离</strong></p>
<p data-nodeid="4942">找出了“新大哥”，我们就要再计算一遍其他数据点与新数据中心的距离，代入到欧式距离公式中即可得出结果，如下表所示：</p>
<p data-nodeid="4943"><img src="https://s0.lgstatic.com/i/image/M00/6E/D0/Ciqc1F-znSqAAVLxAAA3p1aPARo881.png" alt="Drawing 20.png" data-nodeid="5085"></p>
<p data-nodeid="4944">依然同理，从计算结果可以看出，哪几个数据距离 A 更近，哪几个数据距离 B 更近，这时候我们就可以进行第二次分组，如下表所示：</p>
<p data-nodeid="4945"><img src="https://s0.lgstatic.com/i/image/M00/6E/D1/Ciqc1F-znZ6AOoyzAAAsN4FNpyg676.png" alt="Lark20201117-175314.png" data-nodeid="5089"></p>
<p data-nodeid="4946">这里我们看到分组情况就会发现，分组情况与上一次没有发生变化！这说明无论我们再怎么选择新的大哥，这两组数据的分类已经不会再产生任何变化了，也就意味着计算收敛已经结束，K-means 聚类算法已经将所有数据分成了两组互不类似的组类，如下图所示：</p>
<p data-nodeid="4947"><img src="https://s0.lgstatic.com/i/image/M00/73/80/CgqCHl_GA9GAe5hrAABn1mTQEEc321.png" alt="Lark20201201-164935.png" data-nodeid="5093"></p>
<h4 data-nodeid="4948">方法总结</h4>
<p data-nodeid="4949">简单来说，我们一次次重复“选择数据中心 - 计算距离 - 分组 - 再次选择数据中心”的流程，直到分组之后所有的数据都不会再变化了，也就得到了最终的聚合结果。</p>
<p data-nodeid="4950">明白了聚类分析的思路和方法，我们怎么应用到实际中呢？面对大量数据的时候我们该怎么办？如果分类数很多的情况该怎么做呢？</p>
<h3 data-nodeid="4951">K-Means 聚类法实操</h3>
<p data-nodeid="4952">能够实现聚类功能的多为数据挖掘软件，比较常见的就是 SPSS，其中内嵌了二阶聚类、K-Means 聚类、系统聚类等多种聚类方法，实现起来也比较简单。我们通过 SPSS 将数据导入，点击上方菜单栏的“分析”，从下拉的“分类”中点击“K-Means 聚类”。</p>
<p data-nodeid="4953"><img src="https://s0.lgstatic.com/i/image/M00/6E/D1/Ciqc1F-znWqAK_jlAAPyy0ovCEg774.png" alt="Drawing 24.png" data-nodeid="5101"></p>
<div data-nodeid="4954"><p style="text-align:center">图 6  步骤一</p></div>
<p data-nodeid="4955">然后我们就会进入到选项界面，首先要将变量 X、Y 拖入到框中，聚类数也就是 K 值，按照自己的需求进行设定；聚类方法一般选择的是“迭代与分类”，聚类中心一般不用选择，除非你想自己设定聚类中心。</p>
<p data-nodeid="4956"><img src="https://s0.lgstatic.com/i/image/M00/6E/DC/CgqCHl-znbOAQkGtAAFqg9vl5Tw866.png" alt="Drawing 25.png" data-nodeid="5105"></p>
<div data-nodeid="4957"><p style="text-align:center">图 7  步骤二</p></div>
<p data-nodeid="4958">右侧的“迭代”选项可以设定迭代的次数和终止条件，一般是默认收敛条件为 0，也就是迭代到分类不再发生变化为止。</p>
<p data-nodeid="4959">输出结果中就可以看到最终每个数据的分组情况（QCL_1），以及聚类后每个数据与中心点的距离（QCL_2），如下图所示：</p>
<p data-nodeid="4960"><img src="https://s0.lgstatic.com/i/image/M00/6E/DC/CgqCHl-znbmAdr2mAAGI2gOfpNg596.png" alt="Drawing 26.png" data-nodeid="5114"></p>
<div data-nodeid="4961"><p style="text-align:center">图 8  步骤三</p></div>
<p data-nodeid="4962">其实你只要了解聚类分析当中各种概念的意义，再用工具实现起来就非常简单了。</p>
<h3 data-nodeid="4963">总结</h3>
<p data-nodeid="4964">本课时我们主要讲解了聚类模型的本质，和 K-means 聚类法的原理及实操。</p>
<p data-nodeid="4965">其实聚类的本质就是“近朱者赤，近墨者黑”，它是不断推测数据之间的联系规则，从而将数据进行划分族类，也就是去挖掘数据内部的规律，“摸索”出一个分类规则。</p>
<p data-nodeid="4966"><img src="https://s0.lgstatic.com/i/image/M00/6E/DC/CgqCHl-znh2Acd-QAAEDXz5tryY355.png" alt="Lark20201117-175519.png" data-nodeid="5121"></p>
<h3 data-nodeid="4967">教学相长</h3>
<p data-nodeid="4968">上一讲我们主要学习了回归模型当中的检验方法，课后留了一些关于 T 参数、P 值等含义的问题，下面我将一一解答：</p>
<ul data-nodeid="4969">
<li data-nodeid="4970">
<p data-nodeid="4971">T 参数存在的意义就是表示因子的显著性，是为了比较因变量与自变量之间变化的差异程度，就是看这个因子变化剧烈时，最终值是否也变化剧烈；</p>
</li>
<li data-nodeid="4972">
<p data-nodeid="4973">相关性不需要看 coefficient ，而是要看 T 参数，因为 coefficient 是为了体现对最终值大小的影响程度，T 检验是体现对最终值变化程度大小的影响程度；</p>
</li>
<li data-nodeid="4974">
<p data-nodeid="4975">P 值不具有统计学的含义，以偶然性造成最终值变化的概率很小，也就是说 P&gt;0.05，说明这件事作为偶然性事件发生的概率比较大，因为是偶然事件，所以不具有统计学意义。</p>
</li>
</ul>
<p data-nodeid="4976">关于本讲内容的问题你可以在下方留言，我会及时给你答疑解惑！同时也欢迎你关注我本人的公众号（微信搜索：数据分析不是个事儿），之后会定期更新原创高质量的数据分析文章。</p>
<p data-nodeid="4977"><a href="https://shenceyun.lagou.com/t/Jka" data-nodeid="5132"><img src="https://s0.lgstatic.com/i/image/M00/6C/D8/CgqCHl-roqGAN8UnABMkdzfcUXs455.png" alt="Lark20201111-163519.png" data-nodeid="5131"></a></p>
<p data-nodeid="4978" class="te-preview-highlight">阿里 P7 数据分析师的进阶之路，<a href="https://shenceyun.lagou.com/t/Jka" data-nodeid="5136">点击链接，全面赋能！</a></p>

---

### 精选评论

##### Vicky：
> 如果说根据用户的收入和消费情况来分成三种阶层，那么k值就是2吗？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 分成三种阶层，就说明有三个数据中心，则K=3；K的取值不看分析的维度有多少，而要看最终的数据分类数有多少。

##### **阳：
> 实例中大哥K=2，为啥选两个大哥呢

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 因为K是数据中心，我们要选出两个大哥，也就是两个数据组类。

