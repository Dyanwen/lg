<p data-nodeid="37495">第 29 课时讲过，在计算 PV 和 UV 的过程中关键的一个步骤就是进行日志数据的清洗。实际上在其他业务，比如订单数据的统计中，我们也需要过滤掉一些“脏数据”。</p>



<p data-nodeid="37127">所谓“脏数据”是指与我们定义的标准数据结构不一致，或者不需要的数据。因为在数据清洗 ETL 的过程中经常需要进行数据的反序列化解析和 Java 类的映射，在这个映射过程中“脏数据”会导致反序列化失败，从而使得任务失败进行重启。在一些大作业中，重启会导致任务不稳定，而过多的“脏数据”会导致我们的任务频繁报错，最终彻底失败。</p>
<h3 data-nodeid="37761">架构</h3>
<p data-nodeid="37762" class=""><img src="https://s0.lgstatic.com/i/image/M00/3A/D9/Ciqc1F8ii-SAHBJTAAFaSnabmZI145.png" alt="image.png" data-nodeid="37766"></p>


<p data-nodeid="37130">我们在第 30 课时中提过整个 PV 和 UV 计算过程中的数据处理架构，其中使用 Flume 收集业务数据并且发送到 Kafka 中，那么在计算 PV、UV 前就需要消费 Kafka 中的数据，并且将“脏数据”过滤掉。</p>
<p data-nodeid="38031">在实际业务中，我们消费原始 Kafka 日志数据进行处理后，会同时把明细数据写到类似 Elasticsearch 这样的引擎中查询；也会把汇总数据写入 HBase 或者 Redis 等数据库中提供给前端查询展示用。同时，还会把数据再次写入 Kafka 中提供给其他业务使用。</p>
<p data-nodeid="38032" class=""><img src="https://s0.lgstatic.com/i/image/M00/3A/D9/Ciqc1F8ii_aAKfanAAGn-aiNv_Y140.png" alt="image (1).png" data-nodeid="38040"></p>


<h3 data-nodeid="37133">日志清洗</h3>
<p data-nodeid="37134">我们的原始数据被处理成 JSON 的形式发送到 Kafka 中，将原始数据反序列化成对应的访问日志对象进行计算，过滤掉一些“不合法”数据，比如访问者 ID 为空等。在这个过程中我们的 Source 是 Kafka Consumer，并且使用处理时间作为时间特征。</p>
<p data-nodeid="37135">首先新建环境，设置检查点等参数：</p>
<pre class="lang-java" data-nodeid="38330"><code data-language="java">StreamExecutionEnviro nment env = StreamExecutionEnvironment.getExecutionEnvironment(); 
env.getCheckpointConfig().setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE); 
env.enableCheckpointing(<span class="hljs-number">5000</span>); 
</code></pre>


<p data-nodeid="37137">接下来介入 Kafka Source，我们在第 30 课时中用 Flume 将收集到的原始日志写到了名为 log_kafka 的 Topic 中，Flume 的配置如下：</p>
<pre class="lang-powershell" data-nodeid="37138"><code data-language="powershell"><span class="hljs-comment">#sink配置 </span>
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink 
a1.sinks.k1.topic = log_kafka 
a1.sinks.k1.brokerList = <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">9092</span> 
a1.sinks.k1.requiredAcks = <span class="hljs-number">1</span> 
a1.sinks.k1.batchSize = <span class="hljs-number">20</span> 
</code></pre>
<p data-nodeid="37139">我们构造的 Kafka Consumer 属性如下：</p>
<pre class="lang-powershell" data-nodeid="37140"><code data-language="powershell">Properties properties = new Properties(); 
properties.setProperty(<span class="hljs-string">"bootstrap.servers"</span>, <span class="hljs-string">"127.0.0.1:9092"</span>); 
//设置消费组 
FlinkKafkaConsumer&lt;String&gt; consumer = new FlinkKafkaConsumer&lt;&gt;(<span class="hljs-string">"log_kafka"</span>, new SimpleStringSchema(), properties); 
</code></pre>
<p data-nodeid="37141">使用 Filter 算子和将不合法的数据过滤。过滤的逻辑是：如果消息体中 userId 为空或者事件消息不是“点击”的事件。</p>
<p data-nodeid="37142">定义的消息格式如下所示：</p>
<pre class="lang-java" data-nodeid="37143"><code data-language="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UserClick</span> </span>{ 
    <span class="hljs-keyword">private</span> String userId; 
    <span class="hljs-keyword">private</span> Long timestamp; 
    <span class="hljs-keyword">private</span> String action; 
    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getUserId</span><span class="hljs-params">()</span> </span>{ 
        <span class="hljs-keyword">return</span> userId; 
    } 
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setUserId</span><span class="hljs-params">(String userId)</span> </span>{ 
        <span class="hljs-keyword">this</span>.userId = userId; 
    } 
    <span class="hljs-function"><span class="hljs-keyword">public</span> Long <span class="hljs-title">getTimestamp</span><span class="hljs-params">()</span> </span>{ 
        <span class="hljs-keyword">return</span> timestamp; 
    } 
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setTimestamp</span><span class="hljs-params">(Long timestamp)</span> </span>{ 
        <span class="hljs-keyword">this</span>.timestamp = timestamp; 
    } 
    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getAction</span><span class="hljs-params">()</span> </span>{ 
        <span class="hljs-keyword">return</span> action; 
    } 
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setAction</span><span class="hljs-params">(String action)</span> </span>{ 
        <span class="hljs-keyword">this</span>.action = action; 
    } 
} 
<span class="hljs-keyword">enum</span> UserAction{ 
    <span class="hljs-comment">//点击 </span>
    CLICK(<span class="hljs-string">"CLICK"</span>), 
    <span class="hljs-comment">//购买 </span>
    PURCHASE(<span class="hljs-string">"PURCHASE"</span>), 
    <span class="hljs-comment">//其他 </span>
    OTHER(<span class="hljs-string">"OTHER"</span>); 
    <span class="hljs-keyword">private</span> String action; 
    UserAction(String action) { 
        <span class="hljs-keyword">this</span>.action = action; 
    } 
} 
</code></pre>
<p data-nodeid="37144">我们简化后的消息体如上，其中 userId 为用户的 ID，timestamp 是时间戳，UserAction 是用户动作枚举：点击、购买和其他。我们需要其中的“点击”事件。</p>
<p data-nodeid="37145">首先需要过滤掉字符串中明显不合法的数据：</p>
<pre class="lang-java" data-nodeid="37146"><code data-language="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UserActionFilter</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">FilterFunction</span>&lt;<span class="hljs-title">String</span>&gt; </span>{ 
    <span class="hljs-meta">@Override</span> 
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">boolean</span> <span class="hljs-title">filter</span><span class="hljs-params">(String input)</span> <span class="hljs-keyword">throws</span> Exception </span>{ 
        <span class="hljs-keyword">return</span> input.contains(<span class="hljs-string">"CLICK"</span>) &amp;&amp; input.startsWith(<span class="hljs-string">"{"</span>) &amp;&amp; input.endsWith(<span class="hljs-string">"}"</span>); 
    } 
} 
</code></pre>
<p data-nodeid="37147">在实际生产中，我们的日志数据并不像我们想象的那样规范，其中有可能夹杂大量的“非法数据”，这些数据需要根据业务需求进行过滤。</p>
<p data-nodeid="37148">我们在这里只获取那些用户事件为“点击”的消息，并且需要满足 JSON 格式数据的基本要求：以“{" 开头，以 "}”结尾。</p>
<p data-nodeid="37149">然后在 FlatMap 中进一步将日志数据进行处理，过滤掉 userId 为空或者 action 类型为空的数据：</p>
<pre class="lang-java" data-nodeid="37150"><code data-language="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyFlatMapFunction</span> <span class="hljs-keyword">implements</span> <span class="hljs-title">FlatMapFunction</span>&lt;<span class="hljs-title">String</span>,<span class="hljs-title">String</span>&gt; </span>{ 
    <span class="hljs-meta">@Override</span> 
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">flatMap</span><span class="hljs-params">(String input, Collector out)</span> <span class="hljs-keyword">throws</span> Exception </span>{ 
        JSONObject jsonObject = JSON.parseObject(input); 
        String user_id = jsonObject.getString(<span class="hljs-string">"user_id"</span>); 
        String action = jsonObject.getString(<span class="hljs-string">"action"</span>); 
        Long timestamp = jsonObject.getLong(<span class="hljs-string">"timestamp"</span>); 
        <span class="hljs-keyword">if</span>(!StringUtils.isEmpty(user_id) || !StringUtils.isEmpty(action)){ 
            UserClick userClick = <span class="hljs-keyword">new</span> UserClick(); 
            userClick.setUserId(user_id); 
            userClick.setTimestamp(timestamp); 
            userClick.setAction(action); 
            out.collect(JSON.toJSONString(userClick)); 
        } 
    } 
} 
</code></pre>
<p data-nodeid="37151">处理完成的数据最后被转成 JSONString 发往下游：</p>
<pre class="lang-java" data-nodeid="37152"><code data-language="java">env.addSource(consumer) 
        .filter(<span class="hljs-keyword">new</span> UserActionFilter()) 
        .flatMap(<span class="hljs-keyword">new</span> MyFlatMapFunction()) 
        .returns(TypeInformation.of(String.class)) 
        .addSink(<span class="hljs-keyword">new</span> FlinkKafkaProducer( 
                <span class="hljs-string">"127.0.0.1:9092"</span>, 
                <span class="hljs-string">"log_user_action"</span>, 
                <span class="hljs-keyword">new</span> SimpleStringSchema() 
        )); 
</code></pre>
<p data-nodeid="37153">当然你也可以在 ProcessFunction 中将所有的过滤转化逻辑放在一起进行处理。</p>
<pre class="lang-java" data-nodeid="37154"><code data-language="java"><span class="hljs-keyword">public</span> <span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">UserActionProcessFunction</span> <span class="hljs-keyword">extends</span> <span class="hljs-title">ProcessFunction</span>&lt;<span class="hljs-title">String</span>, <span class="hljs-title">String</span>&gt; </span>{ 
    <span class="hljs-meta">@Override</span> 
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">processElement</span><span class="hljs-params">(String input, Context ctx, Collector&lt;String&gt; out)</span> <span class="hljs-keyword">throws</span> Exception </span>{ 
        <span class="hljs-keyword">if</span>(! input.contains(<span class="hljs-string">"CLICK"</span>) || input.startsWith(<span class="hljs-string">"{"</span>) || input.endsWith(<span class="hljs-string">"}"</span>)){ 
            <span class="hljs-keyword">return</span>; 
        } 
        JSONObject jsonObject = JSON.parseObject(input); 
        String user_id = jsonObject.getString(<span class="hljs-string">"user_id"</span>); 
        String action = jsonObject.getString(<span class="hljs-string">"action"</span>); 
        Long timestamp = jsonObject.getLong(<span class="hljs-string">"timestamp"</span>); 
        <span class="hljs-keyword">if</span>(!StringUtils.isEmpty(user_id) || !StringUtils.isEmpty(action)){ 
            UserClick userClick = <span class="hljs-keyword">new</span> UserClick(); 
            userClick.setUserId(user_id); 
            userClick.setTimestamp(timestamp); 
            userClick.setAction(action); 
            out.collect(JSON.toJSONString(userClick)); 
        } 
    } 
} 
</code></pre>
<p data-nodeid="37155">我们在上面的例子中将数据发送到了新的 Kafka Topic 中，当然在实际业务中你也可以发往 Elasticsearch、MySQL 等数据库中查询明细。这里我们将处理干净的数据发往了新的 Kafka Topic 中。</p>
<p data-nodeid="37156">到目前为止，我们的数据就被清理干净了，在后续的业务中，可以直接消费新的 Kafka 数据进行 PV 和 UV 的统计了。</p>
<h3 data-nodeid="37157">总结</h3>
<p data-nodeid="37349">这一课时我们学习了使用 Flink 进行数据清洗 ETL 的过程，在实际业务中数据的清洗是必不可少的部分，你可以根据业务需要采用不同的清洗策略，将数据存储到新的数据库中。</p>

---

### 精选评论


