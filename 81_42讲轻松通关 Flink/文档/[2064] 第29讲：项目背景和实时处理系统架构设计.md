<p data-nodeid="5036" class="">从这一课时开始我们进入“Flink 实时统计 PV、UV”项目的学习。本课时先介绍实时统计项目的背景、架构设计和技术选型。</p>


<h3 data-nodeid="4462">背景</h3>
<p data-nodeid="4463">PV（Page View，网站的浏览量）即页面的浏览次数，一般用来衡量网站用户访问的网页数量。我们可以简单地认为，一个用户每次打开一个页面便会记录一次 PV，也就是说，PV 是指页面刷新的次数，刷新一次页面，记录一次 PV。</p>
<p data-nodeid="4464">在互联网项目中，PV 的度量方法是指发起一次请求（Request）从浏览器到网络服务器，网络服务器在接收到请求后会将对应的网页返回给访问者，这个过程就是一次 PV。</p>
<p data-nodeid="4465">UV（Unique Visitor，独立访客次数）是一天内访问某个站点的人数。一天内同一个用户不管有多少次访问网站，那么只记录一次 UV。一般来讲，会通过 IP 或者 Cookie 来进行判断。</p>
<p data-nodeid="4466">如果网站的一个页面有 100 次访问，其中有一些访问者多次访问和点击，那么页面的 UV 一定是小于 100 的。</p>
<p data-nodeid="4467">PV 和 UV 是我们业务中十分常见的场景，对于这种需求一般是通过什么样的技术架构实现呢？</p>
<h3 data-nodeid="5790">技术选型和整体架构</h3>
<p data-nodeid="5791" class=""><img src="https://s0.lgstatic.com/i/image/M00/37/30/Ciqc1F8ZMvyAdIM8AADirKWqIag578.png" alt="image (2).png" data-nodeid="5799"></p>


<p data-nodeid="4470">在互联网常见的后端应用中，技术选型可能多种多样，比如基于 Spring、Dubbo、Spring Cloud 等，但是基本的处理框架大同小异。最常见的数据就是日志数据，如果是 Web 应用，那么我们的日志数据就是用户的访问日志或者用户的点击日志等。</p>
<p data-nodeid="4471">从上图中可以看到有几个关键的处理步骤：</p>
<ul data-nodeid="4472">
<li data-nodeid="4473">
<p data-nodeid="4474">日志数据如何上报</p>
</li>
<li data-nodeid="4475">
<p data-nodeid="4476">日志数据的清洗</p>
</li>
<li data-nodeid="4477">
<p data-nodeid="4478">实时计算程序</p>
</li>
<li data-nodeid="4479">
<p data-nodeid="4480">前端展示</p>
</li>
</ul>
<p data-nodeid="6568">所以基于以上的业务处理流程，我们常用的实时处理技术选型和架构如下图所示：</p>
<p data-nodeid="6569" class=""><img src="https://s0.lgstatic.com/i/image/M00/37/30/Ciqc1F8ZMxSAJ_HtAAFaSnabmZI663.png" alt="image (3).png" data-nodeid="6577"></p>


<p data-nodeid="4483">在上图的架构图中，涉及几个关键的技术选型和处理步骤，我们下面一一进行讲解。</p>
<h4 data-nodeid="4484">日志数据埋点</h4>
<p data-nodeid="4485">“埋点”是数据采集领域中的一个术语，特别是采集用户行为数据，针对用户的某些事件和行为进行捕捉、处理并发送的过程。</p>
<p data-nodeid="4486">埋点数据是十分重要的数据，也可用来进行：</p>
<ul data-nodeid="4487">
<li data-nodeid="4488">
<p data-nodeid="4489">流量监控、页面访问的热点分析</p>
</li>
<li data-nodeid="4490">
<p data-nodeid="4491">构建用户的行为数据，获取用户整个访问的路径和习惯</p>
</li>
<li data-nodeid="4492">
<p data-nodeid="4493">可以根据用户的访问数据进行偏好分析、个性化推荐</p>
</li>
<li data-nodeid="4494">
<p data-nodeid="4495">AB 测试</p>
</li>
<li data-nodeid="4496">
<p data-nodeid="4497">……</p>
</li>
</ul>
<p data-nodeid="4498">数据埋点的方式多种多样，可以在页面中使用 JavaScript 埋点开发，也可以简单地通过 Nginx 代理服务器进行日志的规范化。</p>
<p data-nodeid="4499">当前大型网站的架构一般都是通过 Nginx 等服务器做网管和代理，Nginx 服务器本身支持日志格式的定制化。</p>
<p data-nodeid="4500">服务端也可以先定义好全局的规范化日志，然后再进行采集，可以更加精细化的定制，满足精细化分析的需求。</p>
<p data-nodeid="4501">我们在本案例中的场景是计算 PV 和 UV 数据，所以数据来源最有可能的是 Nginx 定制化的日志格式，例如：</p>
<pre class="lang-javascript" data-nodeid="4502"><code data-language="javascript">log_format access $remote_addr - $remote_user [$time_local] <span class="hljs-string">"$request"</span><span class="hljs-string">' '</span>$status $body_bytes_sent <span class="hljs-string">"$http_referer"</span><span class="hljs-string">' '</span><span class="hljs-string">"$http_user_agent"</span> $http_x_forwarded_for;
</code></pre>
<p data-nodeid="4503">Nginx 服务器的配置中跟日志相关的命令主要有 log_format 和 access_log。其中 log_format 可以用来定义日志格式，access_log 则指定了日志的存储路径。</p>
<h4 data-nodeid="4504">日志数据采集</h4>
<p data-nodeid="4505">日志数据的采集需要根据日志的生成方式进行。在这里介绍两款普遍使用的日志收集中间件：</p>
<ul data-nodeid="4506">
<li data-nodeid="4507">
<p data-nodeid="4508">Flume</p>
</li>
<li data-nodeid="4509">
<p data-nodeid="4510">Logstash/FileBeat</p>
</li>
</ul>
<p data-nodeid="4511">根据官网的介绍：</p>
<blockquote data-nodeid="8173">
<p data-nodeid="8174">Flume 是一个分布式、可靠和高可用的海量日志采集、聚合和传输的系统。Flume 可以采集文件、Socket 数据包等各种形式源数据，又可以将采集到的数据输出到 HDFS、HBase、Hive、Kafka 等众多外部存储系统中。一般的采集需求，通过对 Flume 的简单配置即可实现 Flume 针对特殊场景也具备良好的自定义扩展能力。因此，Flume 可以适用于大部分的日常数据采集场景。</p>
</blockquote>
<p data-nodeid="8175" class=""><img src="https://s0.lgstatic.com/i/image/M00/37/3B/CgqCHl8ZMzaAblKvAAD3vrFEBOg613.png" alt="1.png" data-nodeid="8179"></p>


<p data-nodeid="4515">Flume 分布式系统中核心角色是 Agent，整个采集系统由一个个 Agent 进行的串联。我们可以把每个 Agent 想象为一个数据的投递员，它由三个组件构成：</p>
<ul data-nodeid="4516">
<li data-nodeid="4517">
<p data-nodeid="4518">Source，用来进行数据采集</p>
</li>
<li data-nodeid="4519">
<p data-nodeid="4520">Channel，数据传输的通道</p>
</li>
<li data-nodeid="4521">
<p data-nodeid="4522">Sink，用于把采集后的数据进行处理</p>
</li>
</ul>
<p data-nodeid="4523">我们同样也可以在官网找到 Logstash 和 FileBeat 的介绍：</p>
<blockquote data-nodeid="7362">
<p data-nodeid="7363">Logstash 能够动态地采集、转换和传输数据，不受格式或复杂度的影响。利用 Grok 从非结构化数据中派生出结构，从 IP 地址解码出地理坐标，匿名化或排除敏感字段，并简化整体的处理过程。</p>
</blockquote>
<p data-nodeid="7364" class=""><img src="https://s0.lgstatic.com/i/image/M00/37/3B/CgqCHl8ZMymAOQIcAABATnBXEsQ013.png" alt="image (4).png" data-nodeid="7372"></p>


<p data-nodeid="4527">Logstash 支持各种输入选择，比如 log4j、Redis 等，可以同时从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从你的日志、指标、Web 应用、数据存储以及各种 AWS 服务中采集数据。</p>
<p data-nodeid="4528">同样 FileBeat 也经常用来进行本地文件的日志数据采集，同时可以监控日志目录或者指定的日志文件，并且进行 tail 等操作，也可以将结果转发给 Elasticsearch 或 Logstatsh 等。</p>
<p data-nodeid="4529">如果你的日志分析架构是 ES 系列技术栈，完全可以使用它们来代替 Flume。</p>
<h4 data-nodeid="4530">实时计算</h4>
<p data-nodeid="4531">我们在上个项目的架构设计中指出了 Flink 的优势，在这里不再过多展开：</p>
<ul data-nodeid="4532">
<li data-nodeid="4533">
<p data-nodeid="4534">状态管理</p>
</li>
<li data-nodeid="4535">
<p data-nodeid="4536">丰富的 API</p>
</li>
<li data-nodeid="4537">
<p data-nodeid="4538">生态完善</p>
</li>
<li data-nodeid="4539">
<p data-nodeid="4540">批流一体</p>
</li>
</ul>
<p data-nodeid="4541">但需要注意的是，我们在进行 PV、UV 的统计时，Flink 会被用到两次：</p>
<ul data-nodeid="4542">
<li data-nodeid="4543">
<p data-nodeid="4544">日志清洗</p>
</li>
<li data-nodeid="4545">
<p data-nodeid="4546">数据统计</p>
</li>
</ul>
<p data-nodeid="4547">我们采集到的日志数据根据需要先进行清洗，包括丢弃掉不符合要求的数据，对日志数据进行分类，这个过程也会基于 Flink 进行，然后 Sink 到 Kafka 中给下游进行消费。</p>
<h3 data-nodeid="4548">实时统计主要内容</h3>
<p data-nodeid="4549">在本次的案例中，我们不但对 PV 和 UV 进行计算，同时还会讲解 Flume 和 Kafka 的整合，Flink 日志清洗并 Sink 到 Kafka 等。</p>
<p data-nodeid="4550">整个课程的设计包含以下几个部分：</p>
<ul data-nodeid="4551">
<li data-nodeid="4552">
<p data-nodeid="4553">Flume 和 Kafka 整合和部署</p>
</li>
<li data-nodeid="4554">
<p data-nodeid="4555">Kafka 模拟数据生成和发送</p>
</li>
<li data-nodeid="4556">
<p data-nodeid="4557">Flink 和 Kafka 整合时间窗口设计</p>
</li>
<li data-nodeid="4558">
<p data-nodeid="4559">Flink 计算 PV、UV 代码实现</p>
</li>
<li data-nodeid="4560">
<p data-nodeid="4561">Flink 和 Redis 整合以及 Redis Sink 实现</p>
</li>
</ul>
<h3 data-nodeid="4562">总结</h3>
<p data-nodeid="8982">本节课我们主要讲解了实时进行 PV、UV 计算的技术架构选型，其中涉及了日志数据埋点、日志数据采集、清洗等。在接下来的课程中，我会一一讲解这些知识点。通过本课时，你将学习到类似 PV、UV 等指标计算的整个流程设计和代码开发，在面对相同业务场景时可以根据课程内容灵活处理。</p>

---

### 精选评论


