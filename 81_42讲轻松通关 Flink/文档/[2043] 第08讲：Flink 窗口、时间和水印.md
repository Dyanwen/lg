<p data-nodeid="14836" class="">本课时主要介绍 Flink 中的时间和水印。</p>
<p data-nodeid="14837">我们在之前的课时中反复提到过<strong data-nodeid="14970">窗口</strong>和<strong data-nodeid="14971">时间</strong>的概念，Flink 框架中支持事件时间、摄入时间和处理时间三种。而当我们在流式计算环境中数据从 Source 产生，再到转换和输出，这个过程由于网络和反压的原因会导致消息乱序。因此，需要有一个机制来解决这个问题，这个特别的机制就是“水印”。</p>
<h3 data-nodeid="14838">Flink 的窗口和时间</h3>
<p data-nodeid="14839">我们在第 05 课时中讲解过 Flink 窗口的实现，根据窗口数据划分的不同，目前 Flink 支持如下 3 种：</p>
<ul data-nodeid="14840">
<li data-nodeid="14841">
<p data-nodeid="14842"><strong data-nodeid="14978">滚动窗口</strong>，窗口数据有固定的大小，窗口中的数据不会叠加；</p>
</li>
<li data-nodeid="14843">
<p data-nodeid="14844"><strong data-nodeid="14983">滑动窗口</strong>，窗口数据有固定的大小，并且有生成间隔；</p>
</li>
<li data-nodeid="14845">
<p data-nodeid="14846"><strong data-nodeid="14988">会话窗口</strong>，窗口数据没有固定的大小，根据用户传入的参数进行划分，窗口数据无叠加。</p>
</li>
</ul>
<p data-nodeid="14847">Flink 中的时间分为三种：</p>
<ul data-nodeid="14848">
<li data-nodeid="14849">
<p data-nodeid="14850"><strong data-nodeid="14994">事件时间</strong>（Event Time），即事件实际发生的时间；</p>
</li>
<li data-nodeid="14851">
<p data-nodeid="14852"><strong data-nodeid="14999">摄入时间</strong>（Ingestion Time），事件进入流处理框架的时间；</p>
</li>
<li data-nodeid="14853">
<p data-nodeid="14854"><strong data-nodeid="15004">处理时间</strong>（Processing Time），事件被处理的时间。</p>
</li>
</ul>
<p data-nodeid="14855">下面的图详细说明了这三种时间的区别和联系：</p>
<p data-nodeid="14856"><img src="https://s0.lgstatic.com/i/image/M00/07/44/CgqCHl65D6SAKNl-AADISYD73gQ276.png" alt="image (18).png" data-nodeid="15008"></p>
<h4 data-nodeid="14857">事件时间（Event Time）</h4>
<p data-nodeid="14858">事件时间（Event Time）指的是数据产生的时间，这个时间一般由数据生产方自身携带，比如 Kafka 消息，每个生成的消息中自带一个时间戳代表每条数据的产生时间。Event Time 从消息的产生就诞生了，不会改变，也是我们使用最频繁的时间。</p>
<p data-nodeid="14859">利用 Event Time 需要指定如何生成事件时间的“水印”，并且一般和窗口配合使用，具体会在下面的“水印”内容中详细讲解。</p>
<p data-nodeid="14860">我们可以在代码中指定 Flink 系统使用的时间类型为 EventTime：</p>
<pre class="lang-java" data-nodeid="14861"><code data-language="java"><span class="hljs-keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
<span class="hljs-comment">//设置时间属性为 EventTime</span>
env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);

DataStream&lt;MyEvent&gt; stream = env.addSource(<span class="hljs-keyword">new</span> FlinkKafkaConsumer09&lt;MyEvent&gt;(topic, schema, props));

stream
    .keyBy( (event) -&gt; event.getUser() )
    .timeWindow(Time.hours(<span class="hljs-number">1</span>))
    .reduce( (a, b) -&gt; a.add(b) )
    .addSink(...);
</code></pre>
<p data-nodeid="14862">Flink 注册 EventTime 是通过 InternalTimerServiceImpl.registerEventTimeTimer 来实现的：</p>
<p data-nodeid="14863"><img src="https://s0.lgstatic.com/i/image/M00/07/44/CgqCHl65D6-AJTx1AAC_jnA2dzE629.png" alt="image (19).png" data-nodeid="15016"></p>
<p data-nodeid="14864">可以看到，该方法有两个入参：namespace 和 time，其中 time 是触发定时器的时间，namespace 则被构造成为一个 TimerHeapInternalTimer 对象，然后将其放入 KeyGroupedInternalPriorityQueue 队列中。</p>
<p data-nodeid="14865">那么 Flink 什么时候会使用这些 timer 触发计算呢？答案在这个方法里：</p>
<pre class="lang-java" data-nodeid="14866"><code data-language="java">InternalTimeServiceImpl.advanceWatermark。
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">advanceWatermark</span><span class="hljs-params">(<span class="hljs-keyword">long</span> time)</span> <span class="hljs-keyword">throws</span> Exception </span>{
   currentWatermark = time;

   InternalTimer&lt;K, N&gt; timer;

   <span class="hljs-keyword">while</span> ((timer = eventTimeTimersQueue.peek()) != <span class="hljs-keyword">null</span> &amp;&amp; timer.getTimestamp() &lt;= time) {
      eventTimeTimersQueue.poll();
      keyContext.setCurrentKey(timer.getKey());
      triggerTarget.onEventTime(timer);
   }
}
</code></pre>
<p data-nodeid="14867">这个方法中的 while 循环部分会从 eventTimeTimersQueue 中依次取出触发时间小于参数 time 的所有定时器，调用 triggerTarget.onEventTime() 方法进行触发。</p>
<p data-nodeid="14868">这就是 EventTime 从注册到触发的流程。</p>
<h4 data-nodeid="14869">处理时间（Processing Time）</h4>
<p data-nodeid="14870">处理时间（Processing Time）指的是数据被 Flink 框架处理时机器的系统时间，Processing Time 是 Flink 的时间系统中最简单的概念，但是这个时间存在一定的不确定性，比如消息到达处理节点延迟等影响。</p>
<p data-nodeid="14871">我们同样可以在代码中指定 Flink 系统使用的时间为 Processing Time：</p>
<pre class="lang-java" data-nodeid="14872"><code data-language="java"><span class="hljs-keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

env.setStreamTimeCharacteristic(TimeCharacteristic.ProcessingTime);
</code></pre>
<p data-nodeid="14873">同样，也可以在源码中找到 Flink 是如何注册和使用 Processing Time 的。</p>
<p data-nodeid="14874"><img src="https://s0.lgstatic.com/i/image/M00/07/44/Ciqc1F65D7yANHLJAAGNDGNArrs530.png" alt="image (20).png" data-nodeid="15027"></p>
<p data-nodeid="14875">registerProcessingTimeTimer() 方法为我们展示了如何注册一个 ProcessingTime 定时器：<br>
每当一个新的定时器被加入到 processingTimeTimersQueue 这个优先级队列中时，如果新来的 Timer 时间戳更小，那么更小的这个 Timer 会被重新注册 ScheduledThreadPoolExecutor 定时执行器上。</p>
<p data-nodeid="14876">Processing Time 被触发是在 InternalTimeServiceImpl 的 onProcessingTime() 方法中：</p>
<p data-nodeid="14877"><img src="https://s0.lgstatic.com/i/image/M00/07/44/CgqCHl65D8SAchccAAGd410eR8s589.png" alt="image (21).png" data-nodeid="15034"></p>
<p data-nodeid="14878">一直循环获取时间小于入参 time 的所有定时器，并运行 triggerTarget 的 onProcessingTime() 方法。</p>
<h4 data-nodeid="14879">摄入时间（Ingestion Time）</h4>
<p data-nodeid="14880">摄入时间（Ingestion Time）是事件进入 Flink 系统的时间，在 Flink 的 Source 中，每个事件会把当前时间作为时间戳，后续做窗口处理都会基于这个时间。理论上 Ingestion Time 处于 Event Time 和 Processing Time之间。</p>
<blockquote data-nodeid="14881">
<p data-nodeid="14882">与事件时间相比，摄入时间无法处理延时和无序的情况，但是不需要明确执行如何生成 watermark。在系统内部，摄入时间采用更类似于事件时间的处理方式进行处理，但是有自动生成的时间戳和自动的 watermark。</p>
<p data-nodeid="14883">可以防止 Flink 内部处理数据是发生乱序的情况，但无法解决数据到达 Flink 之前发生的乱序问题。如果需要处理此类问题，建议使用 EventTime。</p>
</blockquote>
<p data-nodeid="14884">Ingestion Time 的时间类型生成相关的代码在 AutomaticWatermarkContext 中：</p>
<p data-nodeid="14885"><img src="https://s0.lgstatic.com/i/image/M00/07/44/Ciqc1F65D9GAS3kXAAN7PTTF3NU199.png" alt="image (22).png" data-nodeid="15043"></p>
<p data-nodeid="14886"><img src="https://s0.lgstatic.com/i/image/M00/07/44/Ciqc1F65D9eAVZoGAAO5hF8UgGw900.png" alt="image (23).png" data-nodeid="15046"></p>
<p data-nodeid="14887">我们可以看出，这里会设置一个 watermark 发送定时器，在 watermarkInterval 时间之后触发。</p>
<p data-nodeid="14888">处理数据的代码在 processAndCollect() 方法中：</p>
<p data-nodeid="14889"><img src="https://s0.lgstatic.com/i/image/M00/07/44/CgqCHl65D-GAN_LZAAE7PAqT6I4490.png" alt="image (24).png" data-nodeid="15051"></p>
<h3 data-nodeid="14890">水印（WaterMark）</h3>
<p data-nodeid="14891">水印（WaterMark）是 Flink 框架中最晦涩难懂的概念之一，有很大一部分原因是因为翻译的原因。</p>
<p data-nodeid="14892">WaterMark 在正常的英文翻译中是水位，但是在 Flink 框架中，翻译为“水位线”更为合理，它在本质上是一个时间戳。</p>
<p data-nodeid="14893">在上面的时间类型中我们知道，Flink 中的时间：<br>
EventTime 每条数据都携带时间戳；</p>
<ul data-nodeid="14894">
<li data-nodeid="14895">
<p data-nodeid="14896">ProcessingTime 数据不携带任何时间戳的信息；</p>
</li>
<li data-nodeid="14897">
<p data-nodeid="14898">IngestionTime 和 EventTime 类似，不同的是 Flink 会使用系统时间作为时间戳绑定到每条数据，可以防止 Flink 内部处理数据是发生乱序的情况，但无法解决数据到达 Flink 之前发生的乱序问题。</p>
</li>
</ul>
<p data-nodeid="14899">所以，我们在处理消息乱序的情况时，会用 EventTime 和 WaterMark 进行配合使用。</p>
<p data-nodeid="14900">首先我们要明确几个基本问题。</p>
<h4 data-nodeid="14901">水印的本质是什么</h4>
<p data-nodeid="14902">水印的出现是为了<strong data-nodeid="15070">解决实时计算中的数据乱序问题</strong>，它的本质是 DataStream 中一个带有时间戳的元素。如果 Flink 系统中出现了一个 WaterMark T，那么就意味着 EventTime &lt; T 的数据都已经到达，窗口的结束时间和 T 相同的那个窗口被触发进行计算了。</p>
<p data-nodeid="14903">也就是说：水印是 Flink 判断迟到数据的标准，同时也是窗口触发的标记。</p>
<p data-nodeid="14904">在程序并行度大于 1 的情况下，会有多个流产生水印和窗口，这时候 Flink 会选取时间戳最小的水印。</p>
<h4 data-nodeid="14905">水印是如何生成的</h4>
<p data-nodeid="14906">Flink 提供了 assignTimestampsAndWatermarks() 方法来实现水印的提取和指定，该方法接受的入参有 AssignerWithPeriodicWatermarks 和 AssignerWithPunctuatedWatermarks 两种。</p>
<p data-nodeid="14907">整体的类图如下：</p>
<p data-nodeid="14908"><img src="https://s0.lgstatic.com/i/image/M00/07/44/Ciqc1F65D-2AKmZ2AAITdhcoNis465.png" alt="image (25).png" data-nodeid="15078"></p>
<h4 data-nodeid="14909">水印种类</h4>
<p data-nodeid="14910"><strong data-nodeid="15083">周期性水印</strong></p>
<p data-nodeid="14911">我们在使用 AssignerWithPeriodicWatermarks 周期生成水印时，周期默认的时间是 200ms，这个时间的指定位置为：</p>
<pre class="lang-java" data-nodeid="14912"><code data-language="java"><span class="hljs-meta">@PublicEvolving</span>
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setStreamTimeCharacteristic</span><span class="hljs-params">(TimeCharacteristic characteristic)</span> </span>{
    <span class="hljs-keyword">this</span>.timeCharacteristic = Preconditions.checkNotNull(characteristic);
    <span class="hljs-keyword">if</span> (characteristic == TimeCharacteristic.ProcessingTime) {
        getConfig().setAutoWatermarkInterval(<span class="hljs-number">0</span>);
    } <span class="hljs-keyword">else</span> {
        getConfig().setAutoWatermarkInterval(<span class="hljs-number">200</span>);
    }
}
</code></pre>
<p data-nodeid="14913">是否还记得上面我们在讲时间类型时会通过 env.setStreamTimeCharacteristic() 方法指定 Flink 系统的时间类型，这个 setStreamTimeCharacteristic() 方法中会做判断，如果用户传入的是 TimeCharacteristic.eventTime 类型，那么 AutoWatermarkInterval 的值则为 200ms ，如上述代码所示。当前我们也可以使用 ExecutionConfig.setAutoWatermarkInterval() 方法来指定自动生成的时间间隔。</p>
<p data-nodeid="14914">在上述的类图中可以看出，我们需要通过 TimestampAssigner 的 extractTimestamp() 方法来提取 EventTime。</p>
<p data-nodeid="14915">Flink 在这里提供了 3 种提取 EventTime() 的方法，分别是：</p>
<ul data-nodeid="14916">
<li data-nodeid="14917">
<p data-nodeid="14918">AscendingTimestampExtractor</p>
</li>
<li data-nodeid="14919">
<p data-nodeid="14920">BoundedOutOfOrdernessTimestampExtractor</p>
</li>
<li data-nodeid="14921">
<p data-nodeid="14922">IngestionTimeExtractor</p>
</li>
</ul>
<p data-nodeid="14923">这三种方法中 BoundedOutOfOrdernessTimestampExtractor() 用的最多，需特别注意，在这个方法中的 maxOutOfOrderness 参数，该参数指的是允许数据乱序的时间范围。简单说，这种方式允许数据迟到 maxOutOfOrderness 这么长的时间。</p>
<pre class="lang-java" data-nodeid="14924"><code data-language="java">    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">BoundedOutOfOrdernessTimestampExtractor</span><span class="hljs-params">(Time maxOutOfOrderness)</span> </span>{
        <span class="hljs-keyword">if</span> (maxOutOfOrderness.toMilliseconds() &lt; <span class="hljs-number">0</span>) {
            <span class="hljs-keyword">throw</span> <span class="hljs-keyword">new</span> RuntimeException(<span class="hljs-string">"Tried to set the maximum allowed "</span> +
                <span class="hljs-string">"lateness to "</span> + maxOutOfOrderness + <span class="hljs-string">". This parameter cannot be negative."</span>);
        }
        <span class="hljs-keyword">this</span>.maxOutOfOrderness = maxOutOfOrderness.toMilliseconds();
        <span class="hljs-keyword">this</span>.currentMaxTimestamp = Long.MIN_VALUE + <span class="hljs-keyword">this</span>.maxOutOfOrderness;
    }

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">abstract</span> <span class="hljs-keyword">long</span> <span class="hljs-title">extractTimestamp</span><span class="hljs-params">(T element)</span></span>;

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> Watermark <span class="hljs-title">getCurrentWatermark</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">long</span> potentialWM = currentMaxTimestamp - maxOutOfOrderness;
        <span class="hljs-keyword">if</span> (potentialWM &gt;= lastEmittedWatermark) {
            lastEmittedWatermark = potentialWM;
        }
        <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Watermark(lastEmittedWatermark);
    }

    <span class="hljs-meta">@Override</span>
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">final</span> <span class="hljs-keyword">long</span> <span class="hljs-title">extractTimestamp</span><span class="hljs-params">(T element, <span class="hljs-keyword">long</span> previousElementTimestamp)</span> </span>{
        <span class="hljs-keyword">long</span> timestamp = extractTimestamp(element);
        <span class="hljs-keyword">if</span> (timestamp &gt; currentMaxTimestamp) {
            currentMaxTimestamp = timestamp;
        }
        <span class="hljs-keyword">return</span> timestamp;
    }
</code></pre>
<p data-nodeid="14925"><strong data-nodeid="15095">PunctuatedWatermark 水印</strong></p>
<p data-nodeid="14926">这种水印的生成方式 Flink 没有提供内置实现，它适用于根据接收到的消息判断是否需要产生水印的情况，用这种水印生成的方式并不多见。</p>
<p data-nodeid="14927">举个简单的例子，假如我们发现接收到的数据 MyData 中以字符串 watermark 开头则产生一个水印：</p>
<pre class="lang-java" data-nodeid="14928"><code data-language="java">data.assignTimestampsAndWatermarks(<span class="hljs-keyword">new</span> AssignerWithPunctuatedWatermarks&lt;UserActionRecord&gt;() {

      <span class="hljs-meta">@Override</span>
      <span class="hljs-function"><span class="hljs-keyword">public</span> Watermark <span class="hljs-title">checkAndGetNextWatermark</span><span class="hljs-params">(MyData data, <span class="hljs-keyword">long</span> l)</span> </span>{
        <span class="hljs-keyword">return</span> data.getRecord.startsWith(<span class="hljs-string">"watermark"</span>) ? <span class="hljs-keyword">new</span> Watermark(l) : <span class="hljs-keyword">null</span>;
      }

      <span class="hljs-meta">@Override</span>
      <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">extractTimestamp</span><span class="hljs-params">(MyData data, <span class="hljs-keyword">long</span> l)</span> </span>{
        <span class="hljs-keyword">return</span> data.getTimestamp();
      }
    });

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">MyData</span></span>{
    <span class="hljs-keyword">private</span> String record;
    <span class="hljs-keyword">private</span> Long timestamp;
    <span class="hljs-function"><span class="hljs-keyword">public</span> String <span class="hljs-title">getRecord</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> record;
    }
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setRecord</span><span class="hljs-params">(String record)</span> </span>{
        <span class="hljs-keyword">this</span>.record = record;
    }
    <span class="hljs-function"><span class="hljs-keyword">public</span> Timestamp <span class="hljs-title">getTimestamp</span><span class="hljs-params">()</span> </span>{
        <span class="hljs-keyword">return</span> timestamp;
    }
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">setTimestamp</span><span class="hljs-params">(Timestamp timestamp)</span> </span>{
        <span class="hljs-keyword">this</span>.timestamp = timestamp;
    }
}
</code></pre>
<h3 data-nodeid="14929">案例</h3>
<p data-nodeid="14930">我们上面讲解了 Flink 关于水印和时间的生成，以及使用，下面举一个例子来讲解。</p>
<p data-nodeid="14931">模拟一个实时接收 Socket 的 DataStream 程序，代码中使用 AssignerWithPeriodicWatermarks 来设置水印，将接收到的数据进行转换，分组并且在一个 5<br>
秒的窗口内获取该窗口中第二个元素最小的那条数据。</p>
<pre class="lang-java" data-nodeid="14932"><code data-language="java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> <span class="hljs-keyword">throws</span> Exception </span>{

    StreamExecutionEnvironment env = StreamExecutionEnvironment.createLocalEnvironment();

    <span class="hljs-comment">//设置为eventtime事件类型</span>
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);
    <span class="hljs-comment">//设置水印生成时间间隔100ms</span>
    env.getConfig().setAutoWatermarkInterval(<span class="hljs-number">100</span>);

    DataStream&lt;String&gt; dataStream = env
            .socketTextStream(<span class="hljs-string">"127.0.0.1"</span>, <span class="hljs-number">9000</span>)
            .assignTimestampsAndWatermarks(<span class="hljs-keyword">new</span> AssignerWithPeriodicWatermarks&lt;String&gt;() {
                <span class="hljs-keyword">private</span> Long currentTimeStamp = <span class="hljs-number">0L</span>;
                <span class="hljs-comment">//设置允许乱序时间</span>
                <span class="hljs-keyword">private</span> Long maxOutOfOrderness = <span class="hljs-number">5000L</span>;

                <span class="hljs-meta">@Override</span>
                <span class="hljs-function"><span class="hljs-keyword">public</span> Watermark <span class="hljs-title">getCurrentWatermark</span><span class="hljs-params">()</span> </span>{

                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Watermark(currentTimeStamp - maxOutOfOrderness);
                }

                <span class="hljs-meta">@Override</span>
                <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> <span class="hljs-title">extractTimestamp</span><span class="hljs-params">(String s, <span class="hljs-keyword">long</span> l)</span> </span>{
                    String[] arr = s.split(<span class="hljs-string">","</span>);
                    <span class="hljs-keyword">long</span> timeStamp = Long.parseLong(arr[<span class="hljs-number">1</span>]);
                    currentTimeStamp = Math.max(timeStamp, currentTimeStamp);
                    System.err.println(s + <span class="hljs-string">",EventTime:"</span> + timeStamp + <span class="hljs-string">",watermark:"</span> + (currentTimeStamp - maxOutOfOrderness));
                    <span class="hljs-keyword">return</span> timeStamp;
                }
            });

    dataStream.map(<span class="hljs-keyword">new</span> MapFunction&lt;String, Tuple2&lt;String, Long&gt;&gt;() {
        <span class="hljs-meta">@Override</span>
        <span class="hljs-function"><span class="hljs-keyword">public</span> Tuple2&lt;String, Long&gt; <span class="hljs-title">map</span><span class="hljs-params">(String s)</span> <span class="hljs-keyword">throws</span> Exception </span>{

            String[] split = s.split(<span class="hljs-string">","</span>);
            <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> Tuple2&lt;String, Long&gt;(split[<span class="hljs-number">0</span>], Long.parseLong(split[<span class="hljs-number">1</span>]));
        }
    })
            .keyBy(<span class="hljs-number">0</span>)
            .window(TumblingEventTimeWindows.of(Time.seconds(<span class="hljs-number">5</span>)))
            .minBy(<span class="hljs-number">1</span>)
            .print();

    env.execute(<span class="hljs-string">"WaterMark Test Demo"</span>);

}
</code></pre>
<p data-nodeid="14933">我们第一次试验的数据如下：</p>
<pre class="lang-java" data-nodeid="14934"><code data-language="java">flink,<span class="hljs-number">1588659181000</span>
flink,<span class="hljs-number">1588659182000</span>
flink,<span class="hljs-number">1588659183000</span>
flink,<span class="hljs-number">1588659184000</span>
flink,<span class="hljs-number">1588659185000</span>
</code></pre>
<p data-nodeid="14935">可以做一个简单的判断，第一条数据的时间戳为 1588659181000，窗口的大小为 5 秒，那么应该会在 flink,1588659185000 这条数据出现时触发窗口的计算。</p>
<p data-nodeid="14936">我们用 nc -lk 9000 命令启动端口，然后输出上述试验数据，看到控制台的输出：</p>
<p data-nodeid="14937"><img src="https://s0.lgstatic.com/i/image/M00/07/44/CgqCHl65EAGATIBjAAMEGkxkMKY790.png" alt="image (26).png" data-nodeid="15108"></p>
<p data-nodeid="14938">很明显，可以看到当第五条数据出现后，窗口触发了计算。</p>
<p data-nodeid="14939">下面再模拟一下数据乱序的情况，假设我们的数据来源如下：</p>
<pre class="lang-java" data-nodeid="14940"><code data-language="java">flink,<span class="hljs-number">1588659181000</span>
flink,<span class="hljs-number">1588659182000</span>
flink,<span class="hljs-number">1588659183000</span>
flink,<span class="hljs-number">1588659184000</span>
flink,<span class="hljs-number">1588659185000</span>
flink,<span class="hljs-number">1588659180000</span>
flink,<span class="hljs-number">1588659186000</span>
flink,<span class="hljs-number">1588659187000</span>
flink,<span class="hljs-number">1588659188000</span>
flink,<span class="hljs-number">1588659189000</span>
flink,<span class="hljs-number">1588659190000</span>
</code></pre>
<p data-nodeid="14941">其中的 flink,1588659180000 为乱序消息，来看看会发生什么？</p>
<p data-nodeid="14942"><img src="https://s0.lgstatic.com/i/image/M00/07/44/CgqCHl65EAmAMMGBAAEzvkTnjK8833.png" alt="image (27).png" data-nodeid="15114"></p>
<p data-nodeid="14943">可以看到，时间戳为 1588659180000 的这条消息并没有被处理，因为此时代码中的允许乱序时间 private Long maxOutOfOrderness = 0L 即不处理乱序消息。</p>
<p data-nodeid="14944">下面修改 private Long maxOutOfOrderness = 5000L，即代表允许消息的乱序时间为 5 秒，然后把同样的数据发往 socket 端口。</p>
<p data-nodeid="14945">可以看到，我们把所有数据发送出去仅触发了一次窗口计算，并且输出的结果中 watermark 的时间往后顺延了 5 秒钟。所以，maxOutOfOrderness 的设置会影响窗口的计算时间和水印的时间，如下图所示：</p>
<p data-nodeid="14946"><img src="https://s0.lgstatic.com/i/image/M00/07/44/Ciqc1F65EBCARpb-AAEFtbvAUWk070.png" alt="image (28).png" data-nodeid="15120"></p>
<p data-nodeid="14947">假如我们继续向 socket 中发送数据：</p>
<pre class="lang-java" data-nodeid="14948"><code data-language="java">flink,<span class="hljs-number">1588659191000</span>
flink,<span class="hljs-number">1588659192000</span>
flink,<span class="hljs-number">1588659193000</span>
flink,<span class="hljs-number">1588659194000</span>
flink,<span class="hljs-number">1588659195000</span>
</code></pre>
<p data-nodeid="14949">可以看到下一次窗口的触发时间：</p>
<p data-nodeid="14950"><img src="https://s0.lgstatic.com/i/image/M00/07/44/Ciqc1F65EBeAWtGuAAFcnwH2ju4157.png" alt="image (29).png" data-nodeid="15125"></p>
<p data-nodeid="14951">在这里要特别说明，Flink 在用时间 + 窗口 + 水印来解决实际生产中的数据乱序问题，有如下的触发条件：</p>
<ul data-nodeid="14952">
<li data-nodeid="14953">
<p data-nodeid="14954">watermark 时间 &gt;= window_end_time；</p>
</li>
<li data-nodeid="14955">
<p data-nodeid="14956">在 [window_start_time,window_end_time) 中有数据存在，这个窗口是左闭右开的。</p>
</li>
</ul>
<p data-nodeid="16700">此外，因为 WaterMark 的生成是以对象的形式发送到下游，同样会消耗内存，因此水印的生成时间和频率都要进行严格控制，否则会影响我们的正常作业。</p>
<p data-nodeid="16701" class="te-preview-highlight"><a href="https://github.com/wangzhiwubigdata/quickstart" data-nodeid="16705">点击这里下载本课程源码</a></p>



<h3 data-nodeid="14958">总结</h3>
<p data-nodeid="14959">这一课时我们学习了 Flink 的时间类型和水印生成，内容偏多并且水印部分理解起来需要时间，建议你结合源码再进一步学习。</p>

---

### 精选评论

##### *磊：
> 不得不说，今天开始有点看不懂了。。

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 加油~

##### **7540：
> 您好，最后一个图片筛选出来的数据，那个时间不知道是怎么算的？麻烦老师解答一下

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 核心问题是：maxOutOfOrderness 的设置会影响窗口的计算时间和水印的时间。你要理解这句话，你可以认为加入正常的水印是100，那么当时设置允许乱序这个水印就会顺延。最后一个图中，有一条乱序消息，他的存在导致水印往后延迟了5秒钟。

##### *放：
> 看来好久才明白:我们的时间窗口的开始时间是第一条数据,窗口时间是5秒后,那么我什么时候开始做kyeBy和minBy的计算呢就是等到整个窗口都完了,也就是 flink,1588659185000 这条数据出现,中间的时间的数据出现多少条我也不管.当它出现时一个时间窗口才完整.第二就是如果事件时间比水印时间小,那么这条数据我不会处理 而加上乱序时间5秒,意味着我的窗口计算是5秒,还要考虑5秒延迟的数据.而水印时间就帮我们考虑了这个延迟, 如果水印时间达到1588659185000,意味着比这个时间低的数据都已到达.那么我们就可以开始计算上一个窗口的数据了,因为不会有比这个时间更低的数据允许进来参与窗口的计算.(水印时间自己减去乱序时间)总结:直到水印的的时间 =数据开始时间 + 窗口时间,才开始计算这个窗口的transform操作.

##### **富：
> 老师您好，我想问下你第二个乱序的例子，计算的窗口分别是[158865917600,1588659180000],[1588659180000,158865918500),[158865918500,1588659190000] 吗？ 因为设置了maxOutOfOrderness，对于eventTime=1588659181000的数据来说，延迟了5秒再触发这个窗口计算，然后第一个窗口因为没有在这个窗口区间范围的数据，就不计算了

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 是的。首先你要理解，maxOutOfOrderness这个参数会导致窗口和计算时间整体后移，等到延迟时间才会触发窗口计算。

##### **冉：
> 如果新来一条分组为flink2的数据，触发了flink2的窗口，会影响flink组窗口的触发吗？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 如果你是分组+窗口聚合，那么数据会先被分组，然后在进行窗口触发的检查。是不会互相影响的

##### **川：
> 老师您好，我发现一个问题：假设记录 B:{flink,1588659195000} 先到达，记录 A:{flink,1588659194000} 后到达，窗口的长度是3秒 [1588659193000~1588659196000）；我实验发现后到的 A 将会被放到和 B 同一窗口内，但 A 会被放在 B 后面，处理顺序是先处理 B 后处理A。也就是说，水印机制无法保证窗口内数据的有序，，，请问这个问题有没有什么解决办法呢

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 我还没有遇到过这个问题。但是可以试试在继承processfunction中覆写processElement方法，在这个方法中自己用PriorityQueue将消息根据时间戳排序，然后在onTimer方法里按顺序取出。

##### **飞：
> 双流join中，设定滑动窗口，在一个slide中关联到的数据，在下一个slide中如果还满足条件，还会输出吗？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 会的，只要匹配到就会输出。所以双流join时都会在sink侧做幂等。

##### **用户3113：
> 老师您好，我这有两个问题：我没太理解为什么第二个乱序的例子结果是1588659185000，按照不处理乱序的模式，1588659180000舍弃，那后面的最小时间不应该是1588659186000么还有为何1588659180000对应的水印时间是1588659185000

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 第一个问题，不处理乱序的模式，1588659180000舍弃，但是此时最小的值是85000，因为这个窗口是左闭右开的。第二个问题，因为我们设置的乱序事件是5秒，那么每条数据对应的水印都会等待5秒，也就是原来的事件加5秒。

##### **威：
> flink,1588659181000,EventTime:1588659181000,watermark is:1588659176000flink,1588659182000,EventTime:1588659182000,watermark is:1588659177000flink,1588659183000,EventTime:1588659183000,watermark is:1588659178000flink,1588659184000,EventTime:1588659184000,watermark is:1588659179000flink,1588659185000,EventTime:1588659185000,watermark is:1588659180000flink,1588659190000,EventTime:1588659190000,watermark is:15886591850005 (flink,1588659181000)我跑了，应该是这样的，和老师的例子不一样，它的watermark应该是当前时间戳减5000,延时嘛，所以第六条数据，时间戳触发了窗口计算，这才有结果

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 没错，关键就是乱序事件的设置。乱序时间会导致水印的产生延迟。

##### **耀：
> 数据如果先经过map处理 然后再assignTimestampsAndWatermarks 这些打印不出来东西 调换一下顺序 就可以了 这是为什么呢

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 不会的，map后在assignTimestampsAndWatermarks是正常操作，你可以参考一下官网的例子。或者网上搜索一些例子，我感觉可能跟你的代码有关。

##### *奇：
> 老师，窗口内数据去重咋实现？比方说我想实现每五分钟统计最近十分钟的活跃人数，数据是用户信息和事件信息

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 在第20讲会专门讲如何去重

##### **用户3693：
> 老师，您好，<div>我才刚开始研究Flink。</div><div>用Flink处理过去的数据时，我用的事件时间，从数据中提取出来的时间字段。可是使用window进行聚合时，确出不来数据，所以我还没<span style="font-size: 0.427rem;">搞明白，窗口的开始时间是以收到的第一条数据的时间(包括事件时间或者系统时间)开始的还是从运行程序的那一刻(task被调度时)的时间？</span></div><div><div><br></div><div><div><br></div></div></div>

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 窗口的开始时间参考Flink中的这个类：getWindowStartWithOffset

##### **昊：
> 执行代码后控制台没有看到窗口触发了计算log，只能看到接收到的数据log。需要改什么吗？我拿老师github 上的代码呢

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 在git pull一下代码

##### **3897：
> <div>flink,1588659181000</div><div>flink,1588659182000</div><div>flink,1588659183000</div><div>flink,1588659184000</div><div>flink,1588659185000</div><div>我在本地用文章中的代码测试，为啥没有触发窗口计算呢？是不是还有其他要修改的？</div>

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 重新拉取一下代码，启动试试看。

##### **晨：
> 打卡 2020年5 月15日

##### 123：
> 打卡

