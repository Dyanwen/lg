<p data-nodeid="108123" class="">在前面的内容中，我们完成了一个商业智能系统，为了方便理解，我做了简化。但是无论从业务复杂性还是技术复杂性来说，我们在课程中模拟的系统与真实环境还有很大的差距。所以这节课，我选取了两个在真实环境中比较常见的问题：数据更新和数据实时性，进行更具体的讨论。</p>
<p data-nodeid="108124">其中，我会围绕数据更新展开详细介绍，以便帮助你根据自己的业务需求进行调整，然后对数据实时性进行简要介绍，帮助你理解真实环境中的复杂数据变化。</p>
<p data-nodeid="108125">本课时的主要内容有：</p>
<ul data-nodeid="108126">
<li data-nodeid="108127">
<p data-nodeid="108128">数据更新</p>
</li>
<li data-nodeid="108129">
<p data-nodeid="108130">数据实时性</p>
</li>
</ul>
<h3 data-nodeid="108131">数据更新</h3>
<p data-nodeid="108132">通常来说，在一个大数据项目中，如果 ETL（Extract-Transform-Load，抽取、转换和加载，通常也叫数据清洗）所花费的时间占整个项目开发时间的 60% 以下，那么项目失败的风险会比较大。这说明数据清洗在整个项目中的重要性，也指出在实际情况中，数据清洗的工作量通常也非常大。</p>
<p data-nodeid="108133">数据清洗的需求主要和具体业务相关，但是有个问题是每个项目都会面对的，就是如何处理数据更新环节。数据更新是每个数据仓库或商业系统项目都会考虑的问题，这是因为我们的数据源，也就是业务数据库每天都会出现增删改查的操作，如果将这些修改操作按照我们的要求与数据仓库进行同步，会非常麻烦。另外，大数据出现以后，对数据更新的频率也提出了更高的要求，以前一个月同步一次更新还可以接受，现在即使要求每天同步更新，也非常正常。</p>
<p data-nodeid="108134">基于定期同步的需要，便引入了<strong data-nodeid="108168">全量数据</strong>和<strong data-nodeid="108169">增量数据</strong>的概念，这里我们假设同步周期为 t 来进行分析。</p>
<p data-nodeid="108135">全量数据就是迄今为止存在于数据仓库中的数据，这部分数据是在前面课时中，通过我们开发的转换任务脚本转换而成，但是这些任务只会在系统上线时执行一次，执行完成后，全量数据的处理工作就已经完成了。所以在执行完成后，后面会以 t为周期对更新数据进行处理，这样才能保证系统的结果是最新的。</p>
<p data-nodeid="108136">增量数据和全量数据不同的是，它以日志的形式进行推送，无法直接进行分析，而全量数据虽然可以直接进行分析，却无法捕捉到最新变化。所以在对更新数据进行处理时，比较推荐的解决办法是将增量数据与全量数据进行合并。</p>
<p data-nodeid="108316">合并的方式如下图所示，其中 n 是天数的序号。</p>
<p data-nodeid="108317" class=""><img src="https://s0.lgstatic.com/i/image/M00/4C/44/Ciqc1F9XXleAR8jnAAEZAJhM_DY821.png" alt="Lark20200908-183426.png" data-nodeid="108321"></p>


<p data-nodeid="108139">也就是说，当前的全量数据和增量数据会生成一份新的全量数据，周而复始。新的全量数据既可以直接进行分析又包含了最新的信息。数据仓库中的每一张表，每天（或者是每个周期）都需要执行这个过程。</p>
<p data-nodeid="108140">而在实际情况中，我们需要根据具体的业务需求进行合并。例如针对订单数据库的情况，每一条订单数据都会存在多个状态，如创建、支付、发货、收货等，如果只保存最新的状态，会漏掉很多有用的信息。在这种情况下，我们在合并时，需要注意保存每个订单的每个状态，用这种方式保存的表称为拉链表，即它反映了表中每个实体的变化过程。而如果需要反映每条记录的修改，就像增量数据中的日志那样，那么保存的表就称为流水表。</p>
<p data-nodeid="108141">以 t 为一天为例，根据合并过程可以看出，在每个合并周期，即每一天后，都会生成一个新版本的全量数据。我们可以采取分区表的方式来保存这些新版本的全量数据，即将每一个新的全量数据称为整个分区表中的一个分区。</p>
<p data-nodeid="108142">这只是一种更新方式，你在面对自己的业务需求时，需要根据具体情况进行调整。业务数据库通常会由于历史原因出现各种各样的问题，这些都会在数据同步与更新的时候暴露出来，需要特别引起重视。</p>
<h3 data-nodeid="108143">数据实时性</h3>
<p data-nodeid="108144">数据实时性的问题与数据更新息息相关，对于商业智能系统的使用方来说，会倾向于要求数据更新的频率越快越好，最好能接近于实时。一旦数据更新同步接近于实时，后续的数据处理当然也需要匹配到相应速度，否则意义不大，而且最终给用户呈现的报表也需要实时体现最新的数据。我们目前的方法做不到这个效果，而如果要数据分析结果体现实时数据，则需要采用一种新的架构，这也是我们下节课的内容。</p>
<p data-nodeid="108145">此外，你也可以结合“第 21 课时|统一批处理与流处理：Dataflow”中的 Dataflow进行理解。如果需要得到最好的实时性，那么势必要对结果的正确性有所舍弃，而如果我们希望用户看到的结果在大多数情况下是正确的，就需要忍受相应的延迟。</p>
<p data-nodeid="108146">所以在某种程度上，数据更新和数据实时性是一个问题。</p>
<h3 data-nodeid="108147">总结</h3>
<p data-nodeid="108148">本课时主要讨论了两个生产环境的需求与场景，在真实的工作环境中，需要一个个地解决问题，经验就会慢慢积累，也要多熟悉开源技术，这样会让你事倍功半。</p>
<p data-nodeid="108149">下节课我们要学习的是最后一个课时“另一种并行：Lambda 架构和 Kappa 架构”。完成下节课的学习后，我们的最后一个模块：商业智能系统实战就完成了。下个课时也可以看成是对这个课时提出的两个问题的解答，学习完下个课时，你将会对大数据处理架构有更加完整、清晰的认识。</p>
<p data-nodeid="108150" class="">在这里，我还想再次强调的是，整体实战模块的内容看上去相对简单，但需要你在课后练习的部分较多。随着我们的课程接近尾声，我也更加想要听到你在实践过程中遇到的问题，你的每一个反馈，对我而言都是最重要的。所以还是欢迎你来留言，与我一起讨论学习 Spark 课程遇到的问题。</p>

---

### 精选评论


