<p>在前面的课时中，我们学习了 Spark 的用法和原理，今天这个课时主要介绍 Spark 两个比较重要的优化提升项目，从这两个项目中可以看出 Spark 的优化思路。</p>
<p>这节课与前面的课时有所不同，主要介绍一些比较细的优化思路，其中很多也与开发数据库的思路不谋而合，你可以换换脑筋，无法完全理解也没关系，可以作为阅读一些论文、参与开源社区讨论的基础。</p>
<h3>Tungsten 项目</h3>
<p>Tungsten 项目产生的原因是由于固态硬盘和万兆交换机的普及和应用，I/O 性能的大幅提升使得 CPU 和内存成了大数据处理中的新瓶颈。例如一个中等规模的集群（50~100台），在某些大型作业执行过程中，网络 I/O 和硬盘 I/O 经常会接近其性能理论值，而 CPU 的使用率却很难长期维持在一个很高水平。基于此，Spark 开发团队希望开发一个新的 Spark 核心执行引擎来尽可能地压榨出 CPU 和内存的性能极限。2015 年，Tungsten 项目诞生了。</p>
<h4>1．内存管理</h4>
<p>Tungsten 旨在利用应用程序语义显式管理内存，消除 JVM 对象模型和垃圾回收的开销。Spark 选择 JVM 来负责内存管理，JVM 的垃圾回收器（Garbage Collector，GC）会不停地监控某个对象是否还有活跃的引用，如果没有，垃圾回收器会回收该对象并释放为其分配的内存。而对对象的引用通常存在于堆中的某些对象里或者作为变量存放于栈里，前者存活时间较长，后者存活时间较短。</p>
<p>另外，JVM 对象开销一向是很大的，例如字符串采用 UTF-8 编码，还有一些对象 header 等信息，这样就容易引起内存不足，降低 CPU 访问数据的吞吐量。JVM 的垃圾回收器是一个非常复杂的组件，同时它的设计思路和面对的场景通常都是针对在线事务处理（OLTP）系统，如交易系统，而 Spark 的使用场景则偏向于在线分析处理（OLAP）系统和离线计算系统，这两种场景对于性能需求差别非常大，因此利用 JVM 的垃圾回收器来应对 Spark 面对的场景，必然无法令人满意。</p>
<p>Tungsten 的目的就是摆脱 JVM 的垃圾回收器，自己管理内存。尽管在过去十几年中，对于那些普通用途的字节码，JVM 的垃圾回收器在预测对象生命周期方面取得了很好的效果，但是 Spark 比谁都清楚哪些数据需要留在内存中，哪些需要从内存中移除，这种情况下选择 JVM 管理内存，无疑不是最好的选择，<strong>这也是利用应用语义显式管理内存的意义所在</strong>，因此，Tungsten 绕过了 JVM 提供的安全内存托管系统，而使用了 sun.misc.Unsafe 包中的类，它允许 Tungsten 自主管理其内存。使用 Unsafe 类构建的数据结构在存储和访问性能上也大大优于 JVM 对象模型。</p>
<h4>2．缓存感知计算</h4>
<p>现代计算机系统使用 64 位地址指针指向 64 位内存块。而 Tungsten 也总是使用 8 字节的数据集来和 64 位内存块对齐。在 CPU 内核和内存之间，有一个 L1、L2 和 L3 高速分层存储，它们随着 CPU 数量增加而增加。通常，L3 在所有核心之间共享。如果你的 CPU 内核要求将某个主存储器地址加载到 CPU 内核的寄存器（寄存器是 CPU 内核中的一个存储区），那么首先会在 L1~L3 缓存中检查是否包含请求的内存地址。我们将与这种地址相关联的数据称为存储器页。如果是这种情况，则略过主存储器访问，并且从 L1，L2 或 L3 高速缓存中直接加载该页。否则，该页从主存储器加载，会导致更高的延迟。延迟太高，CPU 内核会等待（或执行其他工作）多个 CPU 时钟周期，直到主存储器页被传送到 CPU 内核的寄存器中。此外，该页也被放入所有高速缓存中，并且如果它们是满的，则从高速缓存中删除较不频繁访问的存储器页。因此我们得出两个结论：</p>
<ul>
<li>在计算过程中多次访问存储页，缓存才有意义。</li>
<li>由于缓存远小于主存，它们只包含主存储器页的子集，因此，为了从缓存中受益，需要一个暂时结束的访问模式，因为如果在计算任务的末期才访问同一个页面，那么它可能已经从缓存中被去除掉了。</li>
</ul>
<p>基于上述结论，缓存淘汰和预取策略十分关键。当然，现代计算机系统不仅使用最近最少使用算法（Least Recently Use，LRU）从缓存中删除缓存的存储页，还会保留下那些虽然缓存时间长但很有可能被再次请求的存储页。另外，现代 CPU 还会预测将来的存储页请求，从而将该存储页预取至缓存中。不管怎样，应始终避免随机存储访问模式，通常越顺序存储访问执行得越快。</p>
<p>那么我们应该如何避免随机存储访问模式呢？让我们来看看 java.util.HashMap 。顾名思义，键（key）对象的散列值（value）会被用来将对象分组到桶中。散列（hash）的副作用是：哪怕键值差别非常细微，散列值也会不一样，并会导致被分组到相应的桶中。每个桶可以被看成指向存储在映射表中的链表指针（pointer）。这些指针指向的是随机内存区域。因此，顺序扫描是不可能的，如下图所示：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/79/CgqCHl7YrGCAC66HAAGTpjmLmgk128.png" alt="图片1.png"></p>
<p>你可能会发现这些指针指向的对象都位于主存储（Java 堆）的随机区域中。为了提升顺序扫描性能，Tungsten 采取了不同的办法：指针不仅存储目标值内存地址，还会保存键本身。在前面，我们已经了解了 UnsafeRow 的概念，8 字节的存储区域用来保存两个整型值，例如，键和指向值的指针。这种存储布局如下图所示。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/79/CgqCHl7YrGeAOUnlAAEiSODJCgc212.png" alt="图片2.png"></p>
<p>这样，就可以运行具有顺序存储访问模式的排序算法（如快速排序）。当排序时，键和指针的组合存储区域会被到处移动，存储值的地方却不会变。虽然这些值可以随机分布在存储器中，但是键和指针的组合存储区域被以顺序布局，如下图所示。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/79/CgqCHl7YrG-AAlOOAAIvHSA4W4E018.png" alt="图片3.png"></p>
<h4>3．代码生成</h4>
<p>下面这段代码的逻辑很简单，可以理解为做了一个向量的内积，i、j 都来自某个向量。</p>
<pre><code data-language="java" class="lang-java">val&nbsp;i&nbsp;=&nbsp;<span class="hljs-number">23</span>
val&nbsp;j&nbsp;=&nbsp;<span class="hljs-number">5</span>
<span class="hljs-keyword">var</span>&nbsp;z&nbsp;=&nbsp;i*x+j*y
</code></pre>
<p>假设 x 和 y 都来自表中的某一行。现在，假设将表达式应用到表中的每一行中，而这个表有数十亿行，JVM 只能执行这个表达式数十亿次，这是一个非常大的开销。因此 Tungsten 实际做的是将这个表达式转换为字节码，并将其发送到执行者线程中。<br>
你可能知道，每个类在 JVM 上执行的都是字节码，这是针对不同微处理器架构的机器代码的一个中间层，这是 Java 的特点之一。因此 JVM 的工作流如下：</p>
<p>1、Java 源代码被编译为字节码；</p>
<p>2、Java 字节码被 JVM 翻译；</p>
<p>3、JVM 将字节码转换成特定平台的机器指令，并将其发送到目标 CPU。</p>
<p>目前，还没有人想过在运行时直接生成字节码，这就是代码生成想要实现的。Tungsten 分析将要被执行的任务生成由人编写的，在 JVM 上执行的特定的高性能字节码，而不是依赖预编译组件。</p>
<p>Tungsten 还有助于加速序列化与反序列化对象，JVM 提供的原生框架性能较差。而分布式数据处理框架的性能瓶颈通常在 Shuffle 阶段，在这个阶段中，数据通过网络传输，对象的序列化与反序列化是主要瓶颈（而不是 I/O 带宽），它同时也增加了 CPU 负担。因此提高这里的性能有助于消除计算瓶颈。</p>
<h4>4、Catalyst 优化器</h4>
<p>Catalyst 优化器是 Spark SQL 的重要组成部分，它是一个函数式可扩展的查询优化器，贯穿于查询计划的生成到最后执行计划的生成，对 Spark SQL 优化起到了至关重要的作用，在Tungsten 中，Catalyst 优化器也得到了优化和提升。在关系型数据库系统中，通常认为查询优化器是其最为复杂的核心组件，Spark SQL 也是如此，在 Catalyst 优化器的帮助下，Spark 开发者只需要编写简单的 SQL 就能驱动非常复杂的查询作业，并能获得最佳性能表现。</p>
<p>那么 Catalyst 优化器是如何工作的？下面这张图展示了优化器核心组件和顺序调优的过程：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/79/CgqCHl7YrIWAB0WUAAKobDDgLrw945.png" alt="图片4.png"></p>
<p>首先，无论是 DataFrame API、Dataset API 还是 Spark SQL，它们都会被转换为 ULEP（Unresolved Logical Execution Plan，未解析的逻辑执行计划）。ULEP 本质上就是一棵 SQL 语法树，生成了 ULEP 后还不能直接执行，而是通过一系列工作对 ULEP 进行处理。当ULEP 在数据目录（Catalog）中补齐了字段类型、列名等时，就会成为 RLEP（Resolved Logical Execution Plan，解析好的逻辑执行计划）。</p>
<p>RLEP 会经过多次转换生成 Optimised Logical Plan（优化的逻辑计划），该计划不会包含如何计算的描述，而只包含必须被计算的内容。根据一些策略，优化的 LEP 会转化为 PEP（Physical Execution Plans，物理执行计划）。PEP 是完全解析的执行计划。这意味着一个 PEP 包含生成期望结果的详细指令。生成 PEP 的策略会对连接算法进行优化。此外，对那些在一个 RDD 上执行的多个操作，会根据规则简化为一个复杂操作。在生成了很多 PEP 后（它们都会返回相同的结果），最好的选择是基于启发式算法来最小化执行时间。最后，执行操作会作用于 RDD 上。</p>
<p>在数据源支持的情况下，某些操作可以被下压到数据源，如过滤（谓词）或者属性选择（投影）。谓词下压的主要思路是，某些抽象语法树的部分不由 Spark 来执行，而是由数据源本身来执行，这样就减少了 Spark 与数据库的数据传输。</p>
<p><strong>从 Tungsten 可以看出，使用 DataFrame、Dataset 和 Spark SQL 处理数据，可以看成是一种从底层高度优化的 RDD 执行方案。</strong> 这种优化是全方位的，不仅仅体现在执行计划上，还体现存储、计算方式上。</p>
<h3>Hydrogen 项目</h3>
<p>Hydrogen 项目与 Tungsten 项目一样，都是对 Spark 有巨大提升的前沿探索项目，Hydrogen 项目从 Spark 2.3 开始，历经 Spark 2.4 以及 Spark 3.0。Hydrogen 项目出现的背景是，目前机器学习框架与深度学习框架开始井喷，而 Spark 的野心在于一统整个数据科学领域，所以也乐见其成，Spark 对这些框架的态度是“拥抱机器学习生态系统，并将其视为一等公民”，由此，Spark 需要将涉及数据预处理以及模型训练等整个流程深度地与这些机器学习、深度学习框架进行集成，这也是 Hydrogen 项目的目标。</p>
<p>为了实现这个目标，也就是高效地支持绝大部分机器学习框架，Spark 面临两大挑战：数据交换与执行模型。我们来看看 Hydrogen 项目是如何解决的。</p>
<h4>1、数据交换</h4>
<p>数据交换指的是在 Spark 与机器学习框架之间高吞吐地传输数据。Spark 提出了一种用户自定义函数（UDF），用来执行用户任意的代码。这种 UDF 通常用来与机器学习框架进行集成，例如使用 TensorFlow 对测试数据进行预测。UDF 支持各种语言，如 Scala、Python、R 等，UDF 可以很方便地使 Spark 与机器学习框架进行集成，用户可以在 UDF 中写一段代码来调用机器学习库。在使用 UDF 时，我们可以采用一次一行的方式执行，如下图所示：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/6D/Ciqc1F7YrJyAKVUEAADe5K0PSdg115.png" alt="图片5.png"></p>
<p>上图中包含一个简单的 Python UDF，对输入进行 +1 操作，它将对每一行的第一列进行 +1 操作，数据首先被 Spark 一次一行地读取，并在 Spark 中进行列切分，将第一列发送给 Python 进程，Python 进程接收到输入以后，对输入进行 +1 操作，并返回给 Spark，Spark 得到结果并将其和原来的两列拼接成新的一行，也就是上图中右边的那一行。Spark 一共要执行 3 次操作，直到所有数据读取完毕。如果我们深入分析这种交换方式，会发现这种交换方式的性能非常糟糕，原因是大部分的时间花在了 Spark 将数据传输给 Python，Python 又把数据传输给 Spark 上，据统计，92% 的 CPU 周期被浪费了。这当然不是我们想要的，来看看下一种交换方式：向量化的数据传输，如下图所示：</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/79/CgqCHl7YrKSAVcdPAAEktvK7qW0310.png" alt="图片6.png"></p>
<p>与一次一行的数据交换方式不同，我们采取了列式存储的小批量传输，也就是说，数据本来就是按列存储，如 ORC 或者 Parquet 这种格式，而非按行存储。Spark 会选取第一列（需要进行 +1 的列）的一个切片发送给 Python 进程，而 Python 收到的则会是一个 numpy 数组或者 panda 序列，在 UDF 中我们可以直接通过<strong>向量化操作</strong>对向量进行 +1 操作，这种计算无疑是高效的，例如 numpy 底层的数组操作由 C 语言编写，效率较原生 Python 大大提升。Spark 得到结果会按照固有的列式存储格式发送给下游。</p>
<p>向量化的数据交换方式在两个环节性能都有提升，其一是与 Python 进程的数据传输，其二是 UDF 的执行效率，根据 Databricks 的测试结果，整体效率较一次一行的数据交换方式有 3～240 倍的提升，效果极其明显。</p>
<h4>2、执行模型</h4>
<p>执行模型要解决的是，一旦 Spark 与机器学习框架进行深度融合，就会导致它与计算模型之间天生的不相容性。如果不解决这个问题，那么“一等公民”始终是一句空话。Spark 的计算模型是高度并行的，作业被划分为任务，任务与任务之间相互独立，没有依赖，如下图左边所示。</p>
<p>而常见的分布式机器学习框架的执行模型通常是统一调度，互相协调的，这是为了优化通信，在模型训练过程中，任务之间通常会有高吞吐和大带宽的数据交互，如下图右边所示。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/79/CgqCHl7YrLqAU-07AACWN8JE81g638.png" alt="图片7.png"></p>
<p>这两种模式看起来没有什么冲突，但是一旦某个任务失败，Spark 只需重新执行该任务即可，但分布式机器学习框架通常会执行所有相关的任务。在 Hydrogen 项目的第 2 部分，Spark 在一个更高的层次提出了一种带有同步栅的执行模型（及其配套的 API），统一了 Spark 与机器学习框架的执行模型，如下图所示。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/6E/Ciqc1F7YrMOAK4mvAAE5Zvaf1AI774.png" alt="图片8.png"></p>
<p>在这种模型中，Spark 将整个作业切分成 3 个 Stage，其中虚线表示的就是同步栅，在每个 Stage 中，并行的方式可以不同，以 Stage 2 的并行方式为例，一旦某个任务失败，将会重新执行所有任务。这种执行模型很好地融合了 Spark 与机器学习框架。</p>
<p>从 Hydrogen 项目的这两个部分来看，Hydrogen 项目的关键词是融合，数据交换从数据边界的层面进行了融合，而执行引擎在执行逻辑上将两种不同的分布式计算理念进行了融合，从上图中可以看出数据交换是执行引擎的基础，Stage 之间的数据交换就是利用了 Hydrogen 的数据交换的能力。</p>
<p>在 Spark 后面版本的迭代中，Hydrogen 项目的主要内容就是 SPARK-24579。SPARK-24579 的主要内容是标准化 Spark 和人工智能、深度学习框架，如 TensorFlow、MXNet 之间的数据交换过程，并优化其传输性能。SPARK-24579 的出发点在于，目前大数据与人工智能的结合是很多业务与应用成功的关键，而这两个领域的顶级开源社区也多次尝试整合，但由于 Spark SQL、DataFrame、Structured Streaming 的日趋成熟，Spark 仍然是大数据社区的首选，因此人工智能框架如何与 Spark 进行集成是整合的关键。当然，目前已经存在一些解决方案，如 TensorFlowOnSpark、TensorFrames 等，但是还没有一种标准化传输方案，所以性能优化只能根据具体情况来实现，SPARK-24579 所探讨的正是如何降低整个过程的复杂性：标准化 Spark 和人工智能、深度学习框架之间的数据交换接口。这样，人工智能、深度学习框架就可以利用 Spark 从任何地方加载数据，而无须花费额外的精力来构建复杂的数据解决方案。</p>
<p>在 JIRA 上我们还可以通过 Hydrogen 项目的标签对 issue 进行过滤，目前有 3 个没有关闭的史诗级 issue，除了SPARK-24579、SPARK-24374，还有一个 SPARK-24615，如下图所示，该 issue 也是 Hydrogen 项目的一个重要改进，将会为 Spark 添加原生的 GPU 调度支持。</p>
<p><img src="https://s0.lgstatic.com/i/image/M00/18/6E/Ciqc1F7YrNKAd6nBAABMGaZEO28266.png" alt="image (1).png"></p>
<p>目前，GPU 已经广泛应用于分布式深度学习与训练加速，但通常用户需要用 Spark 加载大量数据，最新的 Spark 版本已经在 YARN 和 Kubernetes 中支持 GPU 了，虽然如此，但是 Spark 本身并不知道它们暴露的 GPU，所以 Spark 用户无法正常请求和调度，SPARK-24615 将会为这类训练加速任务添加调度支持，该 issue 的目标如下。</p>
<ul>
<li>让 Spark 3.0 在 Standalone 模式、YARN 模式和 Kubernetes 模式中具有 GPU 感知能力。</li>
<li>保证普通作业的调度性能。</li>
</ul>
<p>未来，该 issue 希望达到的目标如下。</p>
<ul>
<li>GPU 计算卡的细粒度调度。</li>
<li>将 GPU 计算卡和它的内存看成一个不可分割的单元。</li>
<li>支持 TPU。</li>
<li>支持 Mesos。</li>
</ul>
<p>该 issue 想要做到的是在资源层面实现 Spark 和人工智能框架的融合和统一，同步栅模型则在执行层面上实现 Spark 和人工智能框架的融合和统一。</p>
<h3>小结</h3>
<p>本课时主要介绍了 Spark 开发过程中的两个重要大型优化项目，这两个项目很大程度上体现了 Spark 设计者的思路，并影响着 Spark 未来的发展方向，其中可以看到，向量化执行和代码生成都是数据库引擎的优化技术，说明 Spark 借鉴了这一部分思想为己用。</p>
<p>本课时的内容偏理论，所以这里给你留一个任务，你可以去 Spark Jira 看板上跟踪 Hydrogen 项目的最新进展以及 Spark 未来的发展方向，链接如下：</p>
<p><a href="https://issues.apache.org/jira/projects/SPARK/">https://issues.apache.org/jira/projects/SPARK/</a>。</p>
<p>你不要小看了这个过程，未来你也可以向社区提出自己所需的 issue，提出 issue 也是参与社区的一种重要形式。</p>

---

### 精选评论

##### *聪：
> 深入浅出

##### **生：
> 这章好有难度啊，要反复看，抓基础

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 小编看好你哦~加油

