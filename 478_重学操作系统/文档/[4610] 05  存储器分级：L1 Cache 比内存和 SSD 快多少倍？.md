<p data-nodeid="6291" class=""><strong data-nodeid="6408">近两年我在面试求职者的时候，喜欢问这样一道面试题：SSD、内存和 L1 Cache 相比速度差多少倍</strong>？</p>
<p data-nodeid="6292" class="">其实比起复杂的技术问题，我更喜欢在面试中提问这种像生活常识一样的简单问题。因为我觉得，复杂的问题是由简单的问题组成的，如果你把简单的问题学扎实了，那么复杂问题也是可以自己推导的。</p>
<p data-nodeid="6293">如果你不知道 L1 Cache，可能会错误地判断内存执行速度。我们写程序，会用寄存器、内存以及硬盘，所以按照墨菲定律，如果这里有一个认知是错误的，那么最终的结果就会产生问题。</p>
<p data-nodeid="10404" class="">下面，回到我们今天的问题，这个问题关联的知识点是存储器分级策略。接下来，请你带着问题开始学习今天的内容。</p>









<h3 data-nodeid="6295">为什么会有存储器分级策略？</h3>
<p data-nodeid="6296">要想弄清楚存储器分级策略。</p>
<p data-nodeid="6297">首先，你要弄清楚，“我们希望存储器是什么样子的”，也就是“我们的需求是什么”？</p>
<p data-nodeid="6298">然后，你要弄清楚，我们的需求有哪些“实现约束”。</p>
<p data-nodeid="6299">从需求上讲，我们希望存储器速度快、体积小、空间大、能耗低、散热好、断电数据不丢失。但在现实中，我们往往无法把所有需求都实现。</p>
<p data-nodeid="6300">下面我们举几个例子，带你深入体会一下，比如：</p>
<ul data-nodeid="6301">
<li data-nodeid="6302">
<p data-nodeid="6303">如果一个存储器的体积小，那它存储空间就会受到制约。</p>
</li>
<li data-nodeid="6304">
<p data-nodeid="6305">如果一个存储器电子元件密度很大，那散热就会有问题。因为电子元件都会产生热能，所以电子元件非常集中的 CPU，就需要单独的风扇或者水冷帮助电子元件降温。</p>
</li>
<li data-nodeid="6306">
<p data-nodeid="6307">如果一个存储器离 CPU 较远，那么在传输过程中必然会有延迟，因此传输速度也会下降。</p>
</li>
</ul>
<p data-nodeid="6308">这里你可能会有疑问，因为在大多数人的认知里，光速是很快的，而信号又是以光速传输的。既然光速这么快，那信号的延迟应该很小才对。但事实并不是这样，比如时钟信号是 1GHz 的 CPU，1G 代表 10 个亿，因此时钟信号的一个周期是 1/10 亿秒。而光的速度是 3×10 的 8 次方米每秒，就是 3 亿米每秒。所以在一个周期内，光只能前进 30 厘米。</p>
<p data-nodeid="6309">你看！虽然在宏观世界里光速非常快，但是到计算机世界里，光速并没有像我们认知中的那么快。所以即使元件离 CPU 的距离稍微远了一点，运行速度也会下降得非常明显。</p>
<p data-nodeid="10888" class="">你可能还会问，那干吗不把内存放到 CPU 里？</p>

<p data-nodeid="6311">如果你这么做的话，除了整个电路散热和体积会出现问题，服务器也没有办法做定制内存了。也就是说 CPU 在出厂时就决定了它的内存大小，如果你想换更大的内存，就要换 CPU，而组装定制化是你非常重要的诉求，这肯定是不能接受的。</p>
<p data-nodeid="6312">此外，在相同价格下，一个存储器的速度越快，那么它的能耗通常越高。能耗越高，发热量越大。</p>
<p data-nodeid="6313">因此，我们上面提到的需求是不可能被全部满足的，除非将来哪天存储技术有颠覆性的突破。</p>
<h3 data-nodeid="6314">存储器分级策略</h3>
<p data-nodeid="6315">既然我们不能用一块存储器来解决所有的需求，那就必须把需求分级。</p>
<p data-nodeid="6316">一种可行的方案，就是根据数据的使用频率使用不同的存储器：高频使用的数据，读写越快越好，因此用最贵的材料，放到离 CPU 最近的位置；使用频率越低的数据，我们放到离 CPU 越远的位置，用越便宜的材料。</p>
<p data-nodeid="6317"><img src="https://s0.lgstatic.com/i/image/M00/51/2D/Ciqc1F9kgVGAD_IMAACXR1QKcDo779.png" alt="Lark20200918-174334.png" data-nodeid="6432"></p>
<p data-nodeid="6318">具体来说，通常我们把存储器分成这么几个级别：</p>
<ol data-nodeid="6319">
<li data-nodeid="6320">
<p data-nodeid="6321">寄存器；</p>
</li>
<li data-nodeid="6322">
<p data-nodeid="6323">L1-Cache；</p>
</li>
<li data-nodeid="6324">
<p data-nodeid="6325">L2-Cache；</p>
</li>
<li data-nodeid="6326">
<p data-nodeid="6327">L3-Cahce；</p>
</li>
<li data-nodeid="6328">
<p data-nodeid="6329">内存；</p>
</li>
<li data-nodeid="6330">
<p data-nodeid="6331">硬盘/SSD。</p>
</li>
</ol>
<h4 data-nodeid="6332">寄存器（Register）</h4>
<p data-nodeid="6333">寄存器紧挨着 CPU 的控制单元和逻辑计算单元，它所使用的材料速度也是最快的。就像我们前面讲到的，存储器的速度越快、能耗越高、产热越大，而且花费也是最贵的，因此数量不能很多。</p>
<p data-nodeid="6334">寄存器的数量通常在几十到几百之间，每个寄存器可以用来存储一定字节（byte）的数据。比如：</p>
<ul data-nodeid="6335">
<li data-nodeid="6336">
<p data-nodeid="6337">32 位 CPU 中大多数寄存器可以存储 4 个字节；</p>
</li>
<li data-nodeid="6338">
<p data-nodeid="6339">64 位 CPU 中大多数寄存器可以存储 8 个字节。</p>
</li>
</ul>
<p data-nodeid="6340">寄存机的访问速度非常快，一般要求在半个 CPU 时钟周期内完成读写。比如一条要在 4 个周期内完成的指令，除了读写寄存器，还需要解码指令、控制指令执行和计算。如果寄存器的速度太慢，那 4 个周期就可能无法完成这条指令了。</p>
<h4 data-nodeid="6341">L1-Cache</h4>
<p data-nodeid="13808" class="">L1- 缓存在 CPU 中，相比寄存器，虽然它的位置距离 CPU 核心更远，但造价更低。通常 L1-Cache 大小在几十 Kb 到几百 Kb 不等，读写速度在 2~4 个 CPU 时钟周期。</p>

<h4 data-nodeid="6343">L2-Cache</h4>
<p data-nodeid="13314" class="">L2- 缓存也在 CPU 中，位置比 L1- 缓存距离 CPU 核心更远。它的大小比 L1-Cache 更大，具体大小要看 CPU 型号，有 2M 的，也有更小或者更大的，速度在 10~20 个 CPU 周期。</p>

<h4 data-nodeid="6345">L3-Cache</h4>
<p data-nodeid="12824" class="">L3- 缓存同样在 CPU 中，位置比 L2- 缓存距离 CPU 核心更远。大小通常比 L2-Cache 更大，读写速度在 20~60 个 CPU 周期。L3 缓存大小也是看型号的，比如 i9 CPU 有 512KB L1 Cache；有 2MB L2 Cache； 有16MB L3 Cache。</p>




<h4 data-nodeid="6347">内存</h4>
<p data-nodeid="14306" class="">内存的主要材料是半导体硅，是插在主板上工作的。因为它的位置距离 CPU 有一段距离，所以需要用总线和 CPU 连接。因为内存有了独立的空间，所以体积更大，造价也比上面提到的存储器低得多。现在有的个人电脑上的内存是 16G，但有些服务器的内存可以到几个 T。内存速度大概在 200~300 个 CPU 周期之间。</p>

<h3 data-nodeid="6349">SSD 和硬盘</h3>
<p data-nodeid="14808" class="">SSD 也叫固态硬盘，结构和内存类似，但是它的优点在于断电后数据还在。内存、寄存器、缓存断电后数据就消失了。内存的读写速度比 SSD 大概快 10~1000 倍。以前还有一种物理读写的磁盘，我们也叫作硬盘，它的速度比内存慢 100W 倍左右。因为它的速度太慢，现在已经逐渐被 SSD 替代。</p>

<p data-nodeid="6351"><img src="https://s0.lgstatic.com/i/image/M00/51/2C/Ciqc1F9kgMWAAU1JAABxd6qpCo0763.png" alt="Lark20200918-173926.png" data-nodeid="6460"></p>
<p data-nodeid="6352" class="">当 CPU 需要内存中某个数据的时候，如果寄存器中有这个数据，我们可以直接使用；如果寄存器中没有这个数据，我们就要先查询 L1 缓存；L1 中没有，再查询 L2 缓存；L2 中没有再查询 L3 缓存；L3 中没有，再去内存中拿。</p>
<h3 data-nodeid="6353">缓存条目结构</h3>
<p data-nodeid="6354">上面我们介绍了存储器分级结构大概有哪些存储以及它们的特点，接下来还有一些缓存算法和数据结构的设计困难要和你讨论。比如 CPU 想访问一个内存地址，那么如何检查这个数据是否在 L1- 缓存中？换句话说，缓存中的数据结构和算法是怎样的？</p>
<p data-nodeid="6355">无论是缓存，还是内存，它们都是一个线性存储器，也就是数据一个挨着一个的存储。如果我们把内存想象成一个只有 1 列的表格，那么缓存就是一个多列的表格，这个表格中的每一行叫作一个缓存条目。</p>
<h4 data-nodeid="6356">方案 1</h4>
<p data-nodeid="6357">缓存本质上是一个 Key-Value 的存储，它的 Key 是内存地址，值是缓存时刻内存地址中的值。我们先思考一种简单的方案，一个缓存条目设计 2 列：</p>
<ol data-nodeid="6358">
<li data-nodeid="6359">
<p data-nodeid="6360">内存的地址；</p>
</li>
<li data-nodeid="6361">
<p data-nodeid="6362">缓存的值。</p>
</li>
</ol>
<p data-nodeid="6363">CPU 读取到一个内存地址，我们就增加一个条目。当我们要查询一个内存地址的数据在不在 L1- 缓存中的时候，可以遍历每个条目，看条目中的内存地址是否和查询的内存地址相同。如果相同，我们就取出条目中缓存的值。</p>
<p data-nodeid="6364">这个方法需要遍历缓存中的每个条目，因此计算速度会非常慢，在最坏情况下，算法需要检查所有的条目，所以这不是一个可行的方案。</p>
<h4 data-nodeid="6365">方案 2</h4>
<p data-nodeid="6366">其实很多优秀的方案，往往是从最笨的方案改造而来的。现在我们已经拥有了一个方案，但是这个方案无法快速确定一个内存地址缓存在哪一行。因此我们想要找到一个更好的方法，让我们看到一个内存地址，就能够快速知道它在哪一行。</p>
<p data-nodeid="15061" class="">这里，我们可以用一个数学的方法。比如有 1000 个内存地址，但只有 10 个缓存条目。内存地址的编号是 0、1、2、3，...，999，缓存条目的编号是 0~9。我们思考一个内存编号，比如 701，然后用数学方法把它映射到一个缓存条目，比如 701 整除 10，得到缓存条目 1。</p>

<p data-nodeid="6368">用这种方法，我们每次拿到一个内存地址，都可以快速确定它的缓存条目；然后再比较缓存条目中的第一列内存地址和查询的内存地址是否相同，就可以确定内存地址有没有被缓存。</p>
<p data-nodeid="6369">延伸一下，这里用到了一种类似哈希表的方法：<code data-backticks="1" data-nodeid="6476">地址 % 10</code>，其实就构成了一个简单的哈希函数。</p>
<h3 data-nodeid="6370">指令的预读</h3>
<p data-nodeid="6371">接下来我们讨论下指令预读的问题。</p>
<p data-nodeid="16077" class="">之前我们学过，CPU 顺序执行内存中的指令，CPU 执行指令的速度是非常快的，一般是 2~6 个 CPU 时钟周期；这节课，我们学习了存储器分级策略，发现内存的读写速度其实是非常慢的，大概有 200~300 个时钟周期。</p>


<p data-nodeid="6373">不知道你发现没有？这也产生了一个非常麻烦的问题：CPU 其实是不能从内存中一条条读取指令再执行的，如果是这样做，那每执行一条指令就需要 200~300 个时钟周期了。</p>
<p data-nodeid="6374">那么，这个问题如何处理呢？</p>
<p data-nodeid="6375">这里我再多说一句，你在做业务开发 RPC 调用的时候，其实也会经常碰到这种情况，远程调用拖慢了整体执行效率，下面我们一起讨论这类问题的解决方案。</p>
<p data-nodeid="16593" class="">一个解决办法就是 CPU 把内存中的指令预读几十条或者上百条到读写速度较快的 L1- 缓存中，因为 L1- 缓存的读写速度只有 2~4 个时钟周期，是可以跟上 CPU 的执行速度的。</p>

<p data-nodeid="6377">这里又产生了另一个问题：如果数据和指令都存储在 L1- 缓存中，如果数据缓存覆盖了指令缓存，就会产生非常严重的后果。因此，L1- 缓存通常会分成两个区域，一个是指令区，一个是数据区。</p>
<p data-nodeid="6378">与此同时，又出现了一个问题，L1- 缓存分成了指令区和数据区，那么 L2/L3 需不需要这样分呢？其实，是不需要的。因为 L2 和 L3，不需要协助处理指令预读的问题。</p>
<h3 data-nodeid="6379">缓存的命中率</h3>
<p data-nodeid="6380">接下来，还有一个重要的问题需要解决。就是 L1/L2/L3 加起来，缓存的命中率有多少？</p>
<p data-nodeid="6381">所谓命中就是指在缓存中找到需要的数据。和命中相反的是穿透，也叫 miss，就是一次读取操作没有从缓存中找到对应的数据。</p>
<p data-nodeid="6382">据统计，L1 缓存的命中率在 80% 左右，L1/L2/L3 加起来的命中率在 95% 左右。因此，CPU 缓存的设计还是相当合理的。只有 5% 的内存读取会穿透到内存，95% 都能读取到缓存。&nbsp;这也是为什么程序语言逐渐取消了让程序员操作寄存器的语法，因为缓存保证了很高的命中率，多余的优化意义不大，而且很容易出错。</p>
<h3 data-nodeid="6383">缓存置换问题</h3>
<p data-nodeid="6384">最后的一个问题，比如现在 L1- 缓存条目已经存满了，接下来 CPU 又读了内存，需要把一个新的条目存到 L1- 缓存中，既然有一个新的条目要进来，那就有一个旧的条目要出去。所以，这个时候我们就需要用一个算法去计算哪个条目应该被置换出去。这个问题叫作缓存置换问题。有关缓存置换问题，我会在 “21 | 进程的调度：进程调度都有哪些方法？”中和你讨论。</p>
<h3 data-nodeid="6385">总结</h3>
<p data-nodeid="6386">这节课我们讲到了存储器分级策略，讨论了 L1/L2/L3 缓存的工作原理。本课时学习的内容，是所有缓存知识的源头。所有缓存系统的设计，都是存储资源的分级。我们在设计缓存的时候，除了要关心整体架构外，还需要注意细节，比如：</p>
<ul data-nodeid="6387">
<li data-nodeid="6388">
<p data-nodeid="6389">条目怎么设计？</p>
</li>
<li data-nodeid="6390">
<p data-nodeid="6391">算法怎么设计？</p>
</li>
<li data-nodeid="6392">
<p data-nodeid="6393">命中率怎么统计？</p>
</li>
<li data-nodeid="6394">
<p data-nodeid="6395">缓存怎么置换等？</p>
</li>
</ul>
<p data-nodeid="6396">现在我们来说一下课前提出的问题：<strong data-nodeid="6512">SSD、内存和 L1 Cache 相比速度差多少倍</strong>？</p>
<p data-nodeid="6397">还是老规矩，请你先自己思考这个问题的答案，写在留言区，然后再来看我接下来的分析。</p>
<p data-nodeid="17111" class=""><strong data-nodeid="17120">【解析】</strong> 因为内存比 SSD 快 10~1000 倍，L1 Cache 比内存快 100 倍左右。因此 L1 Cache 比 SSD 快了 1000~100000 倍。所以你有没有发现 SSD 的潜力很大，好的 SSD 已经接近内存了，只不过造价还略高。</p>

<p data-nodeid="6399">这个问题告诉我们，不同的存储器之间性能差距很大，构造存储器分级很有意义，分级的目的是要构造缓存体系。</p>
<h3 data-nodeid="6400">课后习题</h3>
<p data-nodeid="6401">最后，我再给你留一道课后练习题，同样也是一道高频面试题目。</p>
<p data-nodeid="6402"><strong data-nodeid="6530">假设有一个二维数组，总共有 1M 个条目，如果我们要遍历这个二维数组，应该逐行遍历还是逐列遍历</strong>？</p>
<p data-nodeid="6403" class="">你可以把你的答案、思路或者课后总结写在留言区，这样可以帮助你产生更多的思考，这也是构建知识体系的一部分。经过长期的积累，相信你会得到意想不到的收获。如果你觉得今天的内容对你有所启发，欢迎分享给身边的朋友。期待看到你的思考！</p>

---

### 精选评论

##### *方：
> 课代表总结:">存储器分级: 一般情况下存储器分为寄存器，l1 cache，l2 cache, l3 cache ，内存，SSD/磁盘。从云到右，距离CPU逐渐变远，读取速度逐渐减低，空间逐渐增大。缓存条目: 缓存可以看作是双列结构，分别存储着内存地址和对应的值。想要快速的定位缓存条目可以通过取余(类似hash算法)快速定位缓存条目位置。指令预读: 通过对于指令的预读，使得读取指令的速度跟的上指令的执行速度。减少指令从内存中的读取次数(更耗时)，其实就是批处理。缓存的命中: l1的缓存命中率约为80%，l1 l2 l3缓存加在一块命中率高达95%。缓存置换: 当缓存满了之后，再读取数据到缓存将置换掉之前的缓存。思考题: 因为读取数组元素的时候，他会将和他连在一起的若干元素(块数据)都读入缓存中。而再遍历后续的数据时将直接命中缓存，大大减少了从内存读取的次数。而二维数组中的列数据在内存上往往是不连续的，因此如果是按列遍历很难命中缓存，将不断的从内存读取数据，速度很低。

##### **鹏：
> 二维数组的结构是由多个一维数组构成的，其中这些一维数组都是连续的，所以逐行遍历会将这些连续的地址加载到cache中，缓存命中率大大提高。之前有用JAVA语言在Linux环境中试过，相差11～12倍的样子。cache line是64字节，不同的语言，对象占用情况也不一致，是否有开启指针压缩等。

##### **法：
> “先列后行”遍历发生的页面交换次数要比“先行后列”多，且cache命中率相对较低。例如对于int b[128][1024];假设内存页大小为4096字节，该数组每行正好占据一个内存页的空间，若按先行后列遍历，外层循环每走一行，内层走过1024个元素正好一页，没发生页面调度，遍历完整个数组页面调度次数最多为128次；若按先列后行，则每遍历一个元素，都发生一次页面调度，因为列上每个元素位于同行内（不同页），遍历整个数组页面调度次数可能达到1024*128次；实际中由于物理内存足够，调度次数会减少很多

##### **亮：
> 老师讲的都能听懂没有什么压力，做一次梳理。😄

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 优秀！

##### **6475：
> 肯定是按行遍历，可以充分利用 cpu 缓存，快的不止一点点！

##### **珍：
> 老师讲下段页式

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 模块五内存管理见！

##### **民：
> 数据预读的特性, 使用逐行遍历

##### **珲：
> “比如有 1000 个内存地址，但只有 10 个缓存条目。内存地址的编号是 0、1、2、3，...，999，缓存条目的编号是 0~9。我们思考一个内存编号，比如 701，然后用数学方法把它映射到一个缓存条目，比如 701 整除 10，得到缓存条目 1。”这里10个缓存条目如何与1000个地址一一对应呢？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 缓存总是比目标数据小的，比如CPU缓存肯定比内存小。并不是追求11映射。

##### **锦：
> 按行读入，因为行里数据地址相邻，读取完这一个就可以接着读取下一个，不用一直去内存重新加载。例如一次读取10w条，按行读取只需10次。按列读取时，要处理下一个数据，由于下一个数据在另一列，需要重新去内存读取，也就是一个数据就去内存加载一次，就要加载100w次，效果一个天一个地

##### rick：
> “比如时钟信号是 1GHz 的 CPU，1G 代表 10 个亿，因此时钟信号的一个周期是 1/10 亿秒。而光的速度是 3×10 的 8 次方米每秒，就是 3 亿米每秒。所以在一个周期内，光只能前进 33 厘米”—这里应该是30厘米吧？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 1/10亿秒*3*10^8=0.3 同学很细心，应该是30厘米。我已经修正了，谢谢

##### *䭽：
> 大家学会了吗？

##### **蛟：
> 要看这个二维数组是主行存储还是主列存储，放在numpy里面就是看order是C形式还是Fortran形式

##### **超：
> 学到很多新东西😁

##### *锋：
> 空间换时间

##### **文：
> 老师讲的很好，条理很清楚，能更好地理解OS。一点点将之前了解到的知识串联起来，感谢！

##### **华：
> 这个已经是听过的最清晰的Linux讲解了，但因为是新手，还有些没太懂的就略过了，但总体对Linux有了更好的认知

##### **安：
> 缓存从内存中抓取一般都是整个数据块，所以它的物理内存是连续的，也是按行抓取。当二维数组有 1M 个条目，假如是 int[1024][1024] ，假设一页的内存为 4096 个字节，而每一行正好占据内存的一页。如果以列的形式进行遍历，就会发生 1024*1024  次页面调度，而如果以行遍历，则只会发生 1024 次页面调度。调度次数越多，遍历所花费的时间越长。

##### **珲：
> 各级缓存如果在出厂时大小是定的，那它的数据范围不也是可以确定的吗，为什么还要去设计算法检测在哪级缓存呢？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 缓存可比内存小多了。 因此只能存内存中一小部分。 因此需要设计算法。

##### **玮：
> 请问老师，L1中的内容必然存在于L2中，L2中的内容必然存在于L3中么？这三级是如何区分的呢？按照用途？按照存储的数据的类型？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 这就是简单设计的3层，缓存设计往往简单有效更好。没有很复杂的算法。除了L1分成了数据区和指令区外，其他没啥区别。工作原理也一致。多数情况下L1中有一个条目，那么L2中也有。但是这个不好说。具体同学可以再深挖下。

##### **鑫：
> 计算机小白，有两个问题：1.缓存条目结构这段第二种方法“每次拿到一个内存地址，都可以快速确定它的缓存条目；然后再比较缓存条目中的第一列内存地址和查询的内存地址是否相同，就可以确定内存地址有没有被缓存”如果不一样是不是需要跟第一种方法一样需要遍历缓存中的每个条目呢？2.指令的预读这段“L1- 缓存通常会分成两个区域，一个是指令区，一个是数据区”为什么指令不能存在指令寄存器中呢？

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 1.如果不一样，就认为没有被缓存，直接读内存了。 2. 内存速度太慢了，如果一条条指令读，然后CPU执行，瓶颈就会在内存读写速度上。因此指令必须一块一块的导入CPU，这里就需要缓存。

##### **弟：
> L1速度是SSD的1000～100000倍吧……少写个0？

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 感谢反馈，小编已更改

##### **1969：
> 等着下期呢😂

##### **星：
> 逐行遍历。因为内存是线性结构存储。最近在学习java并发，结合这章知识真是受益匪浅

##### **鸣：
> 不知不觉就看到最新章节了，老师很棒，了解了很多，是时候重学一波操作系统的知识了，现在感觉计算机组成原理很重要，大学的时候没有好好学，哎，后悔死了。

##### **用户9719：
> 这要看使用的是什么语言也就是数组的结构是怎么设计的使用C这样的语言我觉得都可以使用java就需要按照行遍历了

##### **喆：
> 这门课老师讲的真是买的这些里面最好的，很清晰。

##### **冠琛：
> 学习学习

##### *庚：
> 逐行，空间局域性

##### **俊：
> 二维数组在内存中存储的时候会把二维数组按照行摊平的，按行遍历可以充分利用 CPU 预读的特性的

##### **生：
> ｛｛1，2，3｝，｛4，5，6｝｝数组按行存储，按行遍历比较好

