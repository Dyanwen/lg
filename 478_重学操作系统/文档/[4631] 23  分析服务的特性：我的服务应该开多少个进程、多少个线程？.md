<p data-nodeid="44683" class="">在平时工作中，你应该经常会遇到自己设计的服务即将上线，这就需要从整体评估各项指标，比如应该开多少个容器、需要多少 CPU 呢？另一方面，应该开多少个线程、多少个进程呢？——如果结合服务特性、目标并发量、目标吞吐量、用户可以承受的延迟等分析，又应该如何调整各种参数？</p>
<p data-nodeid="44684">资源分配多了，CPU、内存等资源会产生资源闲置浪费。资源给少了，则服务不能正常工作，甚至雪崩。因此这里就产生了一个性价比问题——这一讲，就以“<strong data-nodeid="44808">我的服务应该开多少个进程、多少个线程</strong>”为引，我们一起讨论如何更好地利用系统的资源。</p>
<h3 data-nodeid="44685">计算密集型和 I/O 密集型</h3>
<p data-nodeid="44686">通常我们会遇到两种任务，一种是计算、一种是 I/O。</p>
<p data-nodeid="44687"><strong data-nodeid="44819">计算</strong>，就是利用 CPU 处理算数运算。比如深度神经网络（Deep Neural Networks），需要大量的计算来计算神经元的激活和传播。再比如，根据营销规则计算订单价格，虽然每一个订单只需要少量的计算，但是在并发高的时候，所有订单累计加起来就需要大量计算。如果一个应用的主要开销在计算上，我们称为<strong data-nodeid="44820">计算密集型</strong>。</p>
<p data-nodeid="44688">再看看 <strong data-nodeid="44830">I/O 密集型</strong>，I/O 本质是对设备的读写。读取键盘的输入是 I/O，读取磁盘（SSD）的数据是 I/O。通常 CPU 在设备 I/O 的过程中会去做其他的事情，当 I/O 完成，设备会给 CPU 一个中断，告诉 CPU 响应 I/O 的结果。比如说从硬盘读取数据完成了，那么硬盘给 CPU 一个中断。如果操作对 I/O 的依赖强，比如频繁的文件操作（写日志、读写数据库等），可以看作<strong data-nodeid="44831">I/O 密集型</strong>。</p>
<p data-nodeid="44689">你可能会有一个疑问，<strong data-nodeid="44837">读取硬盘数据到内存中这个过程，CPU 需不需要一个个字节处理</strong>？</p>
<p data-nodeid="44690">通常是不用的，因为在今天的计算机中有一个叫作 Direct Memory Access（DMA）的模块，这个模块允许硬件设备直接通过 DMA 写内存，而不需要通过 CPU（占用 CPU 资源）。</p>
<p data-nodeid="44691"><img src="https://s0.lgstatic.com/i/image/M00/71/6A/Ciqc1F--MyKAQSfQAABs29xFyFQ392.png" alt="5.png" data-nodeid="44841"></p>
<p data-nodeid="44692">很多情况下我们没法使用 DMA，比如说你想把一个数组拷贝到另一个数组内，执行的 memcpy 函数内部实现就是一个个 byte 拷贝，这种情况也是一种<strong data-nodeid="44847">CPU 密集的操作</strong>。</p>
<p data-nodeid="44693">可见，区分是计算密集型还是 I/O 密集型这件事比较复杂。按说查询数据库是一件 I/O 密集型的事情，但是如果存储设备足够好，比如用了最好的固态硬盘阵列，I/O 速度很快，反而瓶颈会在计算上（对缓存的搜索耗时成为主要部分）。因此，需要一些可衡量指标，来帮助我们确认应用的特性。</p>
<h3 data-nodeid="44694">衡量 CPU 的工作情况的指标</h3>
<p data-nodeid="44695">我们先来看一下 CPU 关联的指标。如下图所示：CPU 有 2 种状态，忙碌和空闲。此外，CPU 的时间还有一种被偷走的情况。</p>
<p data-nodeid="44696"><img src="https://s0.lgstatic.com/i/image/M00/71/6A/Ciqc1F--MyyAGUJkAACsJU_MgVg506.png" alt="7.png" data-nodeid="44853"></p>
<p data-nodeid="44697">忙碌就是 CPU 在执行有意义的程序，空闲就是 CPU 在执行让 CPU 空闲（空转）的指令。通常让 CPU 空转的指令能耗更低，因此让 CPU 闲置时，我们会使用特别的指令，最终效果和让 CPU 计算是一样的，都可以把 CPU 执行时间填满，只不过这类型指令能耗低一些而已。除了忙碌和空闲，CPU 的时间有可能被宿主偷走，比如一台宿主机器上有 10 个虚拟机，宿主可以偷走给任何一台虚拟机的时间。</p>
<p data-nodeid="44698">如上图所示，CPU 忙碌有 3 种情况：</p>
<ol data-nodeid="44699">
<li data-nodeid="44700">
<p data-nodeid="44701">执行用户空间程序；</p>
</li>
<li data-nodeid="44702">
<p data-nodeid="44703">执行内核空间程序；</p>
</li>
<li data-nodeid="44704">
<p data-nodeid="44705">执行中断程序。</p>
</li>
</ol>
<p data-nodeid="44706">CPU 空闲有 2 种情况。</p>
<ol data-nodeid="44707">
<li data-nodeid="44708">
<p data-nodeid="44709">CPU 无事可做，执行空闲指令（注意，不能让 CPU 停止工作，而是执行能耗更低的空闲指令）。</p>
</li>
<li data-nodeid="44710">
<p data-nodeid="44711">CPU 因为需要等待 I/O 而空闲，比如在等待磁盘回传数据的中断，这种我们称为 I/O Wait。</p>
</li>
</ol>
<p data-nodeid="44712">下图是我们执行 top 指令看到目前机器状态的快照，接下来我们仔细研究一下这些指标的含义：</p>
<p data-nodeid="44713"><img src="https://s0.lgstatic.com/i/image/M00/71/76/CgqCHl--MzuAVvG-AAMVu_JwSyA231.png" alt="2.png" data-nodeid="44865"></p>
<p data-nodeid="44714">如上图所示，你可以细看下 <strong data-nodeid="44871">%CPU(s)</strong> 开头那一行（第 3 行）：</p>
<ol data-nodeid="44715">
<li data-nodeid="44716">
<p data-nodeid="44717">us（user），即用户空间 CPU 使用占比。</p>
</li>
<li data-nodeid="44718">
<p data-nodeid="44719">sy（system），即内核空间 CPU 使用占比。</p>
</li>
<li data-nodeid="44720">
<p data-nodeid="44721">ni（nice），nice 是 Unix 系操作系统控制进程优先级用的。-19 是最高优先级， 20 是最低优先级。这里代表了调整过优先级的进程的 CPU 使用占比。</p>
</li>
<li data-nodeid="44722">
<p data-nodeid="44723">id（idle），闲置的 CPU 占比。</p>
</li>
<li data-nodeid="44724">
<p data-nodeid="44725">wa（I/O Wait），I/O Wait 闲置的 CPU 占比。</p>
</li>
<li data-nodeid="44726">
<p data-nodeid="44727">hi（hardware interrupts），响应硬件中断 CPU 使用占比。</p>
</li>
<li data-nodeid="44728">
<p data-nodeid="44729">si（software interrrupts），响应软件中断 CPU 使用占比。</p>
</li>
<li data-nodeid="44730">
<p data-nodeid="44731">st（stolen），如果当前机器是虚拟机，这个指标代表了宿主偷走的 CPU 时间占比。对于一个宿主多个虚拟机的情况，宿主可以偷走任何一台虚拟机的 CPU 时间。</p>
</li>
</ol>
<p data-nodeid="44732">上面我们用 top 看的是一个平均情况，如果想看所有 CPU 的情况可以 top 之后，按一下<code data-backticks="1" data-nodeid="44881">1</code>键。结果如下图所示：</p>
<p data-nodeid="44733"><img src="https://s0.lgstatic.com/i/image/M00/71/6A/Ciqc1F--M0uAGZ1pAAmKNbPhB9A282.png" alt="3.png" data-nodeid="44885"></p>
<p data-nodeid="44734">当然，对性能而言，CPU 数量也是一个重要因素。可以看到我这台虚拟机一共有 16 个核心。</p>
<h3 data-nodeid="44735">负载指标</h3>
<p data-nodeid="44736">上面的指标非常多，在排查问题的时候，需要综合分析。其实还有一些更简单的指标，比如上图中 top 指令返回有一项叫作<code data-backticks="1" data-nodeid="44889">load average</code>——平均负载。 负载可以理解成某个时刻正在排队执行的进程数除以 CPU 核数。平均负载需要多次采样求平均值。 如果这个值大于<code data-backticks="1" data-nodeid="44891">1</code>，说明 CPU 相当忙碌。因此如果你想发现问题，可以先检查这个指标。</p>
<p data-nodeid="44737">具体来说，如果平均负载很高，CPU 的 I/O Wait 也很高， 那么就说明 CPU 因为需要大量等待 I/O 无法处理完成工作。产生这个现象的原因可能是：线上服务器打日志太频繁，读写数据库、网络太频繁。你可以考虑进行批量读写优化。</p>
<p data-nodeid="44738">到这里，你可能会有一个疑问：为什么批量更快呢？我们知道一次写入 1M 的数据，就比写一百万次一个 byte 快。因为前者可以充分利用 CPU 的缓存、复用发起写操作程序的连接和缓冲区等。</p>
<p data-nodeid="44739">如果想看更多<code data-backticks="1" data-nodeid="44896">load average</code>，你可以看<code data-backticks="1" data-nodeid="44898">/proc/loadavg</code>文件。</p>
<h3 data-nodeid="44740">通信量（Traffic）</h3>
<p data-nodeid="44741">如果怀疑瓶颈发生在网络层面，或者想知道当前网络状况。可以查看<code data-backticks="1" data-nodeid="44902">/proc/net/dev</code>，下图是在我的虚拟机上的查询结果：</p>
<p data-nodeid="44742"><img src="https://s0.lgstatic.com/i/image/M00/71/76/CgqCHl--M1aALjSiAALKG4QzX18230.png" alt="4.png" data-nodeid="44906"></p>
<p data-nodeid="44743">我们来一起看一下上图中的指标。表头分成了 3 段：</p>
<ul data-nodeid="44744">
<li data-nodeid="44745">
<p data-nodeid="44746">Interface（网络接口），可以理解成网卡</p>
</li>
<li data-nodeid="44747">
<p data-nodeid="44748">Receive：接收的数据</p>
</li>
<li data-nodeid="44749">
<p data-nodeid="44750">Transmit：发送的数据</p>
</li>
</ul>
<p data-nodeid="44751">然后再来看具体的一些参数：</p>
<ul data-nodeid="44752">
<li data-nodeid="44753">
<p data-nodeid="44754">byte 是字节数</p>
</li>
<li data-nodeid="44755">
<p data-nodeid="44756">package 是封包数</p>
</li>
<li data-nodeid="44757">
<p data-nodeid="44758">erros 是错误数</p>
</li>
<li data-nodeid="44759">
<p data-nodeid="44760">drop 是主动丢弃的封包，比如说时间窗口超时了</p>
</li>
<li data-nodeid="44761">
<p data-nodeid="44762">fifo: FIFO 缓冲区错误（<strong data-nodeid="44921">如果想了解更多可以关注我即将推出的《计算机网络》专栏</strong>）</p>
</li>
<li data-nodeid="44763">
<p data-nodeid="44764">frame: 底层网络发生了帧错误，代表数据出错了</p>
</li>
</ul>
<p data-nodeid="44765">如果你怀疑自己系统的网络有故障，可以查一下通信量部分的参数，相信会有一定的收获。</p>
<h3 data-nodeid="44766">衡量磁盘工作情况</h3>
<p data-nodeid="44767">有时候 I/O 太频繁导致磁盘负载成为瓶颈，这个时候可以用<code data-backticks="1" data-nodeid="44926">iotop</code>指令看一下磁盘的情况，如图所示：</p>
<p data-nodeid="44768"><img src="https://s0.lgstatic.com/i/image/M00/71/76/CgqCHl--M2OAJezyAAkRwbdJVmk356.png" alt="1.png" data-nodeid="44930"></p>
<p data-nodeid="44769">上图中是磁盘当前的读写速度以及排行较靠前的进程情况。</p>
<p data-nodeid="44770">另外，如果磁盘空间不足，可以用<code data-backticks="1" data-nodeid="44933">df</code>指令：</p>
<p data-nodeid="44771"><img src="https://s0.lgstatic.com/i/image/M00/71/76/CgqCHl--M22AY0VPAAaPk8du-CY254.png" alt="6.png" data-nodeid="44937"></p>
<p data-nodeid="44772">其实 df 是按照挂载的文件系统计算空间。图中每一个条目都是一个文件系统。有的文件系统直接挂在了一个磁盘上，比如图中的<code data-backticks="1" data-nodeid="44939">/dev/sda5</code>挂在了<code data-backticks="1" data-nodeid="44941">/</code>上，因此这样可以看到各个磁盘的使用情况。</p>
<p data-nodeid="44773">如果想知道更细粒度的磁盘 I/O 情况，可以查看<code data-backticks="1" data-nodeid="44944">/proc/diskstats</code>文件。 这里有 20 多个指标我就不细讲了，如果你将来怀疑自己系统的 I/O 有问题，可以查看这个文件，并阅读相关手册。</p>
<h3 data-nodeid="44774">监控平台</h3>
<p data-nodeid="44775">Linux 中有很多指令可以查看服务器当前的状态，有 CPU、I/O、通信、Nginx 等维度。如果去记忆每个指令自己搭建监控平台，会非常复杂。这里你可以用市面上别人写好的开源系统帮助你收集这些资料。 比如 Taobao System Activity Report（tsar）就是一款非常好用的工具。它集成了大量诸如上面我们使用的工具，并且帮助你定时收集服务器情况，还能记录成日志。你可以用 logstash 等工具，及时将日志收集到监控、分析服务中，比如用 ELK 技术栈。</p>
<h3 data-nodeid="44776">决定进程/线程数量</h3>
<p data-nodeid="44777">最后我们讲讲如何决定线程、进程数量。 上面观察指标是我们必须做的一件事情，通过观察上面的指标，可以对我们开发的应用有一个基本的认识。</p>
<p data-nodeid="44778">下面请你思考一个问题：<strong data-nodeid="44955">如果线程或进程数量 = CPU 核数，是不是一个好的选择</strong>？</p>
<p data-nodeid="44779">有的应用不提供线程，比如 PHP 和 Node.js。</p>
<p data-nodeid="44780">Node.js 内部有一个事件循环模型，这个模型可以理解成协程（Coroutine），相当于大量的协程复用一个进程，可以达到比线程池更高的效率（减少了线程切换）。PHP 模型相对则差得多。Java 是一个多线程的模型，线程和内核线程对应比 1：1；Go 有轻量级线程，多个轻量级线程复用一个内核级线程。</p>
<p data-nodeid="44781">以 Node.js 为例，如果现在是 8 个核心，那么开 8 个 Node 进程，是不是就是最有效利用 CPU 的方案呢？ 乍一看——8 个核、8 个进程，每个进程都可以使用 1 个核，CPU 利用率很高——其实不然。 你不要忘记，CPU 中会有一部分闲置时间是 I/O Wait，这个时候 CPU 什么也不做，主要时间用于等待 I/O。</p>
<p data-nodeid="44782">假设我们应用执行的期间只用 50% CPU 的执行时间，其他 50% 是 I/O Wait。那么 1 个 CPU 同时就可以执行两个进程/线程。</p>
<p data-nodeid="44783">我们考虑一个更一般的模型，如果你的应用平均 I/O 时间占比是 P，假设现在内存中有 n 个这样的线程，那么 CPU 的利用率是多少呢？</p>
<p data-nodeid="44784">假设我们观察到一个应用 （进程），I/O 时间占比是 P，那么可以认为这个进程等待 I/O 的概率是 P。那么如果有 n 个这样的线程，n 个线程都在等待 I/O 的概率是P<sup>n</sup>。而满负荷下，CPU 的利用率就是 CPU 不能空转——也就是不能所有进程都在等待 I/O。因此 CPU 利用率 = 1 -P<sup>n</sup>。</p>
<p data-nodeid="44785">理论上，如果 P = 50%，两个这样的进程可以达到满负荷。 但是从实际出发，何时运行线程是一个分时的调度行为，实际的 CPU 利用率还要看开了多少个这样的线程，如果是 2 个，那么还是会有一部分闲置资源。</p>
<p data-nodeid="44786">因此在实际工作中，开的线程、进程数往往是超过 CPU 核数的。<strong data-nodeid="44976">你可能会问，具体是多少最好呢</strong>？——这里没有具体的算法，要以实际情况为准。比如：你先以 CPU 核数 3 倍的线程数开始，然后进行模拟真实线上压力的测试，分析压测的结果。</p>
<ul data-nodeid="44787">
<li data-nodeid="44788">
<p data-nodeid="44789">如果发现整个过程中，瓶颈在 CPU，比如<code data-backticks="1" data-nodeid="44978">load average</code>很高，那么可以考虑优化 I/O Wait，让 CPU 有更多时间计算。</p>
</li>
<li data-nodeid="44790">
<p data-nodeid="44791">当然，如果 I/O Wait 优化不动了，算法都最优了，就是磁盘读写速度很高达到瓶颈，可以考虑延迟写、延迟读等等技术，或者优化减少读写。</p>
</li>
<li data-nodeid="44792">
<p data-nodeid="44793">如果发现 idle 很高，CPU 大面积闲置，就可以考虑增加线程。</p>
</li>
</ul>
<h3 data-nodeid="44794">总结</h3>
<p data-nodeid="44795"><strong data-nodeid="44986">那么通过这节课的学习，你现在可以尝试来回答本节关联的面试题目：我的服务应该开多少个进程、多少个线程？</strong></p>
<p data-nodeid="44796"><strong data-nodeid="44991">【解析】</strong> 计算密集型一般接近核数，如果负载很高，建议留一个内核专门给操作系统。I/O 密集型一般都会开大于核数的线程和进程。 但是无论哪种模型，都需要实地压测，以压测结果分析为准；另一方面，还需要做好监控，观察服务在不同并发场景的情况，避免资源耗尽。</p>
<p data-nodeid="44797">然后具体语言的特性也要考虑，Node.js 每个进程内部实现了大量类似协程的执行单元，因此 Node.js 即便在 I/O 密集型场景下也可以考虑长期使用核数 -1 的进程模型。而 Java 是多线程模型，线程池通常要大于核数才能充分利用 CPU 资源。</p>
<p data-nodeid="44798">所以核心就一句，眼见为实，上线前要进行压力测试。</p>
<h3 data-nodeid="44799">思考题</h3>
<p data-nodeid="44800"><strong data-nodeid="44999">最后我再给你出一道需要查资料的思考题：如果磁盘坏了，通常会是怎样的情况</strong>？</p>
<p data-nodeid="44801" class="te-preview-highlight">你可以把你的答案、思路或者课后总结写在留言区，这样可以帮助你产生更多的思考，这也是构建知识体系的一部分。经过长期的积累，相信你会得到意想不到的收获。如果你觉得今天的内容对你有所启发，欢迎分享给身边的朋友。期待看到你的思考！</p>

---

### 精选评论

##### **超：
> 计算机网络啥时候出来啊老师

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 4月19日和大家见面哦～

##### **靖：
> load average解释不太正确，man uptime在Section一节中System load averages is the average number of processes that are either in a runnable or unin‐ terruptable state. A process in a runnable state is either using the CPU or waiting to use the CPU.  A process in uninterruptable state is waiting for some I/O access, eg waiting for disk. The averages are taken over the three time intervals. Load averages are not normalized for the number of CPUs in a system, so a load average of 1 means a single CPU system is loaded all the time while on a 4 CPU system it means it was idle 75% of the time.

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 这两个解释并不冲突，角度不一样。但是我给的进程数量除以核数更有意义。以单核为例，如果单核要执行两个进程，load avg是2。代表负载很高。

##### *帆：
> 二月份了，《计算机网络》还没出吗

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 定了定了，《计算机网络》4月19日和大家见面，小伙伴可以期待一下哈

##### **胜：
> 建议在解释cpu负载地方中的「正在排队执行的进程数」改成「等待运行的进程数+等待IO的阻塞进程数」，因为如果有排队执行的进程的话cpu不会处于io/wait的，后面的cpu平均负载高，I/O Wait 也很高的情况很难理解。

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; load计算依据是执行中的进程数量。I/O Wait是CPU用于等待I/O用掉的时间。load高，I/O Wait 高，意味着进程大量等待I/O造成浪费，比如大量串行访问网络服务，应该优化。

##### **林：
> uptime last du df

