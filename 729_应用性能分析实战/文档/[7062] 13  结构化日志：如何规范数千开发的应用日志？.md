<p data-nodeid="2749" class="">在无法远程调试和网络环境隔离等条件下，<strong data-nodeid="3059">应用日志</strong>可以说是我们追查线上各种疑难杂症的<strong data-nodeid="3060">第一手资料</strong>。</p>
<p data-nodeid="2750">好的日志（或是日志埋点）衍生出的 APM 系统，可以让我们具备一种“洞察力”，即先于用户发现问题、定位问题、解决问题；而无规范的应用日志，则会让线上日志五花八门，严重降低线上第一手资料的质量。</p>
<p data-nodeid="2751">从“低头写日志代码”到“抬头写日志”，对于每个 RD 来说，这是一种势在必行的改变。这里“抬头写日志”，意思是写出的日志能更好地融入 APM 生态，并更符合日志规范。这样在定位问题时，才能根据日志做到有的放矢，笃定而行。</p>
<p data-nodeid="2752">所以这一讲，我将以用户订单下单的业务场景为例，教你如何将原始日志改造为结构化日志，并与你分享日志规范化在融入 APM 生态时的踩坑故事与心得经验。其中，框架日志矩阵法和日志码是重点，它们是最能规范数千 RD 编写应用日志的技术手段。</p>
<h3 data-nodeid="2753">为什么需要结构化日志？</h3>
<p data-nodeid="2754">在项目迭代过程中，我们会在代码的必要位置打印日志。比如订单系统，我们会在用户下单的核心代码块，增加 try-catch 去捕获下单逻辑的异常；并在 catch 代码块中，使用 LOGGER.error 方法记录异常日志。</p>
<p data-nodeid="2755">当 RD 上线忘记创建线上表的时候，异常日志是这样的：</p>
<pre class="lang-java" data-nodeid="2756"><code data-language="java">timestamp [thread-id] ERROR Class - Table 'local.dual_1' doesn't exist
</code></pre>
<h4 data-nodeid="2757">1.结构化日志前</h4>
<p data-nodeid="2758">起初，我们会将 ERROR 类型的日志单独放在一个日志文件中，然后通过脚本监听 ERROR 日志文件的增量；当 ERROR 增加时，触发报警；随后 RD 登录堡垒机去搜索日志，从而定位问题。如果公司有安全审计的规范，还要填写工单，拜托 OP（运维专员）去帮忙日志脱敏后下载到本地，才能开始定位问题。</p>
<p data-nodeid="2759">总体来说，这个流程十分原始。</p>
<p data-nodeid="2760">为了解决这个问题，我们会引入 APM 项目 ELK 来处理和分析日志。ELK 具备可视化日志功能，团队成员在接收报警后，只需要登录 ELK，就都可以看到异常日志。</p>
<p data-nodeid="2761">但是，针对上面的 Case，如果不对日志进行改造，贸然引入 ELK，不仅无法发挥出 ELK 的能力，还会带来更多问题。</p>
<ul data-nodeid="2762">
<li data-nodeid="2763">
<p data-nodeid="2764">这个异常日志是由什么应用服务打印的？以及应用的负责人是谁？</p>
</li>
<li data-nodeid="2765">
<p data-nodeid="2766">日志看不懂，找开发的 RD 时，不知道如何快速对齐解决问题的单点瓶颈。</p>
</li>
<li data-nodeid="2767">
<p data-nodeid="2768">日志记不全，不知道引起异常的 SQL 是什么，以及 DB 集群是哪个。</p>
</li>
<li data-nodeid="2769">
<p data-nodeid="2770">……</p>
</li>
</ul>
<h4 data-nodeid="2771">2.结构化日志后</h4>
<p data-nodeid="2772">我们的解决办法是将原来的原始日志改造为结构化日志。顾名思义，结构化日志，即日志是具有结构的。以上面 CASE 的改造为例，结构化后的日志为：</p>
<pre class="lang-json" data-nodeid="2773"><code data-language="json">{ 
   <span class="hljs-attr">"application_id"</span>: <span class="hljs-string">"order"</span>, 
   <span class="hljs-attr">"log_type"</span>: <span class="hljs-string">"mysql_fail"</span>, 
   <span class="hljs-attr">"trace_id"</span>: <span class="hljs-string">"snow_001"</span>, 
   <span class="hljs-attr">"error_msg"</span>: <span class="hljs-string">"Table 'local.dual_1' doesn't exist"</span>, 
   <span class="hljs-attr">"sql"</span>: <span class="hljs-string">"select 'str' from dual_1"</span>, 
   <span class="hljs-attr">"latency"</span>: <span class="hljs-string">"10"</span>, 
   <span class="hljs-attr">"local_ip"</span>:<span class="hljs-string">"127.0.0.1"</span>, 
   <span class="hljs-attr">"remote_ip"</span>:<span class="hljs-string">"localhost"</span>, 
   <span class="hljs-attr">"remote_port"</span>:<span class="hljs-string">"3306"</span>, 
   <span class="hljs-attr">"db_name"</span>: <span class="hljs-string">"local"</span> 
}
</code></pre>
<p data-nodeid="2774">结构化日志可以让团队所有人快速拉齐信息水平，ELK 中展示的异常日志，便很容易被理解：</p>
<ul data-nodeid="2775">
<li data-nodeid="2776">
<p data-nodeid="2777">异常日志（error_msg）"Table 'local.dual_1' doesn't exist" 是由应用（application_id）订单系统（order）引起的；</p>
</li>
<li data-nodeid="2778">
<p data-nodeid="2779">应用节点（local_ip）127.0.0.1 使用 SQL"select 'str' from dual_1" 调用localhost:3306（remote_ip:remote_port）集群；</p>
</li>
<li data-nodeid="2780">
<p data-nodeid="2781">可以使用全局链路 ID（trace_id）snow_001 来跟踪此异常对上下游造成的影响。</p>
</li>
</ul>
<p data-nodeid="2782">你看，日志经过结构化处理，不仅可以降低沟通成本，还能提高每个人对问题的认知，最终帮助定位问题提效。</p>
<h3 data-nodeid="2783">如何将原始日志改造为结构化日志？</h3>
<p data-nodeid="2784">首先我们看上面的 Case，结构化日志就是以 JSON 为结构输出，结构化后的日志会更亲和 ELK 的处理和分析。</p>
<p data-nodeid="2785">以用户订单下单的业务场景为例，如下图所示。</p>
<ul data-nodeid="8626">
<li data-nodeid="8627">
<p data-nodeid="8628"><strong data-nodeid="8639">App</strong>：用户通过手机 App 进行下单请求，会在 App 上生成相应的埋点日志。</p>
</li>
<li data-nodeid="8629">
<p data-nodeid="8630"><strong data-nodeid="8644">Nginx</strong>：请求经过 Nginx 会记录访问日志，然后根据请求的路由规则，专访到相应的应用服务器。</p>
</li>
<li data-nodeid="8631">
<p data-nodeid="8632"><strong data-nodeid="8649">应用服务</strong>：应用服务器 HTTP 框架记录本次请求的分析信息；下单代码块会记录本次请求在代码块中的运行过程；ORM 框架日志会记录本次操作引起的数据变更。</p>
</li>
</ul>
<p data-nodeid="8633" class="te-preview-highlight"><img src="https://s0.lgstatic.com/i/image6/M01/47/6B/Cgp9HWDQXNOAG8t7AAB0MsqNutA799.png" alt="3.png" data-nodeid="8652"></p>
<div data-nodeid="8634"><p style="text-align:center">用户下单业务场景流程图</p></div>




<p data-nodeid="2795">接下来，我会根据订单服务用户下订单的场景，来详细讲述结构化日志应该如何拆分，以及拆分后的每种日志又是如何实现结构化的。</p>
<h4 data-nodeid="2796">1.日志的拆分</h4>
<p data-nodeid="2797">用户通过手机 App 进行下单操作，引发的日志会拆分为“用户下单业务场景流程图”中所示的那 5 类：</p>
<ul data-nodeid="2798">
<li data-nodeid="2799">
<p data-nodeid="2800">用户操作行为的埋点日志</p>
</li>
<li data-nodeid="2801">
<p data-nodeid="2802">Nginx 路由请求的日志</p>
</li>
<li data-nodeid="2803">
<p data-nodeid="2804">HTTP 框架接口提供者日志</p>
</li>
<li data-nodeid="2805">
<p data-nodeid="2806">核心业务下单日志</p>
</li>
<li data-nodeid="2807">
<p data-nodeid="2808">ORM 框架操作数据库日志</p>
</li>
</ul>
<p data-nodeid="2809">可以看出，日志的拆分就是把不同作用的日志，存储到相应的日志文件里面。</p>
<p data-nodeid="2810">拆分带来的好处是在我们定位线上问题的时候就会清晰很多：</p>
<ul data-nodeid="2811">
<li data-nodeid="2812">
<p data-nodeid="2813">比如，我们在进行数据库的性能分析时，可以以 ORM 框架操作数据库的日志为根据；</p>
</li>
<li data-nodeid="2814">
<p data-nodeid="2815">然后，再通过进程 ID、TraceID 或是毫秒级的时间戳，关联到核心业务日志；</p>
</li>
<li data-nodeid="2816">
<p data-nodeid="2817">接着，通过 HTTP 框架接口提供者日志和 Nginx 路由请求的日志，查询出返回给调用者的信息是什么；</p>
</li>
<li data-nodeid="2818">
<p data-nodeid="2819">最后，根据用户操作行为的埋点日志解决线上问题。</p>
</li>
</ul>
<p data-nodeid="2820">在这样的拆分过程中，我们将日志分为了 5 类；而对于这 5 类日志，我们又可以从编写日志的用户角度将其分为两类：</p>
<ul data-nodeid="2821">
<li data-nodeid="2822">
<p data-nodeid="2823">基础架构组 RD 编写的<strong data-nodeid="3159">框架日志</strong></p>
</li>
<li data-nodeid="2824">
<p data-nodeid="2825">负责应用迭代 RD 编写的<strong data-nodeid="3164">业务日志</strong></p>
</li>
</ul>
<p data-nodeid="2826">接下来我展开讲解一下。</p>
<h4 data-nodeid="2827">2.框架日志</h4>
<p data-nodeid="2828">对于用户通过手机 App 进行下单操作已发的上述 5 类日志，其中：</p>
<ul data-nodeid="2829">
<li data-nodeid="2830">
<p data-nodeid="2831">用户操作行为的埋点日志</p>
</li>
<li data-nodeid="2832">
<p data-nodeid="2833">Nginx 路由请求的日志</p>
</li>
<li data-nodeid="2834">
<p data-nodeid="2835">HTTP 框架接口提供者日志</p>
</li>
<li data-nodeid="2836">
<p data-nodeid="2837">ORM 框架操作数据库日志</p>
</li>
</ul>
<p data-nodeid="2838">这 4 类属于框架日志，它们一般由基础架构 RD 负责完成。</p>
<p data-nodeid="2839">在开发过程中，如果项目组内每个开发人员都能编写风格统一的日志，那么在运维处理问题时，就非常容易让每个人都参与进来，将力量拧成一股绳；反之，则各自为战。</p>
<p data-nodeid="2840">那如何将日志风格统一呢？就需要让每个场景的日志都具备这个场景的标准属性，就像表达方式中的“主谓宾定状补”一样，一句话便拆分出明确意义的属性。这样在理解时，就可以更精准、有目的性地知道主语是谁、谓语是哪个。</p>
<p data-nodeid="2841">接下来，我们看一下如何做到让结构化框架日志的每个日志属性都有意义，让其关键信息尽可能少遗漏呢？你可以使用日志矩阵法，去梳理框架日志是否全备。</p>
<p data-nodeid="2842" class=""><strong data-nodeid="3179">【框架日志矩阵法】</strong></p>
<p data-nodeid="2843" class="">通过矩阵法可以评估和决策日志框架记录得是否符合预期，以 HTTP 框架和 ORM 框架为例：</p>
<ul data-nodeid="6985">
<li data-nodeid="6986">
<p data-nodeid="6987">Y 代表需要任何情况都需要记录该字段；</p>
</li>
<li data-nodeid="6988">
<p data-nodeid="6989">O 代表需要在特定的情况下无须人为介入，会记录该字段，如发生慢查；</p>
</li>
<li data-nodeid="6990">
<p data-nodeid="6991">D 代表需要在动态开启 DEBUG 时，记录该字段；</p>
</li>
<li data-nodeid="6992">
<p data-nodeid="6993">橙色代表从系统资源中获取；</p>
</li>
<li data-nodeid="6994">
<p data-nodeid="6995">黄色代表从框架对象中获取。</p>
</li>
</ul>
<p data-nodeid="6996" class=""><img src="https://s0.lgstatic.com/i/image6/M01/47/6B/Cgp9HWDQXLyAfmYnAAEyqvIit-E782.png" alt="2.png" data-nodeid="7004"></p>


<p data-nodeid="2991">框架日志矩阵法，可以清晰地让原始日志变为规范的结构化日志：</p>
<ul data-nodeid="2992">
<li data-nodeid="2993">
<p data-nodeid="2994">定位问题时，明确结构化日志中 JSON 每个属性的作用；</p>
</li>
<li data-nodeid="2995">
<p data-nodeid="2996">定位问题后，我们需要及时复盘结构化框架日志的属性是否有缺失，若有缺失需及时复盘和迭代框架日志矩阵。</p>
</li>
</ul>
<h4 data-nodeid="2997">3.业务日志</h4>
<p data-nodeid="2998">在刚刚介绍 5 大类日志中，除 4 大框架日志外，被“落单”的核心业务下单日志，就是接下来我要讲解的<strong data-nodeid="3342">业务日志</strong>了，它由负责应用迭代的 RD 完成。</p>
<p data-nodeid="2999">以我的实践经验，100 行的业务代码，至少会有 1 处关键业务日志。当项目迭代 2 年以上，代码量超过 10 万行时，那项目就至少会有 1000 处关键业务日志。</p>
<p data-nodeid="3000">当线上出现问题时，RD 会根据业务日志现场，也就是核心业务日志去翻看代码，然后从代码视角来解释现场。当项目的交接和新人的加入时，新接手项目的 RD 会逐渐对原始日志产生理解偏差，所以这种方式也不友好、高效。具体原因如下：</p>
<ul data-nodeid="3001">
<li data-nodeid="3002">
<p data-nodeid="3003">时效低，因为没有使用日志码；</p>
</li>
<li data-nodeid="3004">
<p data-nodeid="3005">由于代码编写的风格不同，RD 也很难理解前人写的原始代码。</p>
</li>
</ul>
<p data-nodeid="3006">而如果我们使用<strong data-nodeid="3352">日志码</strong>和异常规范，就可以从原始作者视角来解释日志，并且可以形成业务日志资产。</p>
<p data-nodeid="3007"><strong data-nodeid="3356">【日志码】</strong></p>
<p data-nodeid="3008">日志码就是在 RD 定义核心日志时，需要<strong data-nodeid="3362">对日志信息指定相应的日志码</strong>。日志码的指定，解决了代码的日志信息不能书写很多，且需要上线才能完成迭代等问题。</p>
<p data-nodeid="3009">当日志信息指定了日志码后，日志信息的角色是简单的代码逻辑阐述。</p>
<ul data-nodeid="3010">
<li data-nodeid="3011">
<p data-nodeid="3012">比如，[A0001] 用户 uid:001 下单失败的原因，账户已被冻结。那我们根据标准的日志码，定义更详细的日志信息和线上问题跟进手册。</p>
</li>
<li data-nodeid="3013">
<p data-nodeid="3014">再比如，日志码 A0001 首次上线时，原始开发成员对 A0001 日志码进行解释，随着项目的运行，值班成员只需对 A0001 相关的工单进行关联。这样向上出现问题时，我们就可以通过日志码快速解决线上问题。</p>
</li>
</ul>
<p data-nodeid="3015">这里给你几个日志码指定时的<strong data-nodeid="3375">建议</strong>。</p>
<ul data-nodeid="3016">
<li data-nodeid="3017">
<p data-nodeid="3018">以目前国内微服务化和中台化的应用形态，3~5 年项目就会重构，代码至多有几十万行为依据，日志码可以有首位 1 个字母 + 4 个数字组成。首字母代表应用系统代码块的业务类型，递增数字代表日志码的增量。</p>
</li>
<li data-nodeid="3019">
<p data-nodeid="3020">日志码的指定可以解决线上日志的可追溯性问题，降低沟通成本。所以项目的日志码字典最好在项目初期就建立，并且业务日志相关的代码块迭代时，以及值班发现相关代码块出现问题时，都要对日志码进行迭代，这样才能发挥出日志码的价值。</p>
</li>
<li data-nodeid="3021">
<p data-nodeid="3022">日志码字典的维护，应该面向可量化监控设计。比如 A0001 代表用户下单时，资金冻结。那当 A0001 日志码超过一定量时，是否可以预测出相关联的上下游系统需要做出的必要调整动作。</p>
</li>
</ul>
<h3 data-nodeid="3023">日志规范化踩坑：如何无侵入式地实现异步日志框架与分布式链路集成？</h3>
<p data-nodeid="3024">应用服务使用异步日志减少资源开销已是当下的常态，使用异步日志集成 APM 是有改造成本的，那如何让落地方案最优呢？接下来，我将结合异步日志框架原理和无侵入集成 APM 的落地方案，与你分享我的踩坑、填坑的经历。</p>
<h4 data-nodeid="3025">1.引入异步日志框架</h4>
<p data-nodeid="3026">随着日志的规范化落地，改造后的打印结构化日志也带来了更大的性能开销。所以，为了提高日志的性能，我们会<strong data-nodeid="3389">引入异步日志框架</strong>来解决此问题。</p>
<p data-nodeid="3027">以 Log4j2 中的异步日志为例，主线程打印日志的代码并不会立刻将日志打印到磁盘上，而是将日志信息保存到异步队列。由异步队列定时、批量地将日志信息从队列中拉取出，一起打印到日志文件中，从而提高打印日志的性能。</p>
<p data-nodeid="4801" class="">业务线程、日志线程打印日志流程你可以参考下面的流程图：<br>
<img src="https://s0.lgstatic.com/i/image6/M01/47/6B/Cgp9HWDQXJ-Ae4MNAABzDeoGUms470.png" alt="1.png" data-nodeid="4806"></p>


<h4 data-nodeid="3029">2.解决分布式链路集成问题</h4>
<p data-nodeid="3030">而引入异步日志框架的同时，如果不对日志框架进行修改，就会造成与 APM 的分布式链路系统无法集成。</p>
<p data-nodeid="3031">原因是在异步框架流程的两处，无法获取存在主线程 Thread Local 中的分布式链路信息，所以解决的两个关键点是：</p>
<ul data-nodeid="3032">
<li data-nodeid="3033">
<p data-nodeid="3034">在 1 处获取必要的主线程 Thread Local 中的分布式链路信息；</p>
</li>
<li data-nodeid="3035">
<p data-nodeid="3036">在 2 处改为从 LogEvent 事件获取分布式链路信息进行打印。</p>
</li>
</ul>
<p data-nodeid="3037">这个说起来很简单，但是现实的日志框架并没有给我们一些关键的拦截点，来实现这些代码的织入。而在主线程手动写入分布式链路信息，显然会带来很大的开发投入，而且保证 100% 编写正确的有效手段也很少。</p>
<p data-nodeid="3038">所以我通过<strong data-nodeid="3411">字节码增强技术</strong>，无侵入地实现了异步日志框架与分布式链路集成的功能，你可以参考我在 Apache SkyWalking 的这个<a href="https://github.com/apache/skywalking/pull/2750?fileGuid=xxQTRXtVcqtHK6j8" data-nodeid="3409">Merge Request</a>进行更深入的学习。</p>
<h3 data-nodeid="3039">小结与思考</h3>
<p data-nodeid="3040">让集群中每个应用的日志都按照统一的规范进行编写，是每个团队在扩大过程中，都要解决的难题。</p>
<p data-nodeid="3041">本讲使用<strong data-nodeid="3419">结构化日志</strong>来实现规范化，这是一种普遍被认可的记录日志的方式。</p>
<ul data-nodeid="3042">
<li data-nodeid="3043">
<p data-nodeid="3044">当线上出现问题时，它能让更多人可以根据规范的日志现场，去参与问题的定位；</p>
</li>
<li data-nodeid="3045">
<p data-nodeid="3046">并且在定位问题时，规范的日志可以减少沟通成本，提升解决问题的协作效率，避免日志过度个性化带来的“信息孤岛”等问题。</p>
</li>
</ul>
<p data-nodeid="3047">围绕结构化日志，我还讲解了框架日志及框架<strong data-nodeid="3431">日志矩阵法</strong>，还有业务日志及<strong data-nodeid="3432">日志码</strong>，这两大知识点，它们是实现开发人员日志规范化的基石，在提升应用日志专业化的重要手段。需要你反复吃透。</p>
<p data-nodeid="3048">那么，你的团队有没有在应用服务中使用过类似日志码的“各种码”呢？如接口设计中，必不可少的错误码等。</p>
<p data-nodeid="3049" class="">你有想过这些“各种码”是如何联动的吗？我们又应该如何管理、治理这些码呢？你可以将你的思考与设计写在留言区，与大家讨论。</p>

---

### 精选评论

##### **聪：
> 赵老师，异步日志框架与分布式链路集成的案例能否展开讲的更详细一些，或者能否单开一个技术博客

 ###### &nbsp;&nbsp;&nbsp; 讲师回复：
> &nbsp;&nbsp;&nbsp; 进一步学习异步框架集成SkyWalking 可以参考https://github.com/apache/skywalking/pull/2750

##### **聪：
> 框架日志矩阵法中，没看到橙色和黄色啊

 ###### &nbsp;&nbsp;&nbsp; 编辑回复：
> &nbsp;&nbsp;&nbsp; 感谢指错，小编已更新图片

